{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to MkDocs"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"howto/","text":"How do I? \u00b6 I have an account, now: How do I log in? \u00b6 Logging in is most straightforward if you are inside the UCL firewall. If you are logging in from home or other external networks then you first have to get on to the UCL network . Linux / Unix / Mac OS X \u00b6 Use the terminal and type the below command to secure shell (ssh) into the machine you wish to access. Replace <your_UCL_user_id> with your central UCL username, and <system_name> with the name of the machine you want to log in to, eg. legion , grace , aristotle . ssh <your_UCL_user_id>@<system_name>.rc.ucl.ac.uk Windows \u00b6 On Windows you need something that will give you a suitable terminal and ssh - usually PuTTY, although you could also use Cygwin if you wanted a full Linux-like environment. Using PuTTY \u00b6 PuTTY is a common SSH client on Windows and is available on Desktop@UCL. You can find it under: Start > All Programs > Applications O-P > PuTTY You will need to create an entry for the host you are connecting to with the settings below. If you want to save your settings, give them an easily-identifiable name in the \"Saved Sessions\" box and press \"Save\". Then you can select it and \"Load\" next time you use PuTTY. In newer versions of PuTTY, it looks like this. TODO: new putty You will then be asked to enter your username and password. Only enter your username, not @legion.rc.ucl.ac.uk . The password field will remain entirely blank when you type in to it - it does not show placeholders to indicate you have typed something. Logging in from outside the UCL firewall \u00b6 You will need to either use the UCL Virtual Private Network or ssh in to UCL's gateway socrates.ucl.ac.uk first. From Socrates you can then ssh in to our systems by typing ssh <your_UCL_user_id>@<system_name>.rc.ucl.ac.uk . Advanced: If you find you need to go via Socrates often, you can set up this jump automatically, see Single-step logins using tunnelling Login problems \u00b6 If you experience difficulties with your login, please make sure that you are typing your UCL user ID and your password correctly. If you have recently updated your password, it takes some hours to propagate to all UCL systems. If you still cannot get access but can access other UCL services like Socrates, please contact us on rc-support@ucl.ac.uk. Your account may have expired, or you may have gone over quota. If you cannot access anything, please see UCL MyAccount - you may need to request a password reset from the Service Desk. If you get a host key error message, you will need to delete old host keys. TODO: details How do I transfer data onto the system? \u00b6 You can transfer data to and from our systems using any program capable of using the Secure Copy (SCP) protocol. This uses the same SSH system as you use to log in to a command line session, but then transfers data over it. This means that if you can use SSH to connect to a system, you can usually use SCP to transfer files to it. Copying files using Linux or Mac OS X \u00b6 You can use the command-line utilities scp, sftp or rsync to copy your data about. You can also use a graphical client (Transmit, CyberDuck, FileZilla). scp \u00b6 This will copy a data file from somewhere on your local machine to a specified location on the remote machine (Legion, Grace etc). scp <local_data_file> <remote_user_id>@<remote_hostname>:<remote_path> # Example: copy myfile from your local current directory into Scratch on Legion scp myfile ccxxxxx@legion.rc.ucl.ac.uk:~/Scratch/ This will do the reverse, copying from the remote machine to your local machine. (This is still run from your local machine). scp <remote_user_id>@<remote_hostname>:<remote_path><remote_data_file> <local_path> # Example: copy myfile from Legion into the Backups directory in your local current directory scp ccxxxxx@legion.rc.ucl.ac.uk:~/Scratch/myfile Backups/ sftp \u00b6 You can use sftp to log in to the remote machine, navigate through directories and use put and get to copy files from and to your local machine. lcd and lls are local equivalents of cd and ls so you can navigate through your local directories as you go. sftp <remote_user_id>@<remote_hostname> cd <remote_path> get <remote_file> lcd <local_path> put <local_file> # Example: download a copy of file1 into your local current directory, # change local directory and upload a copy of file2 sftp ccxxxxx@legion.rc.ucl.ac.uk cd Scratch/files get file1 lcd ../files_to_upload put file2 rsync \u00b6 Rsync is used to remotely synchronise directories, so can be used to only copy files which have changed. Have a look at man rsync as there are many options. Copying files using Windows and WinSCP \u00b6 WinSCP is a graphical client that you can use for scp or sftp. The login/create new session screen will open if this is the first time you are using WinSCP. You can choose SFTP or SCP as the file protocol. If you have an unstable connection with one, you may wish to try the other. SCP is probably generally better. Fill in the hostname of the machine you wish to connect to, your username and password. Click Save and give your settings a useful name. You'll then be shown your list of Stored sessions, which will have the one you just created. Select the session and click Login. Transferring files from outside the UCL firewall \u00b6 As when logging in, when you are outside the UCL firewall you will need a method to connect inside it before you copy files. (You do not want to be copying files on to Socrates and then on to our systems - this is slow, unnecessary, and it means you need space available on Socrates too). You can use the UCL Virtual Private Network and scp direct to our systems or you can do some form of ssh tunnelling. Single-step logins using tunnelling \u00b6 Linux / Unix / Mac OS X \u00b6 Inside your ~/.ssh directory on your local machine, add the below to your config file (or create a file called config if you don't already have one). Generically, it should be of this form where <name> can be anything you want to call this entry. Host <name> User <remote_user_id> HostName <remote_hostname> proxyCommand ssh -W <remote_hostname>:22 <remote_user_id>@socrates.ucl.ac.uk This causes the commands you type in your client to be forwarded on over a secure channel to the specified remote host. Here are some examples - you can have as many of these as you need in your config file. Host legion User ccxxxxx HostName legion.rc.ucl.ac.uk proxyCommand ssh -W legion.rc.ucl.ac.uk:22 ccxxxxx@socrates.ucl.ac.uk Host login05 User ccxxxxx HostName login05.external.legion.ucl.ac.uk proxyCommand ssh -W login05.external.legion.ucl.ac.uk:22 ccxxxxx@socrates.ucl.ac.uk Host aristotle User ccxxxxx HostName aristotle.rc.ucl.ac.uk proxyCommand ssh -W aristotle.rc.ucl.ac.uk:22 ccxxxxx@socrates.ucl.ac.uk You can now just type ssh legion or scp file1 aristotle:~ and you will go through Socrates. You'll be asked for login details twice since you're logging in to two machines, Socrates and your endpoint. Windows - WinSCP \u00b6 WinSCP can also set up SSH tunnels. Create a new session as before, and tick the Advanced options box in the bottom left corner. Select Connection > Tunnel from the left pane. Tick the Connect through SSH tunnel box and enter the hostname of the gateway you are tunnelling through, for example socrates.ucl.ac.uk Fill in your username and password for that host. (Central UCL ones for Socrates). Select Session from the left pane and fill in the hostname you want to end up on after the tunnel. Fill in your username and password for that host and set the file protocol to SCP. Save your settings with a useful name. Windows - PuTTY \u00b6 You can use PuTTY for tunnelling when you just want a single-step login and not a file transfer. Managing your quota \u00b6 How do I submit a job to the scheduler? \u00b6 To submit a job to the scheduler you need to write a jobscript that contains the resources the job is asking for and the actual commands you want to run. This jobscript is then submitted using the qsub command. qsub myjobscript It will be put in to the queue and will begin running on the compute nodes at some point later when it has been allocated resources. Passing in qsub options on the command line \u00b6 The #$ lines in your jobscript are options to qsub. It will take each line which has #$ as the first two characters and use the contents beyond that as an option. You can also pass options directly to the qsub command and this will override the settings in your script. This can be useful if you are scripting your job submissions in more complicated ways. For example, if you want to change the name of the job for this one instance of the job you can submit your script with: qsub -N NewName myscript.sh Or if you want to increase the wall-clock time to 24 hours: qsub -l h_rt=24:0:0 myscript.sh You can submit jobs with dependencies by using the -hold_jid option. For example, the command below submits a job that won't run until job 12345 has finished: qsub -hold_jid 12345 myscript.sh You may specify node type with the -ac allow= flags as below: qsub -ac allow=XYZ myscript.sh That would restrict the job to running on nodes of type X, Y or Z (the older Legion nodes). Note that for debugging purposes, it helps us if you have these options inside your jobscript rather than passed in on the command line whenever possible. We (and you) can see the exact jobscript that was submitted for every job that ran but not what command line options you submitted it with. Checking your previous jobscripts \u00b6 If you want to check what you submitted for a specific job ID, you can do it with the scriptfor utility. scriptfor 12345 As mentioned above, this will not show any command line options you passed in. How do I monitor a job? \u00b6 qstat \u00b6 The qstat command shows the status of your jobs. By default, if you run it with no options, it shows only your jobs (and no-one else\u2019s). This makes it easier to keep track of your jobs. The output will look something like this: job-ID prior name user state submit/start at queue slots ja-task-ID ----------------------------------------------------------------------------------------------------------------- 123454 2.00685 DI_m3 ccxxxxx Eqw 10/13/2017 15:29:11 12 123456 2.00685 DI_m3 ccxxxxx r 10/13/2017 15:29:11 Yorick@node-x02e-006 24 123457 2.00398 DI_m2 ucappka qw 10/12/2017 14:42:12 1 This shows you the job ID, the numeric priority the scheduler has assigned to the job, the name you have given the job, your username, the state the job is in, the date and time it was submitted at (or started at, if it has begun), the head node of the job, the number of 'slots' it is taking up, and if it is an array job the last column shows the task ID. The queue name ( Yorick here) is generally not useful. The head node name ( node-x02e-006 ) is useful - the node-x part tells you this is an X-type node. If you want to get more information on a particular job, note its job ID and then use the -f and -j flags to get full output about that job. Most of this information is not very useful. qstat -f -j 12345 Job states \u00b6 qw : queueing, waiting r : running Rq : a pre-job check on a node failed and this job was put back in the queue Rr : this job was rescheduled but is now running on a new node Eqw : there was an error in this jobscript. This will not run. t : this job is being transferred dr : this job is being deleted Many jobs cycling between Rq and Rr generally means there is a dodgy compute node which is failing pre-job checks, but is free so everything tries to run there. In this case, let us know and we will investigate. If a job stays in t or dr state for a long time, the node it was on is likely to be unresponsive - again let us know and we'll investigate. A job in Eqw will remain in that state until you delete it - you should first have a look at what the error was with qexplain . qexplain \u00b6 This is a utility to show you the non-truncated error reported by your job. qstat -j will show you a truncated version near the bottom of the output. qexplain 123454 qdel \u00b6 You use qdel to delete a job from the queue. qdel 123454 You can delete all your jobs at once: qdel '*' More scheduler commands \u00b6 Have a look at man qstat and note the commands shown in the SEE ALSO section of the manual page. Exit the manual page and then look at the man pages for those. (You will not be able to run all commands). nodesforjob \u00b6 This is a utility that shows you the current How do I run a graphical program? \u00b6","title":"How do I?"},{"location":"howto/#how-do-i","text":"I have an account, now:","title":"How do I?"},{"location":"howto/#how-do-i-log-in","text":"Logging in is most straightforward if you are inside the UCL firewall. If you are logging in from home or other external networks then you first have to get on to the UCL network .","title":"How do I log in?"},{"location":"howto/#linux-unix-mac-os-x","text":"Use the terminal and type the below command to secure shell (ssh) into the machine you wish to access. Replace <your_UCL_user_id> with your central UCL username, and <system_name> with the name of the machine you want to log in to, eg. legion , grace , aristotle . ssh <your_UCL_user_id>@<system_name>.rc.ucl.ac.uk","title":"Linux / Unix / Mac OS X"},{"location":"howto/#windows","text":"On Windows you need something that will give you a suitable terminal and ssh - usually PuTTY, although you could also use Cygwin if you wanted a full Linux-like environment.","title":"Windows"},{"location":"howto/#using-putty","text":"PuTTY is a common SSH client on Windows and is available on Desktop@UCL. You can find it under: Start > All Programs > Applications O-P > PuTTY You will need to create an entry for the host you are connecting to with the settings below. If you want to save your settings, give them an easily-identifiable name in the \"Saved Sessions\" box and press \"Save\". Then you can select it and \"Load\" next time you use PuTTY. In newer versions of PuTTY, it looks like this. TODO: new putty You will then be asked to enter your username and password. Only enter your username, not @legion.rc.ucl.ac.uk . The password field will remain entirely blank when you type in to it - it does not show placeholders to indicate you have typed something.","title":"Using PuTTY"},{"location":"howto/#logging-in-from-outside-the-ucl-firewall","text":"You will need to either use the UCL Virtual Private Network or ssh in to UCL's gateway socrates.ucl.ac.uk first. From Socrates you can then ssh in to our systems by typing ssh <your_UCL_user_id>@<system_name>.rc.ucl.ac.uk . Advanced: If you find you need to go via Socrates often, you can set up this jump automatically, see Single-step logins using tunnelling","title":"Logging in from outside the UCL firewall"},{"location":"howto/#login-problems","text":"If you experience difficulties with your login, please make sure that you are typing your UCL user ID and your password correctly. If you have recently updated your password, it takes some hours to propagate to all UCL systems. If you still cannot get access but can access other UCL services like Socrates, please contact us on rc-support@ucl.ac.uk. Your account may have expired, or you may have gone over quota. If you cannot access anything, please see UCL MyAccount - you may need to request a password reset from the Service Desk. If you get a host key error message, you will need to delete old host keys. TODO: details","title":"Login problems"},{"location":"howto/#how-do-i-transfer-data-onto-the-system","text":"You can transfer data to and from our systems using any program capable of using the Secure Copy (SCP) protocol. This uses the same SSH system as you use to log in to a command line session, but then transfers data over it. This means that if you can use SSH to connect to a system, you can usually use SCP to transfer files to it.","title":"How do I transfer data onto the system?"},{"location":"howto/#copying-files-using-linux-or-mac-os-x","text":"You can use the command-line utilities scp, sftp or rsync to copy your data about. You can also use a graphical client (Transmit, CyberDuck, FileZilla).","title":"Copying files using Linux or Mac OS X"},{"location":"howto/#scp","text":"This will copy a data file from somewhere on your local machine to a specified location on the remote machine (Legion, Grace etc). scp <local_data_file> <remote_user_id>@<remote_hostname>:<remote_path> # Example: copy myfile from your local current directory into Scratch on Legion scp myfile ccxxxxx@legion.rc.ucl.ac.uk:~/Scratch/ This will do the reverse, copying from the remote machine to your local machine. (This is still run from your local machine). scp <remote_user_id>@<remote_hostname>:<remote_path><remote_data_file> <local_path> # Example: copy myfile from Legion into the Backups directory in your local current directory scp ccxxxxx@legion.rc.ucl.ac.uk:~/Scratch/myfile Backups/","title":"scp"},{"location":"howto/#sftp","text":"You can use sftp to log in to the remote machine, navigate through directories and use put and get to copy files from and to your local machine. lcd and lls are local equivalents of cd and ls so you can navigate through your local directories as you go. sftp <remote_user_id>@<remote_hostname> cd <remote_path> get <remote_file> lcd <local_path> put <local_file> # Example: download a copy of file1 into your local current directory, # change local directory and upload a copy of file2 sftp ccxxxxx@legion.rc.ucl.ac.uk cd Scratch/files get file1 lcd ../files_to_upload put file2","title":"sftp"},{"location":"howto/#rsync","text":"Rsync is used to remotely synchronise directories, so can be used to only copy files which have changed. Have a look at man rsync as there are many options.","title":"rsync"},{"location":"howto/#copying-files-using-windows-and-winscp","text":"WinSCP is a graphical client that you can use for scp or sftp. The login/create new session screen will open if this is the first time you are using WinSCP. You can choose SFTP or SCP as the file protocol. If you have an unstable connection with one, you may wish to try the other. SCP is probably generally better. Fill in the hostname of the machine you wish to connect to, your username and password. Click Save and give your settings a useful name. You'll then be shown your list of Stored sessions, which will have the one you just created. Select the session and click Login.","title":"Copying files using Windows and WinSCP"},{"location":"howto/#transferring-files-from-outside-the-ucl-firewall","text":"As when logging in, when you are outside the UCL firewall you will need a method to connect inside it before you copy files. (You do not want to be copying files on to Socrates and then on to our systems - this is slow, unnecessary, and it means you need space available on Socrates too). You can use the UCL Virtual Private Network and scp direct to our systems or you can do some form of ssh tunnelling.","title":"Transferring files from outside the UCL firewall"},{"location":"howto/#single-step-logins-using-tunnelling","text":"","title":"Single-step logins using tunnelling"},{"location":"howto/#linux-unix-mac-os-x_1","text":"Inside your ~/.ssh directory on your local machine, add the below to your config file (or create a file called config if you don't already have one). Generically, it should be of this form where <name> can be anything you want to call this entry. Host <name> User <remote_user_id> HostName <remote_hostname> proxyCommand ssh -W <remote_hostname>:22 <remote_user_id>@socrates.ucl.ac.uk This causes the commands you type in your client to be forwarded on over a secure channel to the specified remote host. Here are some examples - you can have as many of these as you need in your config file. Host legion User ccxxxxx HostName legion.rc.ucl.ac.uk proxyCommand ssh -W legion.rc.ucl.ac.uk:22 ccxxxxx@socrates.ucl.ac.uk Host login05 User ccxxxxx HostName login05.external.legion.ucl.ac.uk proxyCommand ssh -W login05.external.legion.ucl.ac.uk:22 ccxxxxx@socrates.ucl.ac.uk Host aristotle User ccxxxxx HostName aristotle.rc.ucl.ac.uk proxyCommand ssh -W aristotle.rc.ucl.ac.uk:22 ccxxxxx@socrates.ucl.ac.uk You can now just type ssh legion or scp file1 aristotle:~ and you will go through Socrates. You'll be asked for login details twice since you're logging in to two machines, Socrates and your endpoint.","title":"Linux / Unix / Mac OS X"},{"location":"howto/#windows-winscp","text":"WinSCP can also set up SSH tunnels. Create a new session as before, and tick the Advanced options box in the bottom left corner. Select Connection > Tunnel from the left pane. Tick the Connect through SSH tunnel box and enter the hostname of the gateway you are tunnelling through, for example socrates.ucl.ac.uk Fill in your username and password for that host. (Central UCL ones for Socrates). Select Session from the left pane and fill in the hostname you want to end up on after the tunnel. Fill in your username and password for that host and set the file protocol to SCP. Save your settings with a useful name.","title":"Windows - WinSCP"},{"location":"howto/#windows-putty","text":"You can use PuTTY for tunnelling when you just want a single-step login and not a file transfer.","title":"Windows - PuTTY"},{"location":"howto/#managing-your-quota","text":"","title":"Managing your quota"},{"location":"howto/#how-do-i-submit-a-job-to-the-scheduler","text":"To submit a job to the scheduler you need to write a jobscript that contains the resources the job is asking for and the actual commands you want to run. This jobscript is then submitted using the qsub command. qsub myjobscript It will be put in to the queue and will begin running on the compute nodes at some point later when it has been allocated resources.","title":"How do I submit a job to the scheduler?"},{"location":"howto/#passing-in-qsub-options-on-the-command-line","text":"The #$ lines in your jobscript are options to qsub. It will take each line which has #$ as the first two characters and use the contents beyond that as an option. You can also pass options directly to the qsub command and this will override the settings in your script. This can be useful if you are scripting your job submissions in more complicated ways. For example, if you want to change the name of the job for this one instance of the job you can submit your script with: qsub -N NewName myscript.sh Or if you want to increase the wall-clock time to 24 hours: qsub -l h_rt=24:0:0 myscript.sh You can submit jobs with dependencies by using the -hold_jid option. For example, the command below submits a job that won't run until job 12345 has finished: qsub -hold_jid 12345 myscript.sh You may specify node type with the -ac allow= flags as below: qsub -ac allow=XYZ myscript.sh That would restrict the job to running on nodes of type X, Y or Z (the older Legion nodes). Note that for debugging purposes, it helps us if you have these options inside your jobscript rather than passed in on the command line whenever possible. We (and you) can see the exact jobscript that was submitted for every job that ran but not what command line options you submitted it with.","title":"Passing in qsub options on the command line"},{"location":"howto/#checking-your-previous-jobscripts","text":"If you want to check what you submitted for a specific job ID, you can do it with the scriptfor utility. scriptfor 12345 As mentioned above, this will not show any command line options you passed in.","title":"Checking your previous jobscripts"},{"location":"howto/#how-do-i-monitor-a-job","text":"","title":"How do I monitor a job?"},{"location":"howto/#qstat","text":"The qstat command shows the status of your jobs. By default, if you run it with no options, it shows only your jobs (and no-one else\u2019s). This makes it easier to keep track of your jobs. The output will look something like this: job-ID prior name user state submit/start at queue slots ja-task-ID ----------------------------------------------------------------------------------------------------------------- 123454 2.00685 DI_m3 ccxxxxx Eqw 10/13/2017 15:29:11 12 123456 2.00685 DI_m3 ccxxxxx r 10/13/2017 15:29:11 Yorick@node-x02e-006 24 123457 2.00398 DI_m2 ucappka qw 10/12/2017 14:42:12 1 This shows you the job ID, the numeric priority the scheduler has assigned to the job, the name you have given the job, your username, the state the job is in, the date and time it was submitted at (or started at, if it has begun), the head node of the job, the number of 'slots' it is taking up, and if it is an array job the last column shows the task ID. The queue name ( Yorick here) is generally not useful. The head node name ( node-x02e-006 ) is useful - the node-x part tells you this is an X-type node. If you want to get more information on a particular job, note its job ID and then use the -f and -j flags to get full output about that job. Most of this information is not very useful. qstat -f -j 12345","title":"qstat"},{"location":"howto/#job-states","text":"qw : queueing, waiting r : running Rq : a pre-job check on a node failed and this job was put back in the queue Rr : this job was rescheduled but is now running on a new node Eqw : there was an error in this jobscript. This will not run. t : this job is being transferred dr : this job is being deleted Many jobs cycling between Rq and Rr generally means there is a dodgy compute node which is failing pre-job checks, but is free so everything tries to run there. In this case, let us know and we will investigate. If a job stays in t or dr state for a long time, the node it was on is likely to be unresponsive - again let us know and we'll investigate. A job in Eqw will remain in that state until you delete it - you should first have a look at what the error was with qexplain .","title":"Job states"},{"location":"howto/#qexplain","text":"This is a utility to show you the non-truncated error reported by your job. qstat -j will show you a truncated version near the bottom of the output. qexplain 123454","title":"qexplain"},{"location":"howto/#qdel","text":"You use qdel to delete a job from the queue. qdel 123454 You can delete all your jobs at once: qdel '*'","title":"qdel"},{"location":"howto/#more-scheduler-commands","text":"Have a look at man qstat and note the commands shown in the SEE ALSO section of the manual page. Exit the manual page and then look at the man pages for those. (You will not be able to run all commands).","title":"More scheduler commands"},{"location":"howto/#nodesforjob","text":"This is a utility that shows you the current","title":"nodesforjob"},{"location":"howto/#how-do-i-run-a-graphical-program","text":"","title":"How do I run a graphical program?"},{"location":"Wiki_Export/","text":"Wiki Exports \u00b6 These pages were imported from the old documentation wiki. They may still have incorrect links, formatting mistakes, or missing scripts. TODO: Delete this page when it is no longer necessary.","title":"Wiki Exports"},{"location":"Wiki_Export/#wiki-exports","text":"These pages were imported from the old documentation wiki. They may still have incorrect links, formatting mistakes, or missing scripts. TODO: Delete this page when it is no longer necessary.","title":"Wiki Exports"},{"location":"Wiki_Export/done/Accessing_RC_Systems/","text":"After you have applied for and been granted access to our services , you can log in using a terminal application that supports the ssh access protocol. Aristotle is a teaching machine accessible to everyone with a UCL user ID and does not need to be applied for. Logging in from Linux or Mac OS X \u00b6 Use the terminal and run the below command to ssh into the correct machine. Replace ccaaxyz with your central UCL username. Legion \u00b6 ssh ccaaxyz@legion.rc.ucl.ac.uk Myriad \u00b6 ssh ccaaxyz@myriad.rc.ucl.ac.uk Grace \u00b6 ssh ccaaxyz@grace.rc.ucl.ac.uk Aristotle \u00b6 ssh ccaaxyz@aristotle.rc.ucl.ac.uk` You will then be asked to enter your UCL password. This user ID and password are those provided to you by Information Services Division . If you will want to run graphical applications, read on to \"Running graphical applications using X-forwarding\". Logging in from Windows \u00b6 On Windows you need something that will give you a suitable terminal and ssh - usually PuTTY, although you could also use Cygwin if you wanted a full Linux-like environment. Using PuTTY \u00b6 PuTTY is a common SSH client on Windows and is available on Desktop@UCL. You can find it under Start > All Programs > Applications O-P > PuTTY You will need to create an entry for the host you are connecting to with the settings below. If you want to save your settings, give them an easily-identifiable name in the \"Saved Sessions\" box and press \"Save\". Then you can select it and \"Load\" next time you use PuTTY. Replace \"legion\" in the hostname with \"myriad\", \"grace\", or \"aristotle\" as appropriate. You will then have a screen come up that asks you for your username and password. Only enter your username, not \"@legion.rc.ucl.ac.uk\". The password field will remain entirely blank when you enter it - it does not show placeholders to indicate you have typed something. Login problems \u00b6 If you experience difficulties with your login, please make sure that you are typing your UCL user ID and your password correctly. If you still cannot get access but can access other UCL services like Socrates, please contact us on rc-support@ucl.ac.uk . If you cannot access anything, please see UCL MyAccount - you may need to request a password reset from the Service Desk. Accessing services from outside UCL \u00b6 If you wish to access any of our machines from outside UCL, you cannot do so directly as they are behind UCL's firewall. To do so you will have to either use ssh to connect to UCL's gateway first: ssh ccaaxyz@socrates.ucl.ac.uk and from there connect to the correct host as described above, or login first to your departmental gateway (if you have one) and then login from there. IS VPN Service \u00b6 Alternatively, you can use the IS VPN service to connect to UCL using a virtual private network. That way, once the connection has been established, you can establish an ssh connection to the host machine directly, for example: ssh ccaaxyz@legion.rc.ucl.ac.uk Running graphical applications using X-forwarding \u00b6 X-forwarding allows users to run a graphical program on a remote computer and display the user interface on their own computer. X-forwarding on Linux \u00b6 If you wish to have X-windows functionality enabled you have to make sure that you add either the -X or -Y flags (see man ssh for details) on all ssh commands you have to run to establish a connection to Legion. For example, connecting from outside of UCL: ssh -X ccaaxyz@socrates.ucl.ac.uk and then ssh -X ccaaxyz@legion.rc.ucl.ac.uk X-forwarding on Mac OS X \u00b6 You will need to install XQuartz to provide an X-Window System for Mac OS X. (Previously known as X11.app). You can then follow the Linux instructions using Terminal.app. X-forwarding on Windows \u00b6 You will need: An SSH client; e.g., PuTTY An X server program; e.g., Exceed, Xming Exceed is available on Desktop@UCL machines and downloadable from the UCL software database . Xming is open source (and mentioned here without testing). Exceed on Desktop@UCL \u00b6 Load Exceed. You can find it under Start > All Programs > Applications O-P > Open Text Exceed 14 > Exceed Open PuTTY (Applications O-P > PuTTY) In PuTTY, set up the connection with the host machine as usual: Host name: legion.rc.ucl.ac.uk (for example) Port: 22 Connection type: SSH Then, from the Category menu, select Connection > SSH > X11 for 'Options controlling SSH X11 forwarding' Make sure the box marked 'Enable X11 forwarding' is checked. Return to the session menu and save these settings with a new identifiable name for reuse in future. Click 'Open' and login to the host as usual To test that X-forwarding is working try one of these test applications: nedit: a text editor xeyes: to bring up a set of eyes that track the mouse position on the screen glxgears: to bring up an animated set of gears xclock: a clock If these work, you have successfully enabled X forwarding for graphical applications. (Note they may not be available on all systems). Installing Xming on your own computer \u00b6 Xming is a popular open source X server for Windows. These are instructions for using it alongside PuTTY. Other SSH clients and X servers are available. We cannot verify how well it may be working. Install both PuTTY and Xming if you have not done so already. During Xming installation, choose not to install an SSH client. Open Xming - the Xming icon should appear on the task bar. Open PuTTY Set up PuTTY as shown in the Exceed section. Transferring files \u00b6 Read on to Managing data on RC systems .","title":"Accessing RC Systems"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#logging-in-from-linux-or-mac-os-x","text":"Use the terminal and run the below command to ssh into the correct machine. Replace ccaaxyz with your central UCL username.","title":"Logging in from Linux or Mac OS X"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#legion","text":"ssh ccaaxyz@legion.rc.ucl.ac.uk","title":"Legion"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#myriad","text":"ssh ccaaxyz@myriad.rc.ucl.ac.uk","title":"Myriad"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#grace","text":"ssh ccaaxyz@grace.rc.ucl.ac.uk","title":"Grace"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#aristotle","text":"ssh ccaaxyz@aristotle.rc.ucl.ac.uk` You will then be asked to enter your UCL password. This user ID and password are those provided to you by Information Services Division . If you will want to run graphical applications, read on to \"Running graphical applications using X-forwarding\".","title":"Aristotle"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#logging-in-from-windows","text":"On Windows you need something that will give you a suitable terminal and ssh - usually PuTTY, although you could also use Cygwin if you wanted a full Linux-like environment.","title":"Logging in from Windows"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#using-putty","text":"PuTTY is a common SSH client on Windows and is available on Desktop@UCL. You can find it under Start > All Programs > Applications O-P > PuTTY You will need to create an entry for the host you are connecting to with the settings below. If you want to save your settings, give them an easily-identifiable name in the \"Saved Sessions\" box and press \"Save\". Then you can select it and \"Load\" next time you use PuTTY. Replace \"legion\" in the hostname with \"myriad\", \"grace\", or \"aristotle\" as appropriate. You will then have a screen come up that asks you for your username and password. Only enter your username, not \"@legion.rc.ucl.ac.uk\". The password field will remain entirely blank when you enter it - it does not show placeholders to indicate you have typed something.","title":"Using PuTTY"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#login-problems","text":"If you experience difficulties with your login, please make sure that you are typing your UCL user ID and your password correctly. If you still cannot get access but can access other UCL services like Socrates, please contact us on rc-support@ucl.ac.uk . If you cannot access anything, please see UCL MyAccount - you may need to request a password reset from the Service Desk.","title":"Login problems"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#accessing-services-from-outside-ucl","text":"If you wish to access any of our machines from outside UCL, you cannot do so directly as they are behind UCL's firewall. To do so you will have to either use ssh to connect to UCL's gateway first: ssh ccaaxyz@socrates.ucl.ac.uk and from there connect to the correct host as described above, or login first to your departmental gateway (if you have one) and then login from there.","title":"Accessing services from outside UCL"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#is-vpn-service","text":"Alternatively, you can use the IS VPN service to connect to UCL using a virtual private network. That way, once the connection has been established, you can establish an ssh connection to the host machine directly, for example: ssh ccaaxyz@legion.rc.ucl.ac.uk","title":"IS VPN Service"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#running-graphical-applications-using-x-forwarding","text":"X-forwarding allows users to run a graphical program on a remote computer and display the user interface on their own computer.","title":"Running graphical applications using X-forwarding"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#x-forwarding-on-linux","text":"If you wish to have X-windows functionality enabled you have to make sure that you add either the -X or -Y flags (see man ssh for details) on all ssh commands you have to run to establish a connection to Legion. For example, connecting from outside of UCL: ssh -X ccaaxyz@socrates.ucl.ac.uk and then ssh -X ccaaxyz@legion.rc.ucl.ac.uk","title":"X-forwarding on Linux"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#x-forwarding-on-mac-os-x","text":"You will need to install XQuartz to provide an X-Window System for Mac OS X. (Previously known as X11.app). You can then follow the Linux instructions using Terminal.app.","title":"X-forwarding on Mac OS X"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#x-forwarding-on-windows","text":"You will need: An SSH client; e.g., PuTTY An X server program; e.g., Exceed, Xming Exceed is available on Desktop@UCL machines and downloadable from the UCL software database . Xming is open source (and mentioned here without testing).","title":"X-forwarding on Windows"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#exceed-on-desktopucl","text":"Load Exceed. You can find it under Start > All Programs > Applications O-P > Open Text Exceed 14 > Exceed Open PuTTY (Applications O-P > PuTTY) In PuTTY, set up the connection with the host machine as usual: Host name: legion.rc.ucl.ac.uk (for example) Port: 22 Connection type: SSH Then, from the Category menu, select Connection > SSH > X11 for 'Options controlling SSH X11 forwarding' Make sure the box marked 'Enable X11 forwarding' is checked. Return to the session menu and save these settings with a new identifiable name for reuse in future. Click 'Open' and login to the host as usual To test that X-forwarding is working try one of these test applications: nedit: a text editor xeyes: to bring up a set of eyes that track the mouse position on the screen glxgears: to bring up an animated set of gears xclock: a clock If these work, you have successfully enabled X forwarding for graphical applications. (Note they may not be available on all systems).","title":"Exceed on Desktop@UCL"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#installing-xming-on-your-own-computer","text":"Xming is a popular open source X server for Windows. These are instructions for using it alongside PuTTY. Other SSH clients and X servers are available. We cannot verify how well it may be working. Install both PuTTY and Xming if you have not done so already. During Xming installation, choose not to install an SSH client. Open Xming - the Xming icon should appear on the task bar. Open PuTTY Set up PuTTY as shown in the Exceed section.","title":"Installing Xming on your own computer"},{"location":"Wiki_Export/done/Accessing_RC_Systems/#transferring-files","text":"Read on to Managing data on RC systems .","title":"Transferring files"},{"location":"Wiki_Export/done/Account_Services/","text":"Information about how to apply for an account to use available Research Computing services is provided below. Internal UCL Clusters \u00b6 We have a single simplified application process for access to the Legion, Myriad, and Grace clusters. Use of these services is subject to a common set of terms and conditions . All applications currently cover a Legion and Myriad account while access to other systems depends on the resources you apply for. We also run clusters that serve particular user groups including users from outside UCL. For information about apply for accounts on those resources, please see their information pages: Molecular Modelling and Materials Hub -- Thomas Molecular Modelling and Materials Hub -- Michael Account sponsors \u00b6 If you are a student or postdoctoral researcher, your application must be approved by a permanent member of staff (normally your supervisor or PI). You will need to enter the UCL username (e.g. ccaaxyz, not the UPI) of this sponsor in the application form, and an email will be sent to this person asking them to approve the application before the account can be created. Permanent members of staff do not need a sponsor and their accounts will be automatically approved. You will need a UCL userid and password. Apply for an account \u00b6 The online application form can be found here: User account application form (UCL login required via Shibboleth) Application process \u00b6 The application process then runs as follows: Enter your UCL userid and password to access the application form. Complete the application form, reading the instructions carefully. Tip: Hover your mouse over text boxes for more information. Upon completion, your nominated sponsor will receive an email asking for the application to be approved. (If they do not receive this, contact rc-support@ucl.ac.uk). If you do not require a sponsor, your account will be automatically approved. Your sponsor should click on the link in the email and approve the account. You will receive an email when your account is approved if you have a sponsor. You should receive an email once we have created your account. Please note that there may be a delay of up to one working day between an application being approved and it being created. If your sponsor does not receive the email, you can send them the link to your application directly (will look like https://signup.rc.ucl.ac.uk/computing/requests/0000 ). Accounts for visitors \u00b6 Applications for UCL visitors to use Research Computing services are welcomed. Please note that: Applicants must have a central UCL account. Queries about how to obtain a UCL account for visitors should be addressed, in the first instance, to your Departmental Administrator. Account applications should specify the UCL grant under which the work is being carried out, if possible, as well as an associated UCL group or researcher. Account applications may not be submitted on behalf of another except to cover accessibility requirements, as the account application process includes agreeing to relevant legal terms and conditions. Accounts for honorary staff \u00b6 UCL Staff Members may sponsor Honorary members (named individuals) to be provided with access to Research Computing services where this is beneficial to UCL\u2019s research interests. This application process is identical to the process above for students and non-permanent staff. All accounts thus provided are subject to all other \u2018standard\u2019 T\\&C\u2019s relating to their use of Research Computing services. Charges for use of research computing services \u00b6 No direct charges are currently applicable for non-exceptional use of any Research Computing services in accordance with standard resource allocation policy as defined by the CRAG . Several methods are available to researchers who wish to gain access to additional resources, or obtain 'priority' use, including chargeable options. Details are available here .","title":"Account Services"},{"location":"Wiki_Export/done/Account_Services/#internal-ucl-clusters","text":"We have a single simplified application process for access to the Legion, Myriad, and Grace clusters. Use of these services is subject to a common set of terms and conditions . All applications currently cover a Legion and Myriad account while access to other systems depends on the resources you apply for. We also run clusters that serve particular user groups including users from outside UCL. For information about apply for accounts on those resources, please see their information pages: Molecular Modelling and Materials Hub -- Thomas Molecular Modelling and Materials Hub -- Michael","title":"Internal UCL Clusters"},{"location":"Wiki_Export/done/Account_Services/#account-sponsors","text":"If you are a student or postdoctoral researcher, your application must be approved by a permanent member of staff (normally your supervisor or PI). You will need to enter the UCL username (e.g. ccaaxyz, not the UPI) of this sponsor in the application form, and an email will be sent to this person asking them to approve the application before the account can be created. Permanent members of staff do not need a sponsor and their accounts will be automatically approved. You will need a UCL userid and password.","title":"Account sponsors"},{"location":"Wiki_Export/done/Account_Services/#apply-for-an-account","text":"The online application form can be found here: User account application form (UCL login required via Shibboleth)","title":"Apply for an account"},{"location":"Wiki_Export/done/Account_Services/#application-process","text":"The application process then runs as follows: Enter your UCL userid and password to access the application form. Complete the application form, reading the instructions carefully. Tip: Hover your mouse over text boxes for more information. Upon completion, your nominated sponsor will receive an email asking for the application to be approved. (If they do not receive this, contact rc-support@ucl.ac.uk). If you do not require a sponsor, your account will be automatically approved. Your sponsor should click on the link in the email and approve the account. You will receive an email when your account is approved if you have a sponsor. You should receive an email once we have created your account. Please note that there may be a delay of up to one working day between an application being approved and it being created. If your sponsor does not receive the email, you can send them the link to your application directly (will look like https://signup.rc.ucl.ac.uk/computing/requests/0000 ).","title":"Application process"},{"location":"Wiki_Export/done/Account_Services/#accounts-for-visitors","text":"Applications for UCL visitors to use Research Computing services are welcomed. Please note that: Applicants must have a central UCL account. Queries about how to obtain a UCL account for visitors should be addressed, in the first instance, to your Departmental Administrator. Account applications should specify the UCL grant under which the work is being carried out, if possible, as well as an associated UCL group or researcher. Account applications may not be submitted on behalf of another except to cover accessibility requirements, as the account application process includes agreeing to relevant legal terms and conditions.","title":"Accounts for visitors"},{"location":"Wiki_Export/done/Account_Services/#accounts-for-honorary-staff","text":"UCL Staff Members may sponsor Honorary members (named individuals) to be provided with access to Research Computing services where this is beneficial to UCL\u2019s research interests. This application process is identical to the process above for students and non-permanent staff. All accounts thus provided are subject to all other \u2018standard\u2019 T\\&C\u2019s relating to their use of Research Computing services.","title":"Accounts for honorary staff"},{"location":"Wiki_Export/done/Account_Services/#charges-for-use-of-research-computing-services","text":"No direct charges are currently applicable for non-exceptional use of any Research Computing services in accordance with standard resource allocation policy as defined by the CRAG . Several methods are available to researchers who wish to gain access to additional resources, or obtain 'priority' use, including chargeable options. Details are available here .","title":"Charges for use of research computing services"},{"location":"Wiki_Export/done/Acknowledging_RC_Systems/","text":"When preparing papers describing work that has been run on RC systems, please ensure that you use the following words to acknowledge use of the service: Legion \u00b6 \"The authors acknowledge the use of the UCL Legion High Performance Computing Facility (Legion@UCL), and associated support services, in the completion of this work.\" Myriad \u00b6 \"The authors acknowledge the use of the UCL Myriad High Performance Computing Facility (Myriad@UCL), and associated support services, in the completion of this work.\" Grace \u00b6 \"The authors acknowledge the use of the UCL Grace High Performance Computing Facility (Grace@UCL), and associated support services, in the completion of this work.\" Aristotle \u00b6 \"The authors acknowledge the use of the UCL Aristotle Computing Facility (Aristotle@UCL), and associated support services, in the completion of this work.\" Thomas \u00b6 Please find the wording at Acknowledging the use of Thomas in publications . Please ensure that you use the wording as above, most importantly the character string \" service @UCL\", so that publications arising from use of the service can be readily found using simple search methods and tools.","title":"Acknowledging the Use of RC Systems"},{"location":"Wiki_Export/done/Acknowledging_RC_Systems/#legion","text":"\"The authors acknowledge the use of the UCL Legion High Performance Computing Facility (Legion@UCL), and associated support services, in the completion of this work.\"","title":"Legion"},{"location":"Wiki_Export/done/Acknowledging_RC_Systems/#myriad","text":"\"The authors acknowledge the use of the UCL Myriad High Performance Computing Facility (Myriad@UCL), and associated support services, in the completion of this work.\"","title":"Myriad"},{"location":"Wiki_Export/done/Acknowledging_RC_Systems/#grace","text":"\"The authors acknowledge the use of the UCL Grace High Performance Computing Facility (Grace@UCL), and associated support services, in the completion of this work.\"","title":"Grace"},{"location":"Wiki_Export/done/Acknowledging_RC_Systems/#aristotle","text":"\"The authors acknowledge the use of the UCL Aristotle Computing Facility (Aristotle@UCL), and associated support services, in the completion of this work.\"","title":"Aristotle"},{"location":"Wiki_Export/done/Acknowledging_RC_Systems/#thomas","text":"Please find the wording at Acknowledging the use of Thomas in publications . Please ensure that you use the wording as above, most importantly the character string \" service @UCL\", so that publications arising from use of the service can be readily found using simple search methods and tools.","title":"Thomas"},{"location":"Wiki_Export/done/Additional_Resource_Requests/","text":"We recognise that researchers may sometimes require a higher throughput of work than it is possible to achieve with free \u2018fair share\u2019 usage of Legion. There a couple of ways of obtaining additional Legion resource beyond this fair share: Make a special request to the CRAG for free access to additional resources \u00b6 Users who wish to request additional resources or reserve resources beyond those provided can complete the additional resource request form in collaboration with your supervisor or the project's principal investigator. This includes requests for increased storage quotas. The completed form should be sent to the Research Computing Platforms team at rc-support@ucl.ac.uk , for technical review. If successful, your case will be presented to the CRAG for consideration at the next meeting of the Group. The CRAG meets monthly, usually on the third Friday of the month, and users will be informed of the Group\u2019s decision as soon as possible after their next meeting. Note that an application to the CRAG for additional resources is only likely to be approved if the impact on other users is not deemed to be significant, or of long duration. Additional resource request form Request hosting of shared datasets \u00b6 We have provision for hosting shared datasets for users on Myriad. These can be datasets that are freely accessible by all users, or ones limited to groups. Hosted datasets: Will not be backed up. Must have a named primary contact. Must be reapplied for every 12 months to make sure they are still current and required. Will have an associated quota. Will be removed when renewal lapses (notice will be given). They are likely to be managed by a role account - access to the role account will be by ssh key. To apply for a hosted dataset, please send this form to rc-support@ucl.ac.uk . Hosted dataset request form Purchase dedicated compute nodes within Legion or Myriad \u00b6 There has previously been a programme allowing researchers to purchase compute nodes to be attached to the Legion cluster. This has been discontinued, while the new Myriad cluster is installed and configured, as Myriad will replace the Legion cluster for the majority of users. There are plans to allow the purchase of nodes for Myriad in future but these have not yet been finalised. Further information \u00b6 For further advice or information on future hardware options, please contact rits@ucl.ac.uk .","title":"Additional Resource Requests"},{"location":"Wiki_Export/done/Additional_Resource_Requests/#make-a-special-request-to-the-crag-for-free-access-to-additional-resources","text":"Users who wish to request additional resources or reserve resources beyond those provided can complete the additional resource request form in collaboration with your supervisor or the project's principal investigator. This includes requests for increased storage quotas. The completed form should be sent to the Research Computing Platforms team at rc-support@ucl.ac.uk , for technical review. If successful, your case will be presented to the CRAG for consideration at the next meeting of the Group. The CRAG meets monthly, usually on the third Friday of the month, and users will be informed of the Group\u2019s decision as soon as possible after their next meeting. Note that an application to the CRAG for additional resources is only likely to be approved if the impact on other users is not deemed to be significant, or of long duration. Additional resource request form","title":"Make a special request to the CRAG for free access to additional resources"},{"location":"Wiki_Export/done/Additional_Resource_Requests/#request-hosting-of-shared-datasets","text":"We have provision for hosting shared datasets for users on Myriad. These can be datasets that are freely accessible by all users, or ones limited to groups. Hosted datasets: Will not be backed up. Must have a named primary contact. Must be reapplied for every 12 months to make sure they are still current and required. Will have an associated quota. Will be removed when renewal lapses (notice will be given). They are likely to be managed by a role account - access to the role account will be by ssh key. To apply for a hosted dataset, please send this form to rc-support@ucl.ac.uk . Hosted dataset request form","title":"Request hosting of shared datasets"},{"location":"Wiki_Export/done/Additional_Resource_Requests/#purchase-dedicated-compute-nodes-within-legion-or-myriad","text":"There has previously been a programme allowing researchers to purchase compute nodes to be attached to the Legion cluster. This has been discontinued, while the new Myriad cluster is installed and configured, as Myriad will replace the Legion cluster for the majority of users. There are plans to allow the purchase of nodes for Myriad in future but these have not yet been finalised.","title":"Purchase dedicated compute nodes within Legion or Myriad"},{"location":"Wiki_Export/done/Additional_Resource_Requests/#further-information","text":"For further advice or information on future hardware options, please contact rits@ucl.ac.uk .","title":"Further information"},{"location":"Wiki_Export/done/Aristotle/","text":"Overview \u00b6 Aristotle is a stop-gap interactive service for teaching running on a pair of nodes of the same specification as Legion's U-type nodes , each with 64 gigabytes of RAM and 16 cores. The machines run RHEL 7 and have a subset of the RCPS software stack available. The main aim of this service is to allow specific teaching courses to run that need to run Unix applications and have outgrown the Socrates service. Access \u00b6 Anyone with a UCL userid and within the UCL institutional firewall can access Aristotle by connecting via ssh to: aristotle.rc.ucl.ac.uk This address can point to more than one actual server (via DNS round-robin); usually there are two available. To connect to a specific server from the set, you will need to know its number: for example, the second server has the address aristotle02.rc.ucl.ac.uk . When you connect, you should be shown which one you are connected to on your command line. The userid and password you need to connect with are those provided to you by Information Services Division . If you experience difficulties with your login, please make sure that you are typing your UCL user ID and your password correctly. If you still cannot get access, please contact us at rc-support@ucl.ac.uk . If you are outside the UCL firewall, you will need to connect to Socrates first, as with our main UCL clusters . User Environment \u00b6 Aristotle runs Red Hat Enterprise Linux 7 and NFS mounts the RCPS Software Stack . As this machine is intended for teaching, work has focused on getting specific applications required for specific courses to work and these are: SAC Phon GMT Fortran compilers (of which there are a large variety) Packages are available through modules and users should consult the relevant modules documentation .","title":"Aristotle"},{"location":"Wiki_Export/done/Aristotle/#overview","text":"Aristotle is a stop-gap interactive service for teaching running on a pair of nodes of the same specification as Legion's U-type nodes , each with 64 gigabytes of RAM and 16 cores. The machines run RHEL 7 and have a subset of the RCPS software stack available. The main aim of this service is to allow specific teaching courses to run that need to run Unix applications and have outgrown the Socrates service.","title":"Overview"},{"location":"Wiki_Export/done/Aristotle/#access","text":"Anyone with a UCL userid and within the UCL institutional firewall can access Aristotle by connecting via ssh to: aristotle.rc.ucl.ac.uk This address can point to more than one actual server (via DNS round-robin); usually there are two available. To connect to a specific server from the set, you will need to know its number: for example, the second server has the address aristotle02.rc.ucl.ac.uk . When you connect, you should be shown which one you are connected to on your command line. The userid and password you need to connect with are those provided to you by Information Services Division . If you experience difficulties with your login, please make sure that you are typing your UCL user ID and your password correctly. If you still cannot get access, please contact us at rc-support@ucl.ac.uk . If you are outside the UCL firewall, you will need to connect to Socrates first, as with our main UCL clusters .","title":"Access"},{"location":"Wiki_Export/done/Aristotle/#user-environment","text":"Aristotle runs Red Hat Enterprise Linux 7 and NFS mounts the RCPS Software Stack . As this machine is intended for teaching, work has focused on getting specific applications required for specific courses to work and these are: SAC Phon GMT Fortran compilers (of which there are a large variety) Packages are available through modules and users should consult the relevant modules documentation .","title":"User Environment"},{"location":"Wiki_Export/done/Batch_Processing/","text":"When running jobs on Legion or Grace, users need to interact with the batch system. For users unfamiliar with HPC environments, this can be a way of working which is unfamiliar to them. What is a batch system? \u00b6 On a large, multi-user machine like Legion many users compete for relatively limited resources. There are two possible ways of organising access to this resource: Either allow everyone to run anything they want when they want but run the risk of people\u2019s jobs interfering with each other or else construct a system where users are allocated resources in turn. This is called a \"batch\" system. In a batch system, users submit their programs with a script to run them and a list of requirements and these jobs are run when resources are available. On Legion, the order jobs are run in is subject to a fair use policy which is discussed in the scheduling policy section. On other sites, users may be billed for their usage and most batch systems provide features for managing accounting in this scenario. When a user uses a batch system, they need to remember a number of important things. The first is that (with some exceptions) their jobs are not interactive. This means that a user must provide their application with inputs in advance (and if they are a developer design their program to operate in this manner). This means that some applications are not suitable for running in a batch system (visualisation for example). In most systems, each job is given a unique ID by the scheduler and this ID is used when interacting with jobs once they have been submitted. Once jobs have been submitted, users can log out and their jobs will execute even though they are not logged in. The second important thing to remember is that once a job has been submitted, a user has little control of when the job is actually run, because the time to completion (from submission) depends on how busy the machine is. It is therefore necessary for users to plan ahead and submit their jobs in a timely manner, rather than waiting until the last minute. Basic commands \u00b6 There are three basic commonly used commands in any batch system - one for submitting jobs, one for checking the status of jobs and one for deleting jobs. On Sun Grid Engine, these are qsub, qstat and qdel. qsub \u00b6 The qsub command submits your job to the batch queue. qsub myscript.sh You can override the settings in your script by specifying them on the command-line, so for example if you want to change the name of the job for this one instance of the job you can submit your script with: qsub -N NewName myscript.sh Or if you want to increase the wall-clock time to 24 hours: qsub -l h_rt=24:0:0 myscript.sh You can submit jobs with dependencies by using the -hold_jid option. For example, the command below submits a job that won't run until job 12345 has finished: qsub -hold_jid 12345 myscript.sh You may specify node type (see Resource Allocation section for more details) with the -ac allow= flags as below: qsub -ac allow=XYZ myscript.sh The example above would restrict the job to running on the older nodes. Note that for debugging purposes, it helps us if you have these options inside your jobscript rather than passed in on the command line, if possible. We can see your jobscript but not what command line you submitted with. qstat \u00b6 The qstat command shows the status of your jobs. By default, if you run it with no options, it shows only your jobs (and no-one else\u2019s). This makes it easier to keep track of your jobs. If you want to get more information on a particular job, note its job ID and then use the -f and -j flags to get full output about that job: `qstat -f -j 12345` If you see that your job is in Eqw state then an error occurred before your job could begin. You can see a truncated version of the error in the output of qstat -j - this is often enough to tell what the problem is if it is a file or directory not found. You can get the full error with qexplain . qexplain 12345 qdel \u00b6 The qdel command lets you delete a job from the queue. You need to provide qdel with a job ID like so: qdel 12345 You can delete all your jobs with: qdel '*' If you wish to learn about additional commands, please run the command \"man qstat\" and take note of the commands shown in the \"SEE ALSO\" section of the manual page. Exit the manual page and then run the \"man\" command on those. If you cannot find the information you need in the man pages, then contact us at rc-support@ucl.ac.uk for assistance.","title":"An introduction to batch processing"},{"location":"Wiki_Export/done/Batch_Processing/#what-is-a-batch-system","text":"On a large, multi-user machine like Legion many users compete for relatively limited resources. There are two possible ways of organising access to this resource: Either allow everyone to run anything they want when they want but run the risk of people\u2019s jobs interfering with each other or else construct a system where users are allocated resources in turn. This is called a \"batch\" system. In a batch system, users submit their programs with a script to run them and a list of requirements and these jobs are run when resources are available. On Legion, the order jobs are run in is subject to a fair use policy which is discussed in the scheduling policy section. On other sites, users may be billed for their usage and most batch systems provide features for managing accounting in this scenario. When a user uses a batch system, they need to remember a number of important things. The first is that (with some exceptions) their jobs are not interactive. This means that a user must provide their application with inputs in advance (and if they are a developer design their program to operate in this manner). This means that some applications are not suitable for running in a batch system (visualisation for example). In most systems, each job is given a unique ID by the scheduler and this ID is used when interacting with jobs once they have been submitted. Once jobs have been submitted, users can log out and their jobs will execute even though they are not logged in. The second important thing to remember is that once a job has been submitted, a user has little control of when the job is actually run, because the time to completion (from submission) depends on how busy the machine is. It is therefore necessary for users to plan ahead and submit their jobs in a timely manner, rather than waiting until the last minute.","title":"What is a batch system?"},{"location":"Wiki_Export/done/Batch_Processing/#basic-commands","text":"There are three basic commonly used commands in any batch system - one for submitting jobs, one for checking the status of jobs and one for deleting jobs. On Sun Grid Engine, these are qsub, qstat and qdel.","title":"Basic commands"},{"location":"Wiki_Export/done/Batch_Processing/#qsub","text":"The qsub command submits your job to the batch queue. qsub myscript.sh You can override the settings in your script by specifying them on the command-line, so for example if you want to change the name of the job for this one instance of the job you can submit your script with: qsub -N NewName myscript.sh Or if you want to increase the wall-clock time to 24 hours: qsub -l h_rt=24:0:0 myscript.sh You can submit jobs with dependencies by using the -hold_jid option. For example, the command below submits a job that won't run until job 12345 has finished: qsub -hold_jid 12345 myscript.sh You may specify node type (see Resource Allocation section for more details) with the -ac allow= flags as below: qsub -ac allow=XYZ myscript.sh The example above would restrict the job to running on the older nodes. Note that for debugging purposes, it helps us if you have these options inside your jobscript rather than passed in on the command line, if possible. We can see your jobscript but not what command line you submitted with.","title":"qsub"},{"location":"Wiki_Export/done/Batch_Processing/#qstat","text":"The qstat command shows the status of your jobs. By default, if you run it with no options, it shows only your jobs (and no-one else\u2019s). This makes it easier to keep track of your jobs. If you want to get more information on a particular job, note its job ID and then use the -f and -j flags to get full output about that job: `qstat -f -j 12345` If you see that your job is in Eqw state then an error occurred before your job could begin. You can see a truncated version of the error in the output of qstat -j - this is often enough to tell what the problem is if it is a file or directory not found. You can get the full error with qexplain . qexplain 12345","title":"qstat"},{"location":"Wiki_Export/done/Batch_Processing/#qdel","text":"The qdel command lets you delete a job from the queue. You need to provide qdel with a job ID like so: qdel 12345 You can delete all your jobs with: qdel '*' If you wish to learn about additional commands, please run the command \"man qstat\" and take note of the commands shown in the \"SEE ALSO\" section of the manual page. Exit the manual page and then run the \"man\" command on those. If you cannot find the information you need in the man pages, then contact us at rc-support@ucl.ac.uk for assistance.","title":"qdel"},{"location":"Wiki_Export/done/Building_and_Running_Matlab_Programs/","text":"Before you start, here are the caveats: \u00b6 Although full Matlab is now available on Legion, you can still compile Matlab programs on an external machine and then run them on Legion using the Matlab runtime. Your Matlab program must be compiled using a 64bit Linux version of the Matlab compiler; the compiled code is not cross-platform compatible so it cannot be built on OS X and then transferred to Legion. Piping code into the Matlab compiler will not work, and the main routine being executed must be converted into a proper Matlab function. When arguments are passed into compiled Matlab executable, the compiled code does not automatically convert them to the required type (i.e. float or integer) as Matlab does from the command line. In this case the arguments, where necessary, must be converted to numbers using the str2num() function. Because of the way Matlab threads work, you must request exclusive access to Legion nodes when running compiled Matlab programs. Compiling your program: \u00b6 The Matlab code is must be compiled using the mcc tool; this must be initially run as mcc -setup before anything is built. The mcc tool can actually be invoked from the interpreter command prompt and executing help mcc will give you quite a lot of information about how to use the tool, along with examples. All .m files must be built into the compiled code with the first .m referenced in the build line acting as the main entry point for the built code. It may be useful to include data files in the built code which are handled in the build line using the -a <datafile> option. Please remember to make the .m file an actual function and all other dependencies sub-functions, otherwise the compiled code will not execute. Some important mcc options: \u00b6 -m : this is option which runs the macro to generate a C stand-alone application. -R : specify runtime options for the Matlab compiler runtime. Some important runtime options: \u00b6 -nojvm : disables the java virtual machine, which may speed-up certain codes. This option cannot be used if you are planning to have, for example pdf files or any other plots produced as output of your run. -nodisplay : prevents anything being displayed on the screen, can be useful if this happens with the application as this would not work correctly in batch mode. --singleCompThread : use only a single computational thread, otherwise Matlab will try to use more than one thread when the operation being performed supports multi threading. This is an alternative to allocating a whole Legion node to your job. Once the application has been built, there should be an executable named after the prefix of the .m file, generally <app name>.m , and a shell script with the name run\\_<app name>.sh - both these files need to be transferred to Legion. We have installed a runtime environment on Legion here: /shared/ucl/apps/Matlab/R2011a/Runtime7.15/v715/ If you have been given pre-compiled code by someone else, the application may not work as the Matlab runtime version must reasonably match that of the Matlab compiler that was used to build the application. The runtime is freely distributable and can be found in the installation directory of Matlab. The runtime has a GUI install interface and it can be installed at any location in your home directory. For more information, please read your Matlab documentation. Job submission scripts: \u00b6 There are three things that you must take into account: The location of the Matlab compiler runtime needs to be passed to the script used to run the compiled Matlab code as the first argument. The compiler runtime needs a directory (cache) to unpack files to when it is running. By default this directory is in the home folder. This needs to be changed since the home directory is not writable in Legion from the compute nodes. Since the Matlab runs will be single node jobs, the cache location should be in the storage on the compute nodes which is stored in TMPDIR . Use the -ac exclusive SGE option to request exclusive access to a Legion node unless you use the --singleCompThread Matlab option. For example, a multi-threaded serial script should look something like: #!/bin/bash -l # Batch script to run a serial job on Legion with the upgraded # software stack under SGE. # Force bash as the executing shell. #$ -S /bin/bash # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM #$ -l mem=1G # Select 12 threads (the most possible on Legion). #$ -l thr=12 # The way Matlab threads work requires Matlab to not share nodes with other # jobs. #$ -ac exclusive # Set the name of the job. #$ -N Matlab_Job_1 # Set the working directory to somewhere in your scratch space. This is # a necessary step with the upgraded software stack as compute nodes cannot # write to $HOME. For example: ##$ -wd /home//Scratch # Alternatively, launch your job from anywhere *within ~/Scratch* #$ -cwd # store the MATLAB runtime path in a global environment variable (MCR_HOME) export MCR_HOME = /shared/ucl/apps/Matlab/R2011a/Runtime7.15/v715/ # the path to the Matlab cache is stored in the global variable MCR_CACHE_ROOT export MCR_CACHE_ROOT = $TMPDIR /mcr_cache # make sure the directory in MCR_CACHE_ROOT exists mkdir -p $MCR_CACHE_ROOT # Run the executable, passing the path stored in MCR_HOME as the first argument. # There is no need to pass the content of MCR_CACHE_ROOT as an argument to the # to the run_appname.sh script since it is a variable that the Matlab runtime is aware of. ./run_appname.sh $MCR_HOME [ arguments list ] # Preferably, tar-up (archive) all output files onto the shared scratch area tar zcvf $HOME /Scratch/files_from_job_ ${ JOB_ID } .tgz $TMPDIR # Make sure you have given enough time for the copy to complete! For any queries and problem reports, please contact rc-support@ucl.ac.uk .","title":"Building and Running Matlab Programs"},{"location":"Wiki_Export/done/Building_and_Running_Matlab_Programs/#before-you-start-here-are-the-caveats","text":"Although full Matlab is now available on Legion, you can still compile Matlab programs on an external machine and then run them on Legion using the Matlab runtime. Your Matlab program must be compiled using a 64bit Linux version of the Matlab compiler; the compiled code is not cross-platform compatible so it cannot be built on OS X and then transferred to Legion. Piping code into the Matlab compiler will not work, and the main routine being executed must be converted into a proper Matlab function. When arguments are passed into compiled Matlab executable, the compiled code does not automatically convert them to the required type (i.e. float or integer) as Matlab does from the command line. In this case the arguments, where necessary, must be converted to numbers using the str2num() function. Because of the way Matlab threads work, you must request exclusive access to Legion nodes when running compiled Matlab programs.","title":"Before you start, here are the caveats:"},{"location":"Wiki_Export/done/Building_and_Running_Matlab_Programs/#compiling-your-program","text":"The Matlab code is must be compiled using the mcc tool; this must be initially run as mcc -setup before anything is built. The mcc tool can actually be invoked from the interpreter command prompt and executing help mcc will give you quite a lot of information about how to use the tool, along with examples. All .m files must be built into the compiled code with the first .m referenced in the build line acting as the main entry point for the built code. It may be useful to include data files in the built code which are handled in the build line using the -a <datafile> option. Please remember to make the .m file an actual function and all other dependencies sub-functions, otherwise the compiled code will not execute.","title":"Compiling your program:"},{"location":"Wiki_Export/done/Building_and_Running_Matlab_Programs/#some-important-mcc-options","text":"-m : this is option which runs the macro to generate a C stand-alone application. -R : specify runtime options for the Matlab compiler runtime.","title":"Some important mcc options:"},{"location":"Wiki_Export/done/Building_and_Running_Matlab_Programs/#some-important-runtime-options","text":"-nojvm : disables the java virtual machine, which may speed-up certain codes. This option cannot be used if you are planning to have, for example pdf files or any other plots produced as output of your run. -nodisplay : prevents anything being displayed on the screen, can be useful if this happens with the application as this would not work correctly in batch mode. --singleCompThread : use only a single computational thread, otherwise Matlab will try to use more than one thread when the operation being performed supports multi threading. This is an alternative to allocating a whole Legion node to your job. Once the application has been built, there should be an executable named after the prefix of the .m file, generally <app name>.m , and a shell script with the name run\\_<app name>.sh - both these files need to be transferred to Legion. We have installed a runtime environment on Legion here: /shared/ucl/apps/Matlab/R2011a/Runtime7.15/v715/ If you have been given pre-compiled code by someone else, the application may not work as the Matlab runtime version must reasonably match that of the Matlab compiler that was used to build the application. The runtime is freely distributable and can be found in the installation directory of Matlab. The runtime has a GUI install interface and it can be installed at any location in your home directory. For more information, please read your Matlab documentation.","title":"Some important runtime options:"},{"location":"Wiki_Export/done/Building_and_Running_Matlab_Programs/#job-submission-scripts","text":"There are three things that you must take into account: The location of the Matlab compiler runtime needs to be passed to the script used to run the compiled Matlab code as the first argument. The compiler runtime needs a directory (cache) to unpack files to when it is running. By default this directory is in the home folder. This needs to be changed since the home directory is not writable in Legion from the compute nodes. Since the Matlab runs will be single node jobs, the cache location should be in the storage on the compute nodes which is stored in TMPDIR . Use the -ac exclusive SGE option to request exclusive access to a Legion node unless you use the --singleCompThread Matlab option. For example, a multi-threaded serial script should look something like: #!/bin/bash -l # Batch script to run a serial job on Legion with the upgraded # software stack under SGE. # Force bash as the executing shell. #$ -S /bin/bash # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM #$ -l mem=1G # Select 12 threads (the most possible on Legion). #$ -l thr=12 # The way Matlab threads work requires Matlab to not share nodes with other # jobs. #$ -ac exclusive # Set the name of the job. #$ -N Matlab_Job_1 # Set the working directory to somewhere in your scratch space. This is # a necessary step with the upgraded software stack as compute nodes cannot # write to $HOME. For example: ##$ -wd /home//Scratch # Alternatively, launch your job from anywhere *within ~/Scratch* #$ -cwd # store the MATLAB runtime path in a global environment variable (MCR_HOME) export MCR_HOME = /shared/ucl/apps/Matlab/R2011a/Runtime7.15/v715/ # the path to the Matlab cache is stored in the global variable MCR_CACHE_ROOT export MCR_CACHE_ROOT = $TMPDIR /mcr_cache # make sure the directory in MCR_CACHE_ROOT exists mkdir -p $MCR_CACHE_ROOT # Run the executable, passing the path stored in MCR_HOME as the first argument. # There is no need to pass the content of MCR_CACHE_ROOT as an argument to the # to the run_appname.sh script since it is a variable that the Matlab runtime is aware of. ./run_appname.sh $MCR_HOME [ arguments list ] # Preferably, tar-up (archive) all output files onto the shared scratch area tar zcvf $HOME /Scratch/files_from_job_ ${ JOB_ID } .tgz $TMPDIR # Make sure you have given enough time for the copy to complete! For any queries and problem reports, please contact rc-support@ucl.ac.uk .","title":"Job submission scripts:"},{"location":"Wiki_Export/done/Cluster_Computing/","text":"UCL has a number of centrally-funded compute cluster facilities available, aimed at supporting all types of research at UCL. Legion , a mixed-use cluster hosted in UCL's Bloomsbury datacentres. Myriad , another mixed-use cluster hosted in UCL's portion of the Virtus datacentre in Slough. Grace , a cluster designed for medium-scale parallel workloads, hosted in UCL's portion of the Virtus datacentre in Slough. What is a cluster? \u00b6 A cluster is a large array of PCs or servers, referred to as nodes , networked together and often with a shared filesystem. Commonly in a shared cluster facility, a scheduler is used to take work from users and assign it to servers or groups of servers to be run as discrete jobs . Jobs can use more than one core or even more than one node simultaneously, communicating over special, faster types of network where available, to allow many cores to divide up the work. So is this the same thing as a supercomputer? \u00b6 Sort of. The term \"supercomputer\" nowadays usually refers to a large cluster designed to be able to run a single job in parallel over the whole machine, with an extremely fast network, but in the past it was used as a catch-all term for a lot of computing installations more architecturally complex and power-hungry than an ordinary desktop computer or server. Why would a user choose to use a cluster? \u00b6 Clusters allow the use of many nodes simultaneously, without the user having to be present or to have a laptop or desktop computer in their office running all the time. This means that users can both run large parallel jobs and large numbers of serial jobs providing them with the ability to run jobs they cannot run locally, or get through work-loads that would be impractical on local resources. The clusters also have some nodes with more specialist hardware and some with extremely large quantities of RAM, allowing jobs that would be completely impossible on ordinary office machines. When should you not use a cluster? \u00b6 The vast majority of clusters run the Linux operating system rather than Windows. The central UCL clusters only run Linux, so if your applications only run on Windows, this service is not suitable for you. The available clusters are currently only x86_64-based (a.k.a. amd64, em64t), so if you need an alternative processor architecture (such as ARM or POWER), these are not suitable. Also, as these clusters are largely designed for work structured around using scripts, if your applications require you to enter commands while they're running, you will not be able to make full use of the service. (Some applications often look like they do but don't in practice, contact us if you're not sure.) What if I need more compute time/longer jobs/more storage? \u00b6 We recognise that researchers may sometimes require resources than the basic all-purpose allocation. Options for acquiring additional resources on a short or long term basis are described on the Additional Resource Requests page. Do I have to pay for any of this? \u00b6 The central UCL clusters are free at point of use for UCL researchers -- you don't pay for the compute time or storage you use. Other compute resources you may have to pay for. How do I get help? \u00b6 Any questions about the central UCL clusters should go to the Research Computing Support Team at rc-support@ucl.ac.uk . The team will respond to your question as quickly as possible, giving priority to requests that are deemed urgent on the basis of the information provided. Available 9:30am to 4:30pm, Monday to Friday, except on Bank Holidays and College Closures. We aim to provide you with a useful response within 24 hours. Please do not email individuals unless you are explicitly asked to do so; always use the rc-support email address provided. What if I need something totally different? \u00b6 Let us know your requirements and we may be able to suggest alternative computing facilities that you may be eligible to use. It will also allow us to take your needs into consideration for future acquisitions.","title":"Cluster Computing"},{"location":"Wiki_Export/done/Cluster_Computing/#what-is-a-cluster","text":"A cluster is a large array of PCs or servers, referred to as nodes , networked together and often with a shared filesystem. Commonly in a shared cluster facility, a scheduler is used to take work from users and assign it to servers or groups of servers to be run as discrete jobs . Jobs can use more than one core or even more than one node simultaneously, communicating over special, faster types of network where available, to allow many cores to divide up the work.","title":"What is a cluster?"},{"location":"Wiki_Export/done/Cluster_Computing/#so-is-this-the-same-thing-as-a-supercomputer","text":"Sort of. The term \"supercomputer\" nowadays usually refers to a large cluster designed to be able to run a single job in parallel over the whole machine, with an extremely fast network, but in the past it was used as a catch-all term for a lot of computing installations more architecturally complex and power-hungry than an ordinary desktop computer or server.","title":"So is this the same thing as a supercomputer?"},{"location":"Wiki_Export/done/Cluster_Computing/#why-would-a-user-choose-to-use-a-cluster","text":"Clusters allow the use of many nodes simultaneously, without the user having to be present or to have a laptop or desktop computer in their office running all the time. This means that users can both run large parallel jobs and large numbers of serial jobs providing them with the ability to run jobs they cannot run locally, or get through work-loads that would be impractical on local resources. The clusters also have some nodes with more specialist hardware and some with extremely large quantities of RAM, allowing jobs that would be completely impossible on ordinary office machines.","title":"Why would a user choose to use a cluster?"},{"location":"Wiki_Export/done/Cluster_Computing/#when-should-you-not-use-a-cluster","text":"The vast majority of clusters run the Linux operating system rather than Windows. The central UCL clusters only run Linux, so if your applications only run on Windows, this service is not suitable for you. The available clusters are currently only x86_64-based (a.k.a. amd64, em64t), so if you need an alternative processor architecture (such as ARM or POWER), these are not suitable. Also, as these clusters are largely designed for work structured around using scripts, if your applications require you to enter commands while they're running, you will not be able to make full use of the service. (Some applications often look like they do but don't in practice, contact us if you're not sure.)","title":"When should you not use a cluster?"},{"location":"Wiki_Export/done/Cluster_Computing/#what-if-i-need-more-compute-timelonger-jobsmore-storage","text":"We recognise that researchers may sometimes require resources than the basic all-purpose allocation. Options for acquiring additional resources on a short or long term basis are described on the Additional Resource Requests page.","title":"What if I need more compute time/longer jobs/more storage?"},{"location":"Wiki_Export/done/Cluster_Computing/#do-i-have-to-pay-for-any-of-this","text":"The central UCL clusters are free at point of use for UCL researchers -- you don't pay for the compute time or storage you use. Other compute resources you may have to pay for.","title":"Do I have to pay for any of this?"},{"location":"Wiki_Export/done/Cluster_Computing/#how-do-i-get-help","text":"Any questions about the central UCL clusters should go to the Research Computing Support Team at rc-support@ucl.ac.uk . The team will respond to your question as quickly as possible, giving priority to requests that are deemed urgent on the basis of the information provided. Available 9:30am to 4:30pm, Monday to Friday, except on Bank Holidays and College Closures. We aim to provide you with a useful response within 24 hours. Please do not email individuals unless you are explicitly asked to do so; always use the rc-support email address provided.","title":"How do I get help?"},{"location":"Wiki_Export/done/Cluster_Computing/#what-if-i-need-something-totally-different","text":"Let us know your requirements and we may be able to suggest alternative computing facilities that you may be eligible to use. It will also allow us to take your needs into consideration for future acquisitions.","title":"What if I need something totally different?"},{"location":"Wiki_Export/done/Compiling/","text":"Download your code \u00b6 Use wget or curl to download the source code for the software you want to install to your account. There might be binaries available, but they often won't work on our clusters because they were compiled for other machines with other library versions available. Use tar or unzip or similar depending on archive type to uncompress your source code. wget https://www.example.com/program.tar.gz tar -xvf program.tar.gz You won't be able to use a package manager like yum, you'll need to follow the manual installation instructions for a user-space install (not using sudo). Set up your modules \u00b6 Before you start compiling, you need to make sure you have the right compilers, libraries and other tools available for your software. If you haven't changed anything, you will have the default modules loaded. For more information on how to use modules, see RC Systems user environment . Check what the instructions for your software tell you about compiling it. If the website doesn't say much, the source code will hopefully have a README or INSTALL file. You may want to use a different compiler - the default is the Intel compiler. module avail compilers will show you all the compiler modules available. Most Open Source software tends to assume you're using GCC and OpenMPI (if it uses MPI) and is most tested with that combination, so if it doesn't specify you may want to begin there (do check what the newest modules available are): `module unload compilers mpi mkl` `module load compilers/gnu/4.9.2` `module load mpi/openmpi/1.10.1/gnu-4.9.2` Available compilers \u00b6 The following compilers are available and supported on Legion: Intel C, C++ and Fortran GNU C, C++ and Fortran We currently have a limited number of licenses for the Intel compilers so only a certain number of users can use them simultaneously. This means that your compilation may fail with an error complaining about not being able to obtain a valid license. If this happens, simply wait for a few minutes and try again. In addition to the supported tools, there are a number of tools installed on Legion which are not supported (for example the PGI compilers) which were installed to build certain supported packages. Users who use the unsupported packages do so at their own risk. Build systems \u00b6 Most software will use some kind of build system to manage how files are compiled and linked and in what order. Here are a few common ones. Automake configure \u00b6 Automake will generate the Makefile for you and hopefully pick up sensible options through configuration. You can give it an install prefix to tell it where to install (or you can build it in place and not use make install at all). ./configure --prefix=/home/username/place/you/want/to/install make # if it has a test suite, good idea to use it make test make install If it has more configuration flags, you can use ./configure --help to view them. Usually configure will create a config.log: you can look in there to find if any tests have failed or things you think should have been picked up haven't. CMake \u00b6 CMake is another build system. It will have a CMakeFile or the instructions will ask you to use cmake or ccmake rather than make. It also generates Makefiles for you. ccmake is a terminal-based interactive interface where you can see what variables are set to and change them, then repeatedly configure until everything is correct, generate the Makefile and quit. cmake is the commandline version. The process tends to go like this: ccmake CMakeLists.txt # press c to configure - will pick up some options # press t to toggle advanced options # keep making changes and configuring until no more errors or changes # press g to generate and exit make # if it has a test suite, good idea to use it make test make install If you need to rerun ccmake and reconfigure, remember to delete the CMakeCache.txt file, or you'll be wondering why your changes haven't taken. Turning on verbose Makefiles in ccmake is also useful if your code didn't compile first time - you'll be able to see what flags the compiler or linker is actually being given when it fails. Make \u00b6 Your code may just come with a Makefile and have no configure, in which case the generic way to compile it is as follows: make targetname There's usually a default target, which make on its own will use. If you need to change any configuration options, you'll need to edit those sections of the Makefile (at the top, where the variables/flags are defined). Here are some typical variables you may want to change in a Makefile. These are what compilers/mpi wrappers to use - these are also defined by the compiler modules, so you can see what they should be. Intel would be icc, icpc, ifort, for example. If it's a program that can be compiled using MPI and only has a variable for CC, then set that to mpicc. CC=gcc CXX=g++ FC=gfortran MPICC=mpicc MPICXX=mpicxx MPIF90=mpif90 CFLAGS and LDFLAGS are flags for the compiler and linker respectively, and there might be LIBS or INCLUDE as well. When linking a library with the name libfoo, use -lfoo . CFLAGS=\"-I/path/to/include\" LDFLAGS=\"-L/path/to/foo/lib -L/path/to/bar/lib\" LDLIBS=\"-lfoo -lbar\" Remember to make clean first if you are recompiling with new options! AVX instructions \u00b6 Note : Legion's current login nodes are of a newer architecture than some of the compute nodes - the login nodes have AVX instructions but the XYZ type nodes do not. This means if you want your code to run on the older nodes, some compiler options cannot be used (e.g. -march=native , -mtune , -xHost ) or your code will segfault. You can either build the code on the login nodes and restrict your jobs to only running on the newer nodes, compile the code with appropriate options for all the nodes, or compile your code inside a job that is running on the XYZ nodes (or during a qrsh session on the same). Intel compilers \u00b6 To tell the Intel compilers to build for SSE4.2 instructions and no AVX, add this to CFLAGS (and CXXFLAGS if relevant): `CFLAGS=-axSSE4.2` (Also see icc -help codegen ). GNU compilers \u00b6 To tell GCC to build for SSE4.2 without AVX, add this to CFLAGS (and CXXFLAGS if relevant): `CFLAGS=-march=nehalem` Restrict node type \u00b6 To restrict a job to newer nodes only, put this in your script: #$ -ac allow=LMNOPQSTU You can also compile one version without AVX and one with, so you can take advantage of the newer nodes when possible. You could use hostname in your jobscript to check what type of node you were on and run the appropriate binary. Hostnames begin with node-x for an X-type node, node-u for a U-type and so on. Test for AVX \u00b6 We have a script that will let you test whether your compiled code is using AVX instructions. If you pass it a directory it will recursively test everything in there. Note that if your code builds multiple kernels and so can choose based on where it runs which instructions to use (like MKL) then this will find AVX instructions but they won't cause your code to segfault. `find /home/username/path/ -perm /111 -type f | xargs /shared/ucl/apps/rcops_scripts/hasavx -q` BLAS and LAPACK \u00b6 BLAS and LAPACK are provided as part of MKL, OpenBLAS or ATLAS. There are several different OpenBLAS and ATLAS modules on Legion for different compilers. MKL is available in the Intel compiler module. Your code may try to link -lblas -llapack : this isn't the right way to use BLAS and LAPACK with MKL or ATLAS (our OpenBLAS now has symlinks that allow you to do this). MKL on Legion OpenBLAS on Legion ATLAS on Legion Set your PATH and other environment variables \u00b6 After you have installed your software, you'll need to add it to your PATH environment variable so you can run it without having to give the full path to its location. Put this in your ~/.bashrc file so it will set this with every new session you create. Replace username with your username and point to the directory your binary was built in (frequently program/bin ). This adds it to the front of your PATH, so if you install a newer version of something, it will be found before the system one. `export PATH=/home/username/location/of/software/binary:$PATH` If you built a library that you'll go on to compile other software with, you probably want to also add the lib directory to your LD_LIBRARY_PATH and LIBRARY_PATH, and the include directory to CPATH (add export statements as above). This may mean your configure step will pick your library up correctly without any further effort on your part. To make these changes to your .bashrc take effect in your current session: source ~/.bashrc Python \u00b6 There are python2/recommended and python3/recommended bundles. These use a virtualenv and have pip set up for you. They both have numpy and scipy available. Set compiler module \u00b6 The Python versions on Legion were built with GCC. You can run them with the default Intel compilers loaded because everything depends on the gcc-libs/4.9.2 module. When you are building your own Python packages you should have the GCC compiler module loaded however, to avoid the situation where you build a package with the Intel compiler and then try to run it with GCC, in which case it will be unable to find Intel-specific instructions. module unload compilers module load compilers/gnu/4.9.2 If you get an error like this when trying to run something, recheck what compiler you used. undefined symbol: __intel_sse2_strrchr Install your own packages in the same virtualenv \u00b6 This will use our central virtualenv, which contains a number of packages already installed. pip install --user <python2pkg> pip3 install --user <python3pkg> These will install into .python2local or .python3local respectively. To see what is already installed, the Python-shared list shows what is installed for both Python2 and 3, while the Python2 list and Python3 list show what is only installed for one or the other. (There may also be prereqs that aren't listed explicitly - pip will tell you if something is already installed as long as you have the recommended module bundle loaded). Use your own virtualenvs \u00b6 If you need different packages that are not compatible with the central installs, you can create a new virtualenv and only yours will be available. virtualenv <DIR> source <DIR>/bin/activate Your bash prompt will show you that a different virtualenv is active. Installing via setup.py \u00b6 If you need to install using setup.py, you can use the --user flag and as long as one of the python bundles is loaded, it will install into the same .python2local or .python3local as pip and you won't need to add any new paths to your environment. python setup.py install --user You can alternatively use --prefix in which case you will have to set the install prefix to somewhere in your space, and also set PYTHONPATH and PATH to include your install location. Some installs won't create the prefix directory for you, in which case create it first. This is useful if you want to keep this package entirely separate and only in your paths on demand. export PYTHONPATH=/home/username/your/path/lib/python2.7/site-packages:$PYTHONPATH # if necessary, create install path mkdir -p home/username/your/path/lib/python2.7/site-packages python setup.py install --prefix=/home/username/your/path # add these to your .bashrc or jobscript export PYTHONPATH=/home/username/your/path/lib/python2.7/site-packages:$PYTHONPATH export PATH=/home/username/your/path/bin:$PATH Check that the PATH is where your Python executables were installed, and the PYTHONPATH is correct. It will tend to tell you at install time if you need to change or create the PYTHONPATH directory. Python script executable paths \u00b6 If you have an executable python script giving the location of python like this, and it fails because that python doesn't exist in that location or isn't the one that has the additional packages installed: `#!/usr/bin/python2.6` You should change it so it uses the first python found in your environment. 1 #!/usr/bin/env python Perl \u00b6 Perl modules will freqently have a Makefile.PL (especially if you download the tar files from CPAN.org yourself). You can install manually as: perl Makefile.PL PREFIX=/home/username/your/perl/location make make install CPAN \u00b6 You can use CPAN to download and install modules locally for you. The first time you run the cpan command, it will create a .cpan directory for you and ask you to give it configuration settings or allow it to set them automatically. You need to tell it where you want your install prefix to be. If it is automatically configured, you need to edit these lines in your .cpan/CPAN/MyConfig.pm , for example if you want it to be in a lib directory in your home (change username to your own username): 'make_install_arg' => q[PREFIX=/home/username/lib], # other lines in here 'makepl_arg' => q[PREFIX=/home/username/lib], 'mbuild_install_arg' => q[PREFIX=/home/username/lib], 'mbuildpl_arg' => q[--install_base /home/username/lib], It will download and build modules inside .cpan and install them where you specified. Set PERL5LIB paths \u00b6 If you install your own Perl or Perl modules, you will need to append them to your PERL5LIB: export PERL5LIB=/home/username/your/perl/location:$PERL5LIB If you installed with CPAN, you may need to add several paths to this based on the layout it creates inside your nominated Perl directory. Errors when using non-default Perl versions \u00b6 warnings.pm \u00b6 If you are using a version of Perl that is not the default system Perl and get strange errors when trying to run a Perl script, particularly ones about warnings.pm: Search pattern not terminated at /shared/ucl/apps/perl/5.20.0/lib/5.20.0/warnings.pm line 1099 then you need to edit the script so that instead of beginning with #!/usr/bin/perl , it begins with #!/usr/bin/env perl . Otherwise it will try to use the old system Perl libraries with your newer Perl executable, which won't work. libperl.so not found \u00b6 You probably built perl without telling it to build the shared library too. Add -Duseshrplib to your build flags. R \u00b6 There are instructions on installing and using local R packages in Using your own local R packages . Compiling with MPI \u00b6 OpenMPI and Intel MPI are available. Certain programs do not work well with one or the other, so if you are having problems try the other one. Intel MPI is based on MPICH, so if the program you are compiling mentions that, try Intel MPI first. The Intel MPI is threadsafe; some versions of OpenMPI aren't. Note that OpenMPI 1.8.4 had a segv bug in non-blocking collectives that is fixed in OpenMPI 1.10.1. Enabling OpenMP \u00b6 To enable OpenMP with the Intel compilers, you simply need to add -openmp to your compile line. With the GNU compilers you need to add -fopenmp . Problems \u00b6 If you experience problems building your applications, please contact your local IT support in the first instance. We are available at rc-support AT ucl.ac.uk to help you if you still cannot build your app or if you need to report a problem with our software stack.","title":"Compiling your code"},{"location":"Wiki_Export/done/Compiling/#download-your-code","text":"Use wget or curl to download the source code for the software you want to install to your account. There might be binaries available, but they often won't work on our clusters because they were compiled for other machines with other library versions available. Use tar or unzip or similar depending on archive type to uncompress your source code. wget https://www.example.com/program.tar.gz tar -xvf program.tar.gz You won't be able to use a package manager like yum, you'll need to follow the manual installation instructions for a user-space install (not using sudo).","title":"Download your code"},{"location":"Wiki_Export/done/Compiling/#set-up-your-modules","text":"Before you start compiling, you need to make sure you have the right compilers, libraries and other tools available for your software. If you haven't changed anything, you will have the default modules loaded. For more information on how to use modules, see RC Systems user environment . Check what the instructions for your software tell you about compiling it. If the website doesn't say much, the source code will hopefully have a README or INSTALL file. You may want to use a different compiler - the default is the Intel compiler. module avail compilers will show you all the compiler modules available. Most Open Source software tends to assume you're using GCC and OpenMPI (if it uses MPI) and is most tested with that combination, so if it doesn't specify you may want to begin there (do check what the newest modules available are): `module unload compilers mpi mkl` `module load compilers/gnu/4.9.2` `module load mpi/openmpi/1.10.1/gnu-4.9.2`","title":"Set up your modules"},{"location":"Wiki_Export/done/Compiling/#available-compilers","text":"The following compilers are available and supported on Legion: Intel C, C++ and Fortran GNU C, C++ and Fortran We currently have a limited number of licenses for the Intel compilers so only a certain number of users can use them simultaneously. This means that your compilation may fail with an error complaining about not being able to obtain a valid license. If this happens, simply wait for a few minutes and try again. In addition to the supported tools, there are a number of tools installed on Legion which are not supported (for example the PGI compilers) which were installed to build certain supported packages. Users who use the unsupported packages do so at their own risk.","title":"Available compilers"},{"location":"Wiki_Export/done/Compiling/#build-systems","text":"Most software will use some kind of build system to manage how files are compiled and linked and in what order. Here are a few common ones.","title":"Build systems"},{"location":"Wiki_Export/done/Compiling/#automake-configure","text":"Automake will generate the Makefile for you and hopefully pick up sensible options through configuration. You can give it an install prefix to tell it where to install (or you can build it in place and not use make install at all). ./configure --prefix=/home/username/place/you/want/to/install make # if it has a test suite, good idea to use it make test make install If it has more configuration flags, you can use ./configure --help to view them. Usually configure will create a config.log: you can look in there to find if any tests have failed or things you think should have been picked up haven't.","title":"Automake configure"},{"location":"Wiki_Export/done/Compiling/#cmake","text":"CMake is another build system. It will have a CMakeFile or the instructions will ask you to use cmake or ccmake rather than make. It also generates Makefiles for you. ccmake is a terminal-based interactive interface where you can see what variables are set to and change them, then repeatedly configure until everything is correct, generate the Makefile and quit. cmake is the commandline version. The process tends to go like this: ccmake CMakeLists.txt # press c to configure - will pick up some options # press t to toggle advanced options # keep making changes and configuring until no more errors or changes # press g to generate and exit make # if it has a test suite, good idea to use it make test make install If you need to rerun ccmake and reconfigure, remember to delete the CMakeCache.txt file, or you'll be wondering why your changes haven't taken. Turning on verbose Makefiles in ccmake is also useful if your code didn't compile first time - you'll be able to see what flags the compiler or linker is actually being given when it fails.","title":"CMake"},{"location":"Wiki_Export/done/Compiling/#make","text":"Your code may just come with a Makefile and have no configure, in which case the generic way to compile it is as follows: make targetname There's usually a default target, which make on its own will use. If you need to change any configuration options, you'll need to edit those sections of the Makefile (at the top, where the variables/flags are defined). Here are some typical variables you may want to change in a Makefile. These are what compilers/mpi wrappers to use - these are also defined by the compiler modules, so you can see what they should be. Intel would be icc, icpc, ifort, for example. If it's a program that can be compiled using MPI and only has a variable for CC, then set that to mpicc. CC=gcc CXX=g++ FC=gfortran MPICC=mpicc MPICXX=mpicxx MPIF90=mpif90 CFLAGS and LDFLAGS are flags for the compiler and linker respectively, and there might be LIBS or INCLUDE as well. When linking a library with the name libfoo, use -lfoo . CFLAGS=\"-I/path/to/include\" LDFLAGS=\"-L/path/to/foo/lib -L/path/to/bar/lib\" LDLIBS=\"-lfoo -lbar\" Remember to make clean first if you are recompiling with new options!","title":"Make"},{"location":"Wiki_Export/done/Compiling/#avx-instructions","text":"Note : Legion's current login nodes are of a newer architecture than some of the compute nodes - the login nodes have AVX instructions but the XYZ type nodes do not. This means if you want your code to run on the older nodes, some compiler options cannot be used (e.g. -march=native , -mtune , -xHost ) or your code will segfault. You can either build the code on the login nodes and restrict your jobs to only running on the newer nodes, compile the code with appropriate options for all the nodes, or compile your code inside a job that is running on the XYZ nodes (or during a qrsh session on the same).","title":"AVX instructions"},{"location":"Wiki_Export/done/Compiling/#intel-compilers","text":"To tell the Intel compilers to build for SSE4.2 instructions and no AVX, add this to CFLAGS (and CXXFLAGS if relevant): `CFLAGS=-axSSE4.2` (Also see icc -help codegen ).","title":"Intel compilers"},{"location":"Wiki_Export/done/Compiling/#gnu-compilers","text":"To tell GCC to build for SSE4.2 without AVX, add this to CFLAGS (and CXXFLAGS if relevant): `CFLAGS=-march=nehalem`","title":"GNU compilers"},{"location":"Wiki_Export/done/Compiling/#restrict-node-type","text":"To restrict a job to newer nodes only, put this in your script: #$ -ac allow=LMNOPQSTU You can also compile one version without AVX and one with, so you can take advantage of the newer nodes when possible. You could use hostname in your jobscript to check what type of node you were on and run the appropriate binary. Hostnames begin with node-x for an X-type node, node-u for a U-type and so on.","title":"Restrict node type"},{"location":"Wiki_Export/done/Compiling/#test-for-avx","text":"We have a script that will let you test whether your compiled code is using AVX instructions. If you pass it a directory it will recursively test everything in there. Note that if your code builds multiple kernels and so can choose based on where it runs which instructions to use (like MKL) then this will find AVX instructions but they won't cause your code to segfault. `find /home/username/path/ -perm /111 -type f | xargs /shared/ucl/apps/rcops_scripts/hasavx -q`","title":"Test for AVX"},{"location":"Wiki_Export/done/Compiling/#blas-and-lapack","text":"BLAS and LAPACK are provided as part of MKL, OpenBLAS or ATLAS. There are several different OpenBLAS and ATLAS modules on Legion for different compilers. MKL is available in the Intel compiler module. Your code may try to link -lblas -llapack : this isn't the right way to use BLAS and LAPACK with MKL or ATLAS (our OpenBLAS now has symlinks that allow you to do this). MKL on Legion OpenBLAS on Legion ATLAS on Legion","title":"BLAS and LAPACK"},{"location":"Wiki_Export/done/Compiling/#set-your-path-and-other-environment-variables","text":"After you have installed your software, you'll need to add it to your PATH environment variable so you can run it without having to give the full path to its location. Put this in your ~/.bashrc file so it will set this with every new session you create. Replace username with your username and point to the directory your binary was built in (frequently program/bin ). This adds it to the front of your PATH, so if you install a newer version of something, it will be found before the system one. `export PATH=/home/username/location/of/software/binary:$PATH` If you built a library that you'll go on to compile other software with, you probably want to also add the lib directory to your LD_LIBRARY_PATH and LIBRARY_PATH, and the include directory to CPATH (add export statements as above). This may mean your configure step will pick your library up correctly without any further effort on your part. To make these changes to your .bashrc take effect in your current session: source ~/.bashrc","title":"Set your PATH and other environment variables"},{"location":"Wiki_Export/done/Compiling/#python","text":"There are python2/recommended and python3/recommended bundles. These use a virtualenv and have pip set up for you. They both have numpy and scipy available.","title":"Python"},{"location":"Wiki_Export/done/Compiling/#set-compiler-module","text":"The Python versions on Legion were built with GCC. You can run them with the default Intel compilers loaded because everything depends on the gcc-libs/4.9.2 module. When you are building your own Python packages you should have the GCC compiler module loaded however, to avoid the situation where you build a package with the Intel compiler and then try to run it with GCC, in which case it will be unable to find Intel-specific instructions. module unload compilers module load compilers/gnu/4.9.2 If you get an error like this when trying to run something, recheck what compiler you used. undefined symbol: __intel_sse2_strrchr","title":"Set compiler module"},{"location":"Wiki_Export/done/Compiling/#install-your-own-packages-in-the-same-virtualenv","text":"This will use our central virtualenv, which contains a number of packages already installed. pip install --user <python2pkg> pip3 install --user <python3pkg> These will install into .python2local or .python3local respectively. To see what is already installed, the Python-shared list shows what is installed for both Python2 and 3, while the Python2 list and Python3 list show what is only installed for one or the other. (There may also be prereqs that aren't listed explicitly - pip will tell you if something is already installed as long as you have the recommended module bundle loaded).","title":"Install your own packages in the same virtualenv"},{"location":"Wiki_Export/done/Compiling/#use-your-own-virtualenvs","text":"If you need different packages that are not compatible with the central installs, you can create a new virtualenv and only yours will be available. virtualenv <DIR> source <DIR>/bin/activate Your bash prompt will show you that a different virtualenv is active.","title":"Use your own virtualenvs"},{"location":"Wiki_Export/done/Compiling/#installing-via-setuppy","text":"If you need to install using setup.py, you can use the --user flag and as long as one of the python bundles is loaded, it will install into the same .python2local or .python3local as pip and you won't need to add any new paths to your environment. python setup.py install --user You can alternatively use --prefix in which case you will have to set the install prefix to somewhere in your space, and also set PYTHONPATH and PATH to include your install location. Some installs won't create the prefix directory for you, in which case create it first. This is useful if you want to keep this package entirely separate and only in your paths on demand. export PYTHONPATH=/home/username/your/path/lib/python2.7/site-packages:$PYTHONPATH # if necessary, create install path mkdir -p home/username/your/path/lib/python2.7/site-packages python setup.py install --prefix=/home/username/your/path # add these to your .bashrc or jobscript export PYTHONPATH=/home/username/your/path/lib/python2.7/site-packages:$PYTHONPATH export PATH=/home/username/your/path/bin:$PATH Check that the PATH is where your Python executables were installed, and the PYTHONPATH is correct. It will tend to tell you at install time if you need to change or create the PYTHONPATH directory.","title":"Installing via setup.py"},{"location":"Wiki_Export/done/Compiling/#python-script-executable-paths","text":"If you have an executable python script giving the location of python like this, and it fails because that python doesn't exist in that location or isn't the one that has the additional packages installed: `#!/usr/bin/python2.6` You should change it so it uses the first python found in your environment. 1 #!/usr/bin/env python","title":"Python script executable paths"},{"location":"Wiki_Export/done/Compiling/#perl","text":"Perl modules will freqently have a Makefile.PL (especially if you download the tar files from CPAN.org yourself). You can install manually as: perl Makefile.PL PREFIX=/home/username/your/perl/location make make install","title":"Perl"},{"location":"Wiki_Export/done/Compiling/#cpan","text":"You can use CPAN to download and install modules locally for you. The first time you run the cpan command, it will create a .cpan directory for you and ask you to give it configuration settings or allow it to set them automatically. You need to tell it where you want your install prefix to be. If it is automatically configured, you need to edit these lines in your .cpan/CPAN/MyConfig.pm , for example if you want it to be in a lib directory in your home (change username to your own username): 'make_install_arg' => q[PREFIX=/home/username/lib], # other lines in here 'makepl_arg' => q[PREFIX=/home/username/lib], 'mbuild_install_arg' => q[PREFIX=/home/username/lib], 'mbuildpl_arg' => q[--install_base /home/username/lib], It will download and build modules inside .cpan and install them where you specified.","title":"CPAN"},{"location":"Wiki_Export/done/Compiling/#set-perl5lib-paths","text":"If you install your own Perl or Perl modules, you will need to append them to your PERL5LIB: export PERL5LIB=/home/username/your/perl/location:$PERL5LIB If you installed with CPAN, you may need to add several paths to this based on the layout it creates inside your nominated Perl directory.","title":"Set PERL5LIB paths"},{"location":"Wiki_Export/done/Compiling/#errors-when-using-non-default-perl-versions","text":"","title":"Errors when using non-default Perl versions"},{"location":"Wiki_Export/done/Compiling/#warningspm","text":"If you are using a version of Perl that is not the default system Perl and get strange errors when trying to run a Perl script, particularly ones about warnings.pm: Search pattern not terminated at /shared/ucl/apps/perl/5.20.0/lib/5.20.0/warnings.pm line 1099 then you need to edit the script so that instead of beginning with #!/usr/bin/perl , it begins with #!/usr/bin/env perl . Otherwise it will try to use the old system Perl libraries with your newer Perl executable, which won't work.","title":"warnings.pm"},{"location":"Wiki_Export/done/Compiling/#libperlso-not-found","text":"You probably built perl without telling it to build the shared library too. Add -Duseshrplib to your build flags.","title":"libperl.so not found"},{"location":"Wiki_Export/done/Compiling/#r","text":"There are instructions on installing and using local R packages in Using your own local R packages .","title":"R"},{"location":"Wiki_Export/done/Compiling/#compiling-with-mpi","text":"OpenMPI and Intel MPI are available. Certain programs do not work well with one or the other, so if you are having problems try the other one. Intel MPI is based on MPICH, so if the program you are compiling mentions that, try Intel MPI first. The Intel MPI is threadsafe; some versions of OpenMPI aren't. Note that OpenMPI 1.8.4 had a segv bug in non-blocking collectives that is fixed in OpenMPI 1.10.1.","title":"Compiling with MPI"},{"location":"Wiki_Export/done/Compiling/#enabling-openmp","text":"To enable OpenMP with the Intel compilers, you simply need to add -openmp to your compile line. With the GNU compilers you need to add -fopenmp .","title":"Enabling OpenMP"},{"location":"Wiki_Export/done/Compiling/#problems","text":"If you experience problems building your applications, please contact your local IT support in the first instance. We are available at rc-support AT ucl.ac.uk to help you if you still cannot build your app or if you need to report a problem with our software stack.","title":"Problems"},{"location":"Wiki_Export/done/Connecting_to_Research_Data_Services/","text":"The Research Data Services group (RDS) run a number of systems designed to help with data storage during and after a project. Several solutions for copying data between RDS and each of the central UCL research computing platforms are presented below. Sections of the example code surrounded by angle brackets (\\<>) should be replaced by the information indicated (do not keep the angle brackets in). Between Legion and RDS \u00b6 If you already have an account with Research Data Services, you can transfer data directly between Legion and Research Data Storage using the Secure Copy ( scp ) command. From RDS to Legion \u00b6 If you are on a research data login node, you can transfer data to Legion\u2019s Scratch area at the highest rate currently possible by running the command: scp data_file.tgz login05.external.legion.ucl.ac.uk:~/Scratch/ Or from somewhere within Legion (including compute nodes in running jobs) running the command: scp ssh.rd.ucl.ac.uk:~/data_file.tgz ~/Scratch/ From Legion to RDS \u00b6 From Legion, send data to your project space on RDS by running the command: scp data_file.tgz ccaaxyz@ssh.rd.ucl.ac.uk:<path_to_project_space> The RDS support pages provide more information: http://www.ucl.ac.uk/isd/services/research-it/research-data/storage/access-guide","title":"Connecting to Research Data Services"},{"location":"Wiki_Export/done/Connecting_to_Research_Data_Services/#between-legion-and-rds","text":"If you already have an account with Research Data Services, you can transfer data directly between Legion and Research Data Storage using the Secure Copy ( scp ) command.","title":"Between Legion and RDS"},{"location":"Wiki_Export/done/Connecting_to_Research_Data_Services/#from-rds-to-legion","text":"If you are on a research data login node, you can transfer data to Legion\u2019s Scratch area at the highest rate currently possible by running the command: scp data_file.tgz login05.external.legion.ucl.ac.uk:~/Scratch/ Or from somewhere within Legion (including compute nodes in running jobs) running the command: scp ssh.rd.ucl.ac.uk:~/data_file.tgz ~/Scratch/","title":"From RDS to Legion"},{"location":"Wiki_Export/done/Connecting_to_Research_Data_Services/#from-legion-to-rds","text":"From Legion, send data to your project space on RDS by running the command: scp data_file.tgz ccaaxyz@ssh.rd.ucl.ac.uk:<path_to_project_space> The RDS support pages provide more information: http://www.ucl.ac.uk/isd/services/research-it/research-data/storage/access-guide","title":"From Legion to RDS"},{"location":"Wiki_Export/done/Contact_and_Support/","text":"Users should direct any queries relating to their use of Research Computing services to the Research Computing Support Team at rc-support@ucl.ac.uk (see below). The team will respond to your question as quickly as possible, giving priority to requests that are deemed urgent on the basis of the information provided. Availability: 9:30am - 4:30pm, Monday - Friday, except on Bank Holidays and College Closures. We aim to provide to you with a useful response within 24 hours. Please do not email individuals unless you are explicitly asked to do so; always use the rc-support email address provided. Contacts \u00b6 The members of the Research Computing Services Group are: Peter Maccallum Head of Research Computing Services Dr Owain Kenway Research Computing Analyst, Team Lead Brian Alston Research Computing Analyst Dr Ian Kirker Research Computing Analyst Heather Kelly Research Computing Analyst as well as our dedicated system administrators. Please note that all support related questions or comments should be directed to the team email address rc-support@ucl.ac.uk in the first instance. Location \u00b6 The Research Computing Team are located at: UCL - Information Services Division 1 St Martins-Le-Grand London EC1A 4AS","title":"Contact and Support"},{"location":"Wiki_Export/done/Contact_and_Support/#contacts","text":"The members of the Research Computing Services Group are: Peter Maccallum Head of Research Computing Services Dr Owain Kenway Research Computing Analyst, Team Lead Brian Alston Research Computing Analyst Dr Ian Kirker Research Computing Analyst Heather Kelly Research Computing Analyst as well as our dedicated system administrators. Please note that all support related questions or comments should be directed to the team email address rc-support@ucl.ac.uk in the first instance.","title":"Contacts"},{"location":"Wiki_Export/done/Contact_and_Support/#location","text":"The Research Computing Team are located at: UCL - Information Services Division 1 St Martins-Le-Grand London EC1A 4AS","title":"Location"},{"location":"Wiki_Export/done/Example_Submission_Scripts/","text":"On this page we describe some basic example scripts to submit jobs to Legion or Grace. For a full description of data management policies, please refer to the data management section of the user guide. After creating your script, submit it to the scheduler with: qsub my_script.sh Service Differences \u00b6 These scripts are all applicable to Legion , Grace , Myriad , Thomas , and Michael , but node sizes (core count, memory, and temporary storage sizes) differ between the different machines, and Grace and Thomas are more suited to MPI and hybrid MPI/OpenMP jobs. Working Directories and Output \u00b6 The parallel filesystems we use to provide the home and scratch filesystems perform best when reading or writing single large files, and worst when operating on many different small files. To avoid causing problems, many of the scripts below are written to create all their files in the temporary TMPDIR storage, and compress and copy them to the scratch area at the end of the job. This can be a problem if your job is not finishing and you need to see the output, or if your job is crashing or failing to produce what you expected. Feel free to modify the scripts to read from or write to scratch directly, however, your performance will generally not be as good as writing to TMPDIR, and you may impact the general performance of the machine if you do this with many jobs simultaneously. Note that there is also the option of using the Local2Scratch process ( see below ), which takes place after the job has finished, in the clean-up step. This gives you the option of always getting the contents of TMPDIR back, at the cost of possibly getting incomplete files and not having any control over where the files go. Note about Projects \u00b6 Projects are a system used in the scheduler and the accounting system to track budgets and access controls. The majority of users of UCL's internal clusters - Legion, Grace, and Myriad - will not need to specify a project and will default to the AllUsers project. Users of the Thomas and Michael services should refer to the specific pages for those machines, and the information they were given when they registered. To specify a project ID in a job script, use the -P object as below: #$ -P <your_project_id> Serial Job Script Example \u00b6 The most basic type of job a user can submit to the Legion cluster is a serial job. These jobs run on a single processor with a single thread. Shown below is a simple job script that runs /bin/date (which prints the current date) on the compute node, and puts the output into the job's output file. #!/bin/bash -l # Batch script to run a serial job on Legion under SGE. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer followed by M, G, or T) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set the name of the job. #$ -N Serial_Job # Set the working directory to somewhere in your scratch space. # This is a necessary step as compute nodes cannot write to $HOME. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/workspace # Your work should be done in $TMPDIR cd $TMPDIR # Run the application. /bin/date > date.txt # Preferably, tar-up (archive) all output files onto the shared scratch area tar -zcvf $HOME /Scratch/files_from_job_ $JOB_ID .tar.gz $TMPDIR # Make sure you have given enough time for the copy to complete! Multi-threaded Job Example \u00b6 For programs that can use multiple threads, you can request multiple processor cores using the -pe smp <number> option. One common method for using multiple threads in a program is OpenMP, and the OMP_NUM_THREADS environment variable is set automatically in a job of this type to tell OpenMP how many threads it should use. Most methods for running multi-threaded applications should correctly detect how many cores have been allocated, though ( via a mechanism called cgroups ). Note that this job script works directly in scratch instead of in the temporary TMPDIR storage. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/bin/bash -l # Batch script to run an OpenMP threaded job on Legion under SGE. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM for each core/thread (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set the name of the job. #$ -N Multi-threaded Job # Request 16 cores. #$ -pe smp 16 # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/output # 8. Run the application. $HOME/my_program/example MPI Job Script Example \u00b6 The default MPI implementation on our clusters is the Intel MPI stack. MPI programs don\u2019t use a shared memory model so they can be run across multiple nodes. This script differs considerably from the serial and OpenMP jobs in that MPI programs need to be invoked by a program called gerun. This is a wrapper for mpirun and takes care of passing the number of processors and a file called a machine file. '''Important''': If you wish to pass a file or stream of data to the standard input (stdin) of an MPI program, there are specific command-line options you need to use to control which MPI tasks are able to receive it. ( -s for Intel MPI, --stdin for OpenMPI.) Please consult the help output of the mpirun command for further information. The gerun launcher does not automatically handle this. If you use OpenMPI, you need to make sure the Intel mpi modules are removed and the OpenMPI modules are loaded, either in your shell start-up files (e.g. ~/.bashrc ), or else in the script itself. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/bin/bash -l # Batch script to run an MPI parallel job under SGE with Intel MPI. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM per process (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space per node (default is 10 GB) #$ -l tmpfs=15G # Set the name of the job. #$ -N MadScience_1_16 # Select the MPI parallel environment and 16 processes. #$ -pe mpi 16 # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID : #$ -wd /home/<your_UCL_id>/Scratch/output # Run our MPI job. GERun is a wrapper that launches MPI jobs on our clusters. gerun $HOME/src/science/simulate Array Job Script Example \u00b6 If you want to submit a large number of similar serial jobs then it may be easier to submit them as an array job. Array jobs are similar to serial jobs except we use the -t option to get Sun Grid Engine to run 10,000 copies of this job numbered 1 to 10,000. Each job in this array will have the same job ID but a different task ID. The task ID is stored in the SGE_TASK_ID environment variable in each task. All the usual SGE output files have the task ID appended. MPI jobs and parallel shared memory jobs can also be submitted as arrays. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #!/bin/bash -l # Batch script to run a serial array job under SGE. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set up the job array. In this instance we have requested 10000 tasks # numbered 1 to 10000. #$ -t 1-10000 # Set the name of the job. #$ -N MyArrayJob # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/output # Run the application. echo \"$JOB_NAME $SGE_TASK_ID\" Array Job Script Example Using Parameter File \u00b6 Often a user will want to submit a large number of similar jobs but their input parameters don't match easily on to an index from 1 to n. In these cases it's possible to use a parameter file. To use this script a user needs to construct a file with a line for each element in the job array, with parameters separated by spaces. For example: 0001 1.5 3 aardvark 0002 1.1 13 guppy 0003 1.23 5 elephant 0004 1.112 23 panda 0005 ... Assuming that this file is stored in ~/Scratch/input/params.txt (you can call this file anything you want) then the user can use awk/sed to get the appropriate variables out of the file as with the script below which stores them in $index , $variable1 , $variable2 and $variable3 . So for example in task 4, $index = 0004 , $variable1 = 1.112 , $variable2 = 23 and $variable3 = panda . Since the parameter file can be generated automatically from a user's datasets, this approach allows the simple automation, submission and management of thousands or tens of thousands of tasks. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #!/bin/bash -l # Batch script to run an array job. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set up the job array. In this instance we have requested 1000 tasks # numbered 1 to 1000. #$ -t 1-1000 # Set the name of the job. #$ -N array-params # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/output # Parse parameter file to get variables. number=$SGE_TASK_ID paramfile=/home/<your_UCL_id>/Scratch/input/params.txt index=\"`sed -n ${number}p $paramfile | awk '{print $1}'`\" variable1=\"`sed -n ${number}p $paramfile | awk '{print $2}'`\" variable2=\"`sed -n ${number}p $paramfile | awk '{print $3}'`\" variable3=\"`sed -n ${number}p $paramfile | awk '{print $4}'`\" # Run the program (replace echo with your binary and options). echo \"$index\" \"$variable1\" \"$variable2\" \"$variable3\" Example Array Job Using Local2Scratch \u00b6 Users can automate the transfer of data from $TMPDIR to their scratch space by adding the text #Local2Scratch to their script on a line alone as a special comment. During the clean-up phase of the job, a tool checks whether the script contains that text, and if so, files are transferred from $TMPDIR to a directory in scratch with the structure <job id>/<job id>.<task id>.<queue>/ . The example below does this for a job array, but this works for any job type. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #!/bin/bash -l # Batch script to run an array job under SGE and # transfer the output to Scratch from local. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set up the job array. In this instance we have requested 10000 tasks # numbered 1 to 10000. #$ -t 1-10000 # Set the name of the job. #$ -N local2scratcharray # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/output # Automate transfer of output to Scratch from $TMPDIR. #Local2Scratch # Run the application in TMPDIR. cd $TMPDIR hostname > hostname.txt Array job script with a stride \u00b6 If each task for your array job is very small, you will get better use of the cluster if you can combine a number of these so each has a couple of hours' worth of work to do. There is a startup cost associated with the amount of time it takes to set up a new job. If your job's runtime is very small, this cost is proportionately high, and you incur it with every array task. Using a stride will allow you to leave your input files numbered as before, and each array task will run N inputs. For example, a stride of 10 will give you these task IDs: 1, 11, 21... Your script can then have a loop that runs task IDs from $SGE_TASK_ID to $SGE_TASK_ID + 9 , so each task is doing ten times as many runs as it was before. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #!/bin/bash -l # Batch script to run an array job with strided task IDs under SGE. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set up the job array. In this instance we have requested task IDs # numbered 1 to 10000 with a stride of 10. #$ -t 1-10000:10 # Set the name of the job. #$ -N arraystride # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/output # Automate transfer of output to Scratch from $TMPDIR. #Local2Scratch # Do your work in $TMPDIR cd $TMPDIR # 10. Loop through the IDs covered by this stride and run the application if # the input file exists. (This is because the last stride may not have that # many inputs available). Or you can leave out the check and get an error. for (( i=$SGE_TASK_ID; i<$SGE_TASK_ID+10; i++ )) do if [ -f \"input.$i\" ] then echo \"$JOB_NAME\" \"$SGE_TASK_ID\" \"input.$i\" fi done GPU job script example \u00b6 To use NVIDIA GPUs with the CUDA libraries, you need to load the CUDA runtime libraries module or else set up the environment yourself. The script below shows what you'll need to unload and load the appropriate modules. You also need to use the -l gpu=<number> option to request the GPUs from the scheduler. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #!/bin/bash -l # Batch script to run a GPU job on Legion under SGE. # Request a number of GPU cards, in this case 2 (the maximum) #$ -l gpu=2 # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set the name of the job. #$ -N GPUJob # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/output # Change into temporary directory to run work cd $TMPDIR # load the cuda module (in case you are running a CUDA program module unload compilers mpi module load compilers/gnu/4.9.2 module load cuda/7.5.18/gnu-4.9.2 # Run the application - the line below is just a random example. mygpucode # 10. Preferably, tar-up (archive) all output files onto the shared scratch area tar zcvf $HOME/Scratch/files_from_job_$JOB_ID.tar.gz $TMPDIR # Make sure you have given enough time for the copy to complete! Job using MPI and GPUs \u00b6 It is possible to run MPI programs that use GPUs but our clusters currently only support this within a single node. The script below shows how to run a program using 2 gpus and 12 cpus. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #!/bin/bash -l # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 12 cores, 2 GPUs, 1 gigabyte of RAM per CPU, 15 gigabyte of TMPDIR space #$ -l mem=1G #$ -l gpu=2 #$ -pe mpi 12 #$ -l tmpfs=15G # Set the name of the job. #$ -N GPUMPIrun # Set the working directory to somewhere in your scratch space. #$ -wd /home/<your user id>/Scratch/output/ # Run our MPI job. You can choose OpenMPI or IntelMPI for GCC. module unload compilers mpi module load compilers/gnu/4.9.2 module load mpi/openmpi/1.10.1/gnu-4.9.2 module load cuda/7.5.18/gnu-4.9.2 gerun myGPUapp","title":"Example submission scripts"},{"location":"Wiki_Export/done/Example_Submission_Scripts/#service-differences","text":"These scripts are all applicable to Legion , Grace , Myriad , Thomas , and Michael , but node sizes (core count, memory, and temporary storage sizes) differ between the different machines, and Grace and Thomas are more suited to MPI and hybrid MPI/OpenMP jobs.","title":"Service Differences"},{"location":"Wiki_Export/done/Example_Submission_Scripts/#working-directories-and-output","text":"The parallel filesystems we use to provide the home and scratch filesystems perform best when reading or writing single large files, and worst when operating on many different small files. To avoid causing problems, many of the scripts below are written to create all their files in the temporary TMPDIR storage, and compress and copy them to the scratch area at the end of the job. This can be a problem if your job is not finishing and you need to see the output, or if your job is crashing or failing to produce what you expected. Feel free to modify the scripts to read from or write to scratch directly, however, your performance will generally not be as good as writing to TMPDIR, and you may impact the general performance of the machine if you do this with many jobs simultaneously. Note that there is also the option of using the Local2Scratch process ( see below ), which takes place after the job has finished, in the clean-up step. This gives you the option of always getting the contents of TMPDIR back, at the cost of possibly getting incomplete files and not having any control over where the files go.","title":"Working Directories and Output"},{"location":"Wiki_Export/done/Example_Submission_Scripts/#note-about-projects","text":"Projects are a system used in the scheduler and the accounting system to track budgets and access controls. The majority of users of UCL's internal clusters - Legion, Grace, and Myriad - will not need to specify a project and will default to the AllUsers project. Users of the Thomas and Michael services should refer to the specific pages for those machines, and the information they were given when they registered. To specify a project ID in a job script, use the -P object as below: #$ -P <your_project_id>","title":"Note about Projects"},{"location":"Wiki_Export/done/Example_Submission_Scripts/#serial-job-script-example","text":"The most basic type of job a user can submit to the Legion cluster is a serial job. These jobs run on a single processor with a single thread. Shown below is a simple job script that runs /bin/date (which prints the current date) on the compute node, and puts the output into the job's output file. #!/bin/bash -l # Batch script to run a serial job on Legion under SGE. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer followed by M, G, or T) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set the name of the job. #$ -N Serial_Job # Set the working directory to somewhere in your scratch space. # This is a necessary step as compute nodes cannot write to $HOME. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/workspace # Your work should be done in $TMPDIR cd $TMPDIR # Run the application. /bin/date > date.txt # Preferably, tar-up (archive) all output files onto the shared scratch area tar -zcvf $HOME /Scratch/files_from_job_ $JOB_ID .tar.gz $TMPDIR # Make sure you have given enough time for the copy to complete!","title":"Serial Job Script Example"},{"location":"Wiki_Export/done/Example_Submission_Scripts/#multi-threaded-job-example","text":"For programs that can use multiple threads, you can request multiple processor cores using the -pe smp <number> option. One common method for using multiple threads in a program is OpenMP, and the OMP_NUM_THREADS environment variable is set automatically in a job of this type to tell OpenMP how many threads it should use. Most methods for running multi-threaded applications should correctly detect how many cores have been allocated, though ( via a mechanism called cgroups ). Note that this job script works directly in scratch instead of in the temporary TMPDIR storage. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/bin/bash -l # Batch script to run an OpenMP threaded job on Legion under SGE. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM for each core/thread (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set the name of the job. #$ -N Multi-threaded Job # Request 16 cores. #$ -pe smp 16 # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/output # 8. Run the application. $HOME/my_program/example","title":"Multi-threaded Job Example"},{"location":"Wiki_Export/done/Example_Submission_Scripts/#mpi-job-script-example","text":"The default MPI implementation on our clusters is the Intel MPI stack. MPI programs don\u2019t use a shared memory model so they can be run across multiple nodes. This script differs considerably from the serial and OpenMP jobs in that MPI programs need to be invoked by a program called gerun. This is a wrapper for mpirun and takes care of passing the number of processors and a file called a machine file. '''Important''': If you wish to pass a file or stream of data to the standard input (stdin) of an MPI program, there are specific command-line options you need to use to control which MPI tasks are able to receive it. ( -s for Intel MPI, --stdin for OpenMPI.) Please consult the help output of the mpirun command for further information. The gerun launcher does not automatically handle this. If you use OpenMPI, you need to make sure the Intel mpi modules are removed and the OpenMPI modules are loaded, either in your shell start-up files (e.g. ~/.bashrc ), or else in the script itself. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/bin/bash -l # Batch script to run an MPI parallel job under SGE with Intel MPI. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM per process (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space per node (default is 10 GB) #$ -l tmpfs=15G # Set the name of the job. #$ -N MadScience_1_16 # Select the MPI parallel environment and 16 processes. #$ -pe mpi 16 # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID : #$ -wd /home/<your_UCL_id>/Scratch/output # Run our MPI job. GERun is a wrapper that launches MPI jobs on our clusters. gerun $HOME/src/science/simulate","title":"MPI Job Script Example"},{"location":"Wiki_Export/done/Example_Submission_Scripts/#array-job-script-example","text":"If you want to submit a large number of similar serial jobs then it may be easier to submit them as an array job. Array jobs are similar to serial jobs except we use the -t option to get Sun Grid Engine to run 10,000 copies of this job numbered 1 to 10,000. Each job in this array will have the same job ID but a different task ID. The task ID is stored in the SGE_TASK_ID environment variable in each task. All the usual SGE output files have the task ID appended. MPI jobs and parallel shared memory jobs can also be submitted as arrays. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #!/bin/bash -l # Batch script to run a serial array job under SGE. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set up the job array. In this instance we have requested 10000 tasks # numbered 1 to 10000. #$ -t 1-10000 # Set the name of the job. #$ -N MyArrayJob # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/output # Run the application. echo \"$JOB_NAME $SGE_TASK_ID\"","title":"Array Job Script Example"},{"location":"Wiki_Export/done/Example_Submission_Scripts/#array-job-script-example-using-parameter-file","text":"Often a user will want to submit a large number of similar jobs but their input parameters don't match easily on to an index from 1 to n. In these cases it's possible to use a parameter file. To use this script a user needs to construct a file with a line for each element in the job array, with parameters separated by spaces. For example: 0001 1.5 3 aardvark 0002 1.1 13 guppy 0003 1.23 5 elephant 0004 1.112 23 panda 0005 ... Assuming that this file is stored in ~/Scratch/input/params.txt (you can call this file anything you want) then the user can use awk/sed to get the appropriate variables out of the file as with the script below which stores them in $index , $variable1 , $variable2 and $variable3 . So for example in task 4, $index = 0004 , $variable1 = 1.112 , $variable2 = 23 and $variable3 = panda . Since the parameter file can be generated automatically from a user's datasets, this approach allows the simple automation, submission and management of thousands or tens of thousands of tasks. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #!/bin/bash -l # Batch script to run an array job. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set up the job array. In this instance we have requested 1000 tasks # numbered 1 to 1000. #$ -t 1-1000 # Set the name of the job. #$ -N array-params # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/output # Parse parameter file to get variables. number=$SGE_TASK_ID paramfile=/home/<your_UCL_id>/Scratch/input/params.txt index=\"`sed -n ${number}p $paramfile | awk '{print $1}'`\" variable1=\"`sed -n ${number}p $paramfile | awk '{print $2}'`\" variable2=\"`sed -n ${number}p $paramfile | awk '{print $3}'`\" variable3=\"`sed -n ${number}p $paramfile | awk '{print $4}'`\" # Run the program (replace echo with your binary and options). echo \"$index\" \"$variable1\" \"$variable2\" \"$variable3\"","title":"Array Job Script Example Using Parameter File"},{"location":"Wiki_Export/done/Example_Submission_Scripts/#example-array-job-using-local2scratch","text":"Users can automate the transfer of data from $TMPDIR to their scratch space by adding the text #Local2Scratch to their script on a line alone as a special comment. During the clean-up phase of the job, a tool checks whether the script contains that text, and if so, files are transferred from $TMPDIR to a directory in scratch with the structure <job id>/<job id>.<task id>.<queue>/ . The example below does this for a job array, but this works for any job type. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #!/bin/bash -l # Batch script to run an array job under SGE and # transfer the output to Scratch from local. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set up the job array. In this instance we have requested 10000 tasks # numbered 1 to 10000. #$ -t 1-10000 # Set the name of the job. #$ -N local2scratcharray # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/output # Automate transfer of output to Scratch from $TMPDIR. #Local2Scratch # Run the application in TMPDIR. cd $TMPDIR hostname > hostname.txt","title":"Example Array Job Using Local2Scratch"},{"location":"Wiki_Export/done/Example_Submission_Scripts/#array-job-script-with-a-stride","text":"If each task for your array job is very small, you will get better use of the cluster if you can combine a number of these so each has a couple of hours' worth of work to do. There is a startup cost associated with the amount of time it takes to set up a new job. If your job's runtime is very small, this cost is proportionately high, and you incur it with every array task. Using a stride will allow you to leave your input files numbered as before, and each array task will run N inputs. For example, a stride of 10 will give you these task IDs: 1, 11, 21... Your script can then have a loop that runs task IDs from $SGE_TASK_ID to $SGE_TASK_ID + 9 , so each task is doing ten times as many runs as it was before. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #!/bin/bash -l # Batch script to run an array job with strided task IDs under SGE. # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set up the job array. In this instance we have requested task IDs # numbered 1 to 10000 with a stride of 10. #$ -t 1-10000:10 # Set the name of the job. #$ -N arraystride # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/output # Automate transfer of output to Scratch from $TMPDIR. #Local2Scratch # Do your work in $TMPDIR cd $TMPDIR # 10. Loop through the IDs covered by this stride and run the application if # the input file exists. (This is because the last stride may not have that # many inputs available). Or you can leave out the check and get an error. for (( i=$SGE_TASK_ID; i<$SGE_TASK_ID+10; i++ )) do if [ -f \"input.$i\" ] then echo \"$JOB_NAME\" \"$SGE_TASK_ID\" \"input.$i\" fi done","title":"Array job script with a stride"},{"location":"Wiki_Export/done/Example_Submission_Scripts/#gpu-job-script-example","text":"To use NVIDIA GPUs with the CUDA libraries, you need to load the CUDA runtime libraries module or else set up the environment yourself. The script below shows what you'll need to unload and load the appropriate modules. You also need to use the -l gpu=<number> option to request the GPUs from the scheduler. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #!/bin/bash -l # Batch script to run a GPU job on Legion under SGE. # Request a number of GPU cards, in this case 2 (the maximum) #$ -l gpu=2 # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space (default is 10 GB) #$ -l tmpfs=15G # Set the name of the job. #$ -N GPUJob # Set the working directory to somewhere in your scratch space. # Replace \"<your_UCL_id>\" with your UCL user ID :) #$ -wd /home/<your_UCL_id>/Scratch/output # Change into temporary directory to run work cd $TMPDIR # load the cuda module (in case you are running a CUDA program module unload compilers mpi module load compilers/gnu/4.9.2 module load cuda/7.5.18/gnu-4.9.2 # Run the application - the line below is just a random example. mygpucode # 10. Preferably, tar-up (archive) all output files onto the shared scratch area tar zcvf $HOME/Scratch/files_from_job_$JOB_ID.tar.gz $TMPDIR # Make sure you have given enough time for the copy to complete!","title":"GPU job script example"},{"location":"Wiki_Export/done/Example_Submission_Scripts/#job-using-mpi-and-gpus","text":"It is possible to run MPI programs that use GPUs but our clusters currently only support this within a single node. The script below shows how to run a program using 2 gpus and 12 cpus. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #!/bin/bash -l # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 12 cores, 2 GPUs, 1 gigabyte of RAM per CPU, 15 gigabyte of TMPDIR space #$ -l mem=1G #$ -l gpu=2 #$ -pe mpi 12 #$ -l tmpfs=15G # Set the name of the job. #$ -N GPUMPIrun # Set the working directory to somewhere in your scratch space. #$ -wd /home/<your user id>/Scratch/output/ # Run our MPI job. You can choose OpenMPI or IntelMPI for GCC. module unload compilers mpi module load compilers/gnu/4.9.2 module load mpi/openmpi/1.10.1/gnu-4.9.2 module load cuda/7.5.18/gnu-4.9.2 gerun myGPUapp","title":"Job using MPI and GPUs"},{"location":"Wiki_Export/done/FAQ/","text":"This page attempts to address some of the topics we most frequently receive questions about, or to which the answers are most complex. Why is my job in Eqw status? \u00b6 If your job goes straight into Eqw state, there was an error in your jobscript that meant your job couldn't be started. You can see a truncated version of the error with: qstat -j <job_ID> To see the full error (in most cases you won't need to load userscripts as it is a default module now): module load userscripts qexplain <job_ID> This often happens because a file or directory you are trying to use doesn't exist. \"Unable to determine job requirements\" error \u00b6 Unable to run job: Rejected by ucl_jsv4h Reason:Unable to determine job requirements. Exiting. The #$ directives are missing from your script, or have extra white space before them. This means SGE isn't picking them up and doesn't know what resources you are requesting. Add them or remove the spaces and it will work. \"/bin/bash: invalid option\" error \u00b6 This is a sign that your jobscript is a DOS-formatted text file and not a Unix one - the line break characters are different. Type dos2unix <yourscriptname> in your terminal to convert it. Sometimes the offending characters will be visible in the error. You can see here it's trying to parse ^M as an option. Your Scratch space goes missing \u00b6 You may have accidentally deleted or replaced the link to your Scratch space. Do an ls -al in your home - if set up correctly, it should look like this: lrwxrwxrwx 1 username private 24 Apr 14 2014 Scratch -> /scratch/scratch/username where username is your UCL user ID. You can recreate the symlink with ln -s /scratch/scratch/username Scratch Which MKL library files should I use to build my application? \u00b6 Depending on which whether you wish to use BLAS/LAPACK/ScaLAPACK/etc... there is a specific set of libraries that you need to pass to your compilation command line. Fortunately, Intel have released a tool that allows you to determine which libraries to link and in which order for a number of compilers and operating systems: http://software.intel.com/en-us/articles/intel-mkl-link-line-advisor/ See also: MKL_on_Legion . SSH known_hosts \u00b6 1. If you get a warning when connecting in via ssh, we may have updated the login nodes, and you probably need to delete old host keys from your ~/.ssh/known_hosts . You can also delete the whole file, and the ssh command will recreate it (asking you to check) next time you try to connect. 2. If you look in the error file for your job, you may find a number of errors like the one below. Please ignore these as they are the result of compute nodes being unable to write to your home directory and do not indicate a problem. Failed to add the RSA host key for IP address '10.143.9.1' to the list of known hosts (/home/uccaoke/.ssh/known_hosts) \"ssh: Unsupported option - -x\" errors \u00b6 These errors indicate that you are attempting to use the QLogic version of mpirun in the OpenMPI parallel environment. It is likely you are doing this by accident and probably intend to use the OpenMPI mpirun but do not have your modules configured correctly. Please add the lines below, either after default modules (defmods) are loaded in your .bashrc, or else in your job script before mpirun: Note : the above assumes you are using the Intel compilers. You get \"Program not started through mpirun. Exiting...\" but are using mpirun! \u00b6 This is most often caused by launching a program built with QLogic MPI with the mpirun from another MPI implementation (e.g. OpenMPI). You can determine which version of MPI your program was built with by running ldd on the application binary. You want to know where the libraries loaded via modules system are on disk \u00b6 Look at the contents of the default modules to find the path to those libraries on the current system. Look at the following command listing: As you can see, the modules system sets the paths to libraries in environment variables which the system uses to locate files. Unable to run job: JSV stderr: perl: warning: Setting locale failed. \u00b6 This error is generally because your SSH client is passing LANG through as part of the SSH command, and is passing something that conflicts with what Legion has it set to. You may be more likely to come across this with newer versions of Mac OS X - if your client is different, have a look for an equivalent option. In Mac OS X Terminal, click Settings and under International untick the box that says \"Set locale environment variables on startup\". Per session, you can try LANG=C ssh userid@legion.rc.ucl.ac.uk Why can't I find out when my job will run? \u00b6 An informative discussion on this matter can be found in the Scheduler section of the User Guide. What can I do to minimise the time I need to wait for my job(s) to run? \u00b6 Minimise the amount of wall clock time you request. Use job arrays instead of submitting large numbers of jobs (see our job script examples ). Plan your work so that you can do other things while your jobs are being scheduled - the rule of thumb is that you will have to wait about twice the requested wall clock time (on average). What is my project code (short string) / project ID? \u00b6 Prior to July 2014, every user had a project code. Now all users belong to the default project \"AllUsers\" and no longer have to specify this. If you see older job script examples mentioning a project ID, you can delete that section. Only projects with access to paid or specialised resources need to give a project code in order to use those resources. If you do not know yours, contact rc-support .","title":"FAQ"},{"location":"Wiki_Export/done/FAQ/#why-is-my-job-in-eqw-status","text":"If your job goes straight into Eqw state, there was an error in your jobscript that meant your job couldn't be started. You can see a truncated version of the error with: qstat -j <job_ID> To see the full error (in most cases you won't need to load userscripts as it is a default module now): module load userscripts qexplain <job_ID> This often happens because a file or directory you are trying to use doesn't exist.","title":"Why is my job in Eqw status?"},{"location":"Wiki_Export/done/FAQ/#unable-to-determine-job-requirements-error","text":"Unable to run job: Rejected by ucl_jsv4h Reason:Unable to determine job requirements. Exiting. The #$ directives are missing from your script, or have extra white space before them. This means SGE isn't picking them up and doesn't know what resources you are requesting. Add them or remove the spaces and it will work.","title":"\"Unable to determine job requirements\" error"},{"location":"Wiki_Export/done/FAQ/#binbash-invalid-option-error","text":"This is a sign that your jobscript is a DOS-formatted text file and not a Unix one - the line break characters are different. Type dos2unix <yourscriptname> in your terminal to convert it. Sometimes the offending characters will be visible in the error. You can see here it's trying to parse ^M as an option.","title":"\"/bin/bash: invalid option\" error"},{"location":"Wiki_Export/done/FAQ/#your-scratch-space-goes-missing","text":"You may have accidentally deleted or replaced the link to your Scratch space. Do an ls -al in your home - if set up correctly, it should look like this: lrwxrwxrwx 1 username private 24 Apr 14 2014 Scratch -> /scratch/scratch/username where username is your UCL user ID. You can recreate the symlink with ln -s /scratch/scratch/username Scratch","title":"Your Scratch space goes missing"},{"location":"Wiki_Export/done/FAQ/#which-mkl-library-files-should-i-use-to-build-my-application","text":"Depending on which whether you wish to use BLAS/LAPACK/ScaLAPACK/etc... there is a specific set of libraries that you need to pass to your compilation command line. Fortunately, Intel have released a tool that allows you to determine which libraries to link and in which order for a number of compilers and operating systems: http://software.intel.com/en-us/articles/intel-mkl-link-line-advisor/ See also: MKL_on_Legion .","title":"Which MKL library files should I use to build my application?"},{"location":"Wiki_Export/done/FAQ/#ssh-known95hosts","text":"1. If you get a warning when connecting in via ssh, we may have updated the login nodes, and you probably need to delete old host keys from your ~/.ssh/known_hosts . You can also delete the whole file, and the ssh command will recreate it (asking you to check) next time you try to connect. 2. If you look in the error file for your job, you may find a number of errors like the one below. Please ignore these as they are the result of compute nodes being unable to write to your home directory and do not indicate a problem. Failed to add the RSA host key for IP address '10.143.9.1' to the list of known hosts (/home/uccaoke/.ssh/known_hosts)","title":"SSH known_hosts"},{"location":"Wiki_Export/done/FAQ/#ssh-unsupported-option-x-errors","text":"These errors indicate that you are attempting to use the QLogic version of mpirun in the OpenMPI parallel environment. It is likely you are doing this by accident and probably intend to use the OpenMPI mpirun but do not have your modules configured correctly. Please add the lines below, either after default modules (defmods) are loaded in your .bashrc, or else in your job script before mpirun: Note : the above assumes you are using the Intel compilers.","title":"\"ssh: Unsupported option - -x\" errors"},{"location":"Wiki_Export/done/FAQ/#you-get-program-not-started-through-mpirun-exiting-but-are-using-mpirun33","text":"This is most often caused by launching a program built with QLogic MPI with the mpirun from another MPI implementation (e.g. OpenMPI). You can determine which version of MPI your program was built with by running ldd on the application binary.","title":"You get \"Program not started through mpirun. Exiting...\" but are using mpirun!"},{"location":"Wiki_Export/done/FAQ/#you-want-to-know-where-the-libraries-loaded-via-modules-system-are-on-disk","text":"Look at the contents of the default modules to find the path to those libraries on the current system. Look at the following command listing: As you can see, the modules system sets the paths to libraries in environment variables which the system uses to locate files.","title":"You want to know where the libraries loaded via modules system are on disk"},{"location":"Wiki_Export/done/FAQ/#unable-to-run-job-jsv-stderr-perl-warning-setting-locale-failed","text":"This error is generally because your SSH client is passing LANG through as part of the SSH command, and is passing something that conflicts with what Legion has it set to. You may be more likely to come across this with newer versions of Mac OS X - if your client is different, have a look for an equivalent option. In Mac OS X Terminal, click Settings and under International untick the box that says \"Set locale environment variables on startup\". Per session, you can try LANG=C ssh userid@legion.rc.ucl.ac.uk","title":"Unable to run job: JSV stderr: perl: warning: Setting locale failed."},{"location":"Wiki_Export/done/FAQ/#why-cant-i-find-out-when-my-job-will-run","text":"An informative discussion on this matter can be found in the Scheduler section of the User Guide.","title":"Why can't I find out when my job will run?"},{"location":"Wiki_Export/done/FAQ/#what-can-i-do-to-minimise-the-time-i-need-to-wait-for-my-jobs-to-run","text":"Minimise the amount of wall clock time you request. Use job arrays instead of submitting large numbers of jobs (see our job script examples ). Plan your work so that you can do other things while your jobs are being scheduled - the rule of thumb is that you will have to wait about twice the requested wall clock time (on average).","title":"What can I do to minimise the time I need to wait for my job(s) to run?"},{"location":"Wiki_Export/done/FAQ/#what-is-my-project-code-short-string-project-id","text":"Prior to July 2014, every user had a project code. Now all users belong to the default project \"AllUsers\" and no longer have to specify this. If you see older job script examples mentioning a project ID, you can delete that section. Only projects with access to paid or specialised resources need to give a project code in order to use those resources. If you do not know yours, contact rc-support .","title":"What is my project code (short string) / project ID?"},{"location":"Wiki_Export/done/GPU_clusters/","text":"UCL users may be able to access the following GPU clusters. National GPU clusters \u00b6 There are two nationally-accessible EPSRC Tier 2 HPC centres with GPUs. Access is generally managed through calls to an EPSRC Resource Allocation Panel Autumn 2017 Tier 2 RAP call Spring 2018 Tier 2 RAP call Autumn 2018 Tier 2 RAP call : technical assessment deadline 25 Sept at 16:00, closes 9 Oct at 16:00. There may also be pump-priming/proof of concept access available. General information about machines with external access is available at HPC-UK . CSD3 \u00b6 Suitable for workloads spanning multiple compute nodes using GPUs and MPI NVIDIA Tesla P100 Access to CSD3 JADE \u00b6 NVIDIA DGX-1 (Tesla P100) Access to JADE","title":"GPU clusters"},{"location":"Wiki_Export/done/GPU_clusters/#national-gpu-clusters","text":"There are two nationally-accessible EPSRC Tier 2 HPC centres with GPUs. Access is generally managed through calls to an EPSRC Resource Allocation Panel Autumn 2017 Tier 2 RAP call Spring 2018 Tier 2 RAP call Autumn 2018 Tier 2 RAP call : technical assessment deadline 25 Sept at 16:00, closes 9 Oct at 16:00. There may also be pump-priming/proof of concept access available. General information about machines with external access is available at HPC-UK .","title":"National GPU clusters"},{"location":"Wiki_Export/done/GPU_clusters/#csd3","text":"Suitable for workloads spanning multiple compute nodes using GPUs and MPI NVIDIA Tesla P100 Access to CSD3","title":"CSD3"},{"location":"Wiki_Export/done/GPU_clusters/#jade","text":"NVIDIA DGX-1 (Tesla P100) Access to JADE","title":"JADE"},{"location":"Wiki_Export/done/GPU_nodes/","text":"Node Types \u00b6 You can view the hardware specifications for GPU node types on the RC Systems Platforms Overview page. There are GPU nodes available in Legion and Myriad. Legion Type P GPU node \u00b6 There is one NVIDIA K40c GPU node in Legion. To use this, you need to specify this in your jobscript or interactive qrsh request (remove the #$ for qrsh): #$ -l gpu=1 Myriad Type J GPU nodes \u00b6 Myriad has two GPU nodes each with two NVIDIA Tesla P100s. To use them, you need to request one or two GPUs in your jobscript or interactive qrsh request (remove the #$ for qrsh): #$ -l gpu=2 Available modules \u00b6 You can see the available CUDA modules by typing `module avail cuda` Sample CUDA code \u00b6 There are samples in the CUDA install locations, e.g. /shared/ucl/apps/cuda/7.5.18/gnu-4.9.2/samples /shared/ucl/apps/cuda/8.0.61/gnu-4.9.2/samples which are further documented by NVIDIA here . In general, you should look at their CUDA docs: http://docs.nvidia.com/cuda/ Sample jobscripts \u00b6 You can see sample jobscripts here . Use this in your script to request up to 2 GPUs. `#$ -l gpu=2` Load GCC and the relevant CUDA module. module unload compilers mpi module load compilers/gnu/4.9.2 module load cuda/7.5.18/gnu-4.9.2 Running the sample code \u00b6 To get started, here's how you would compile and run one of the cuda samples interactively on a user test node using a GPU. 1. Load the cuda module `module unload compilers mpi` `module load compilers/gnu/4.9.2` `module load cuda/7.5.18/gnu-4.9.2` 2. Copy the samples directory to somewhere in your home (or to Scratch if you're building on the GPU node or are going to want a job to write anything in the same directory). cp -r /shared/ucl/apps/cuda/7.5.18/gnu-4.9.2/NVIDIA_CUDA-7.5_Samples/ ~/cuda 3. Choose an example: eigenvalues in this case, and build using the provided makefile - if you have a look at it you can see it is using nvcc and g++. cd NVIDIA_CUDA-7.5_Samples/6_Advanced/eigenvalues/ make 4. Request an interactive job with a GPU and wait to be given access to the node. You will see your prompt change to indicate that you are on a different node than the login node once your qrsh request has been scheduled, and you can then continue. Load the cuda module on the node and run the program. qrsh -l mem=1G,h_rt=0:30:0,gpu=1 -now no module unload compilers mpi module load compilers/gnu/4.9.2 module load cuda/7.5.18 cd ~/cuda/NVIDIA_CUDA-7.5_Samples/6_Advanced/eigenvalues/ ./eigenvalues 5. Your output should look something like this: Starting eigenvalues GPU Device 0: \"Tesla M2070\" with compute capability 2.0 Matrix size: 2048 x 2048 Precision: 0.000010 Iterations to be timed: 100 Result filename: 'eigenvalues.dat' Gerschgorin interval: -2.894310 / 2.923303 Average time step 1: 26.739325 ms Average time step 2, one intervals: 9.031162 ms Average time step 2, mult intervals: 0.004330 ms Average time TOTAL: 35.806992 ms Test Succeeded! Building your own code \u00b6 Please note: if the code you are trying to compile needs to link libcuda, it must also be built on a GPU node because only the GPU node has the correct libraries. The NVIDIA examples don't require this, but things like Tensorflow do. Tensorflow \u00b6 Tensorflow is installed: type module avail tensorflow to see the available versions. Modules to load for the non-MKL GPU version: module unload compilers mpi module load compilers/gnu/4.9.2 module load python3/recommended module load cuda/8.0.61-patch2/gnu-4.9.2 module load cudnn/6.0/cuda-8.0 module load tensorflow/1.4.1/gpu Using MPI and GPUs \u00b6 It is possible to run MPI programs that use GPUs but only within a single node, so you can request 1 GPU and 12 processor cores on Legion, or up to 2 GPUs and 36 cores on Myriad. Looking for more GPUs? \u00b6 GPU clusters available to UCL users .","title":"GPU nodes"},{"location":"Wiki_Export/done/GPU_nodes/#node-types","text":"You can view the hardware specifications for GPU node types on the RC Systems Platforms Overview page. There are GPU nodes available in Legion and Myriad.","title":"Node Types"},{"location":"Wiki_Export/done/GPU_nodes/#legion-type-p-gpu-node","text":"There is one NVIDIA K40c GPU node in Legion. To use this, you need to specify this in your jobscript or interactive qrsh request (remove the #$ for qrsh): #$ -l gpu=1","title":"Legion Type P GPU node"},{"location":"Wiki_Export/done/GPU_nodes/#myriad-type-j-gpu-nodes","text":"Myriad has two GPU nodes each with two NVIDIA Tesla P100s. To use them, you need to request one or two GPUs in your jobscript or interactive qrsh request (remove the #$ for qrsh): #$ -l gpu=2","title":"Myriad Type J GPU nodes"},{"location":"Wiki_Export/done/GPU_nodes/#available-modules","text":"You can see the available CUDA modules by typing `module avail cuda`","title":"Available modules"},{"location":"Wiki_Export/done/GPU_nodes/#sample-cuda-code","text":"There are samples in the CUDA install locations, e.g. /shared/ucl/apps/cuda/7.5.18/gnu-4.9.2/samples /shared/ucl/apps/cuda/8.0.61/gnu-4.9.2/samples which are further documented by NVIDIA here . In general, you should look at their CUDA docs: http://docs.nvidia.com/cuda/","title":"Sample CUDA code"},{"location":"Wiki_Export/done/GPU_nodes/#sample-jobscripts","text":"You can see sample jobscripts here . Use this in your script to request up to 2 GPUs. `#$ -l gpu=2` Load GCC and the relevant CUDA module. module unload compilers mpi module load compilers/gnu/4.9.2 module load cuda/7.5.18/gnu-4.9.2","title":"Sample jobscripts"},{"location":"Wiki_Export/done/GPU_nodes/#running-the-sample-code","text":"To get started, here's how you would compile and run one of the cuda samples interactively on a user test node using a GPU. 1. Load the cuda module `module unload compilers mpi` `module load compilers/gnu/4.9.2` `module load cuda/7.5.18/gnu-4.9.2` 2. Copy the samples directory to somewhere in your home (or to Scratch if you're building on the GPU node or are going to want a job to write anything in the same directory). cp -r /shared/ucl/apps/cuda/7.5.18/gnu-4.9.2/NVIDIA_CUDA-7.5_Samples/ ~/cuda 3. Choose an example: eigenvalues in this case, and build using the provided makefile - if you have a look at it you can see it is using nvcc and g++. cd NVIDIA_CUDA-7.5_Samples/6_Advanced/eigenvalues/ make 4. Request an interactive job with a GPU and wait to be given access to the node. You will see your prompt change to indicate that you are on a different node than the login node once your qrsh request has been scheduled, and you can then continue. Load the cuda module on the node and run the program. qrsh -l mem=1G,h_rt=0:30:0,gpu=1 -now no module unload compilers mpi module load compilers/gnu/4.9.2 module load cuda/7.5.18 cd ~/cuda/NVIDIA_CUDA-7.5_Samples/6_Advanced/eigenvalues/ ./eigenvalues 5. Your output should look something like this: Starting eigenvalues GPU Device 0: \"Tesla M2070\" with compute capability 2.0 Matrix size: 2048 x 2048 Precision: 0.000010 Iterations to be timed: 100 Result filename: 'eigenvalues.dat' Gerschgorin interval: -2.894310 / 2.923303 Average time step 1: 26.739325 ms Average time step 2, one intervals: 9.031162 ms Average time step 2, mult intervals: 0.004330 ms Average time TOTAL: 35.806992 ms Test Succeeded!","title":"Running the sample code"},{"location":"Wiki_Export/done/GPU_nodes/#building-your-own-code","text":"Please note: if the code you are trying to compile needs to link libcuda, it must also be built on a GPU node because only the GPU node has the correct libraries. The NVIDIA examples don't require this, but things like Tensorflow do.","title":"Building your own code"},{"location":"Wiki_Export/done/GPU_nodes/#tensorflow","text":"Tensorflow is installed: type module avail tensorflow to see the available versions. Modules to load for the non-MKL GPU version: module unload compilers mpi module load compilers/gnu/4.9.2 module load python3/recommended module load cuda/8.0.61-patch2/gnu-4.9.2 module load cudnn/6.0/cuda-8.0 module load tensorflow/1.4.1/gpu","title":"Tensorflow"},{"location":"Wiki_Export/done/GPU_nodes/#using-mpi-and-gpus","text":"It is possible to run MPI programs that use GPUs but only within a single node, so you can request 1 GPU and 12 processor cores on Legion, or up to 2 GPUs and 36 cores on Myriad.","title":"Using MPI and GPUs"},{"location":"Wiki_Export/done/GPU_nodes/#looking-for-more-gpus","text":"GPU clusters available to UCL users .","title":"Looking for more GPUs?"},{"location":"Wiki_Export/done/Installing_PGI/","text":"PGI Compiler Suite Installation at UCL \u00b6 UCL has two floating licences for PGI Fortran/C/C++ Server for Linux, purchased primarily for building Gaussian 03 and Gaussian 09 on UCL computers. To install follow the procedure below. If you are installing on a system outside the Institutional Firewall, please connect to the UCL VPN service first. Download version 13.9 or 11.9 from the UCL Software Database on your Linux system in a empty directory. You will need to login with your UCL userid and password. Untar the installer files using: tar xvzf pgilinux-2013-139.tar.gz Run the installer as root and follow the instructions: ./install During the installation you will be asked: Do you wish to generate license keys? (y/n) - Enter n as you will need to use the central UCL licence server. Add the PGI Suite bin directory to your PATH. The default location used by the installer is /opt/pgi/linux86-64/13.9/bin . Open access to TCP ports 27000 and 27055 in your local firewall and any departmental firewall. Setup access to the licence server by setting the LM_LICENSE_FILE environment variable. Use either: export LM_LICENSE_FILE=27000@lic-pgi.ucl.ac.uk export LM_LICENSE_FILE=$LM_LICENSE_FILE:27000@lic-pgi.ucl.ac.uk Use the second version if you have other licence managers already defined. The PGI compilers should now be installed and working.","title":"Installing PGI"},{"location":"Wiki_Export/done/Installing_PGI/#pgi-compiler-suite-installation-at-ucl","text":"UCL has two floating licences for PGI Fortran/C/C++ Server for Linux, purchased primarily for building Gaussian 03 and Gaussian 09 on UCL computers. To install follow the procedure below. If you are installing on a system outside the Institutional Firewall, please connect to the UCL VPN service first. Download version 13.9 or 11.9 from the UCL Software Database on your Linux system in a empty directory. You will need to login with your UCL userid and password. Untar the installer files using: tar xvzf pgilinux-2013-139.tar.gz Run the installer as root and follow the instructions: ./install During the installation you will be asked: Do you wish to generate license keys? (y/n) - Enter n as you will need to use the central UCL licence server. Add the PGI Suite bin directory to your PATH. The default location used by the installer is /opt/pgi/linux86-64/13.9/bin . Open access to TCP ports 27000 and 27055 in your local firewall and any departmental firewall. Setup access to the licence server by setting the LM_LICENSE_FILE environment variable. Use either: export LM_LICENSE_FILE=27000@lic-pgi.ucl.ac.uk export LM_LICENSE_FILE=$LM_LICENSE_FILE:27000@lic-pgi.ucl.ac.uk Use the second version if you have other licence managers already defined. The PGI compilers should now be installed and working.","title":"PGI Compiler Suite Installation at UCL"},{"location":"Wiki_Export/done/Interactive_Sessions/","text":"For an interactive session, you reserve some compute nodes via the scheduler and then are logged in live, just like on the login nodes. These can be used for live visualisation, software debugging, or to work up a script to run your program without having to submit each attempt separately to the queue and wait for it to complete. Please note that time limits are restricted to two hours for interactive sessions, and available core counts are limited. Requesting Access \u00b6 You will be granted an interactive shell after running a command that checks with the scheduler whether the resources you wish to use in your tests/analysis are available. It typically takes the form: qrsh -pe mpi 8 -l mem=512M,h_rt=2:00:00 -now no In this example you are asking to run eight parallel processes within an MPI environment, 512MB RAM per process, for a period of two hours (the maximum allowed for interactive sessions). All job types we support on the system are supported via an interactive session (see our examples section ). Likewise, all qsub options are supported like regular job submission with the difference that with qrsh they must be given at the command line, and not with any job script (or via -@). In addition the -now option is useful when a cluster is busy. By default qrsh and qlogin jobs will run on the next scheduling cycle or give up. The -now no option tells it to keep waiting until it gets scheduled.\u2028Pressing Ctrl+C (i.e. the control key and the C key at the same time) will safely cancel the request if it doesn't seem to be able to get you a session. Interactive X sessions \u00b6 You can get an interactive X session from the head node of the job back to the login\u2028 node. The way to do this is to run the qrsh command in the following generic fashion: qrsh <options> <command> <arguments to <command>> Where <command> is either a command to launch an X terminal like Xterm or Mrxvt or a GUI application like XMGrace or GaussView. To make effective use of the X forwarding you will need to have logged in to the login node with ssh -X or some equivalent method.\u2028\u2028 Here is an example of how you can get a X terminal session with the qrsh command:\u2028 qrsh -l mem=512M,h_rt=0:30:0 \\ /shared/ucl/apps/mrxvt/0.5.4/bin/mrxvt -title 'User Test Node' Working on the nodes \u00b6 If you want to run a command on one of your allocated nodes which is not the headnode, you can use a standard ssh command: ssh <hostname> <command> [args] Where <hostname> can be obtained by inspecting the file $TMPDIR/machines. GPU test nodes \u00b6 You can also run GPU jobs interactively simply by adding the -l gpu=1 or -l gpu=2 options to the qrsh command. For more information, please contact us on rc-support@ucl.ac.uk","title":"Interactive Sessions"},{"location":"Wiki_Export/done/Interactive_Sessions/#requesting-access","text":"You will be granted an interactive shell after running a command that checks with the scheduler whether the resources you wish to use in your tests/analysis are available. It typically takes the form: qrsh -pe mpi 8 -l mem=512M,h_rt=2:00:00 -now no In this example you are asking to run eight parallel processes within an MPI environment, 512MB RAM per process, for a period of two hours (the maximum allowed for interactive sessions). All job types we support on the system are supported via an interactive session (see our examples section ). Likewise, all qsub options are supported like regular job submission with the difference that with qrsh they must be given at the command line, and not with any job script (or via -@). In addition the -now option is useful when a cluster is busy. By default qrsh and qlogin jobs will run on the next scheduling cycle or give up. The -now no option tells it to keep waiting until it gets scheduled.\u2028Pressing Ctrl+C (i.e. the control key and the C key at the same time) will safely cancel the request if it doesn't seem to be able to get you a session.","title":"Requesting Access"},{"location":"Wiki_Export/done/Interactive_Sessions/#interactive-x-sessions","text":"You can get an interactive X session from the head node of the job back to the login\u2028 node. The way to do this is to run the qrsh command in the following generic fashion: qrsh <options> <command> <arguments to <command>> Where <command> is either a command to launch an X terminal like Xterm or Mrxvt or a GUI application like XMGrace or GaussView. To make effective use of the X forwarding you will need to have logged in to the login node with ssh -X or some equivalent method.\u2028\u2028 Here is an example of how you can get a X terminal session with the qrsh command:\u2028 qrsh -l mem=512M,h_rt=0:30:0 \\ /shared/ucl/apps/mrxvt/0.5.4/bin/mrxvt -title 'User Test Node'","title":"Interactive X sessions"},{"location":"Wiki_Export/done/Interactive_Sessions/#working-on-the-nodes","text":"If you want to run a command on one of your allocated nodes which is not the headnode, you can use a standard ssh command: ssh <hostname> <command> [args] Where <hostname> can be obtained by inspecting the file $TMPDIR/machines.","title":"Working on the nodes"},{"location":"Wiki_Export/done/Interactive_Sessions/#gpu-test-nodes","text":"You can also run GPU jobs interactively simply by adding the -l gpu=1 or -l gpu=2 options to the qrsh command. For more information, please contact us on rc-support@ucl.ac.uk","title":"GPU test nodes"},{"location":"Wiki_Export/done/Known_Issues/","text":"This page contains known issues and proposed work-arounds, if available. Check our issue tracker on GitHub . Github clones are regularly stalling after a small percentage \u00b6 This can happen on Legion's login nodes and appears to be an as-yet-unidentified network issue. Try sshing into the dedicated transfer node login05.external.legion.ucl.ac.uk as this has a slightly different setup which does not appear to have the problem.","title":"Known Issues"},{"location":"Wiki_Export/done/Known_Issues/#github-clones-are-regularly-stalling-after-a-small-percentage","text":"This can happen on Legion's login nodes and appears to be an as-yet-unidentified network issue. Try sshing into the dedicated transfer node login05.external.legion.ucl.ac.uk as this has a slightly different setup which does not appear to have the problem.","title":"Github clones are regularly stalling after a small percentage"},{"location":"Wiki_Export/done/Main_Page/","text":"This documentation is maintained by the research computing team for the purpose of sharing information about our services, including user guides, service updates and account request and renewal support. Documentation \u00b6 General User Information: Getting an Account User Guide Clusters: Legion Myriad Grace Thomas Michael Service Information \u00b6 Planned Outages Requesting Additional Resources Email Support \u00b6 For support for any of our services, contact us at: rc-support@ucl.ac.uk We will endeavour to answer queries on any aspect of computing related to your research whatever your skill level or requirements. How to... \u00b6 Connect to the Research Data Storage service Report a problem with one of our computing platforms Access services from outside UCL Apply for access to national GPU clusters Training \u00b6 We infrequently provide a training course aimed at getting users up and running on one of our main clusters. Please see our Training page for details.","title":"Research Computing Services"},{"location":"Wiki_Export/done/Main_Page/#documentation","text":"General User Information: Getting an Account User Guide Clusters: Legion Myriad Grace Thomas Michael","title":"Documentation"},{"location":"Wiki_Export/done/Main_Page/#service-information","text":"Planned Outages Requesting Additional Resources","title":"Service Information"},{"location":"Wiki_Export/done/Main_Page/#email-support","text":"For support for any of our services, contact us at: rc-support@ucl.ac.uk We will endeavour to answer queries on any aspect of computing related to your research whatever your skill level or requirements.","title":"Email Support"},{"location":"Wiki_Export/done/Main_Page/#how-to","text":"Connect to the Research Data Storage service Report a problem with one of our computing platforms Access services from outside UCL Apply for access to national GPU clusters","title":"How to..."},{"location":"Wiki_Export/done/Main_Page/#training","text":"We infrequently provide a training course aimed at getting users up and running on one of our main clusters. Please see our Training page for details.","title":"Training"},{"location":"Wiki_Export/done/Michael/","text":"Michael is an extension to the UCL-hosted Hub for Materials and Molecular Modelling, an EPSRC-funded Tier 2 system providing large scale computation to UK researchers; and delivers computational capability for the Faraday Institution, a national institute for electrochemical energy storage science and technology. Applying for an account \u00b6 Michael accounts belong to you as an individual and are applied for via David Scanlon who is the point of contact for Michael. You will need to supply an SSH public key, which is the only method used to log in. Creating an ssh key pair \u00b6 An ssh key consists of a public and a private part, typically named id_rsa and id_rsa.pub by default. The public part is what we need. You must not share your private key with anyone else. You can copy it onto multiple machines belonging to you so you can log in from all of them (or you can have a separate pair for each machine). Creating an ssh key in Linux/Unix/Mac OS X \u00b6 ssh-keygen -t rsa The defaults should give you a reasonable key. If you prefer to use ECDSA or ED25519 instead, and longer keys, you can. You can also tell it to create one with a different name, so it doesn't overwrite any existing key. We strongly suggest you not use DSA as OpenSSH 7.0 has deprecated it and does not use it by default on client or server. Michael currently accepts them but that may change. You will be asked to add a passphrase for your key. A blank passphrase is not recommended; if you use one please make sure that no one else ever has access to your local computer account. How often you are asked for a passphrase depends on how long your local ssh agent keeps it. You may need to run ssh-add to add the key to your agent so you can use it. If you aren't sure what keys your agent can see, running ssh-add -L will show all the public parts of the keys it is aware of. Creating an ssh key in Windows \u00b6 Have a look at Key-Based SSH Logins With PuTTY which has step-by-step instructions. You can choose whether to use Pageant or not to manage your key. You can again pick RSA, DSA, ECDSA etc but do not pick SSH-1 as that is a very old and insecure key type. Information for Points of Contact \u00b6 Points of Contact have some tools they can use to manage users and allocations, documented at Points of Contact . Logging in \u00b6 You will be assigned a personal username and your SSH key pair will be used to log in. External users will have a username in the form mmmxxxx and UCL users will use their central username. You connect with ssh directly to: michael.rc.ucl.ac.uk SSH timeouts \u00b6 Idle ssh sessions will be disconnected after 7 days. Using the system \u00b6 Michael is a batch system. The login nodes allow you to manage your files, compile code and submit jobs. Very short (\\<15mins) and non-resource-intensive software tests can be run on the login nodes, but anything more should be submitted as a job. Full user guide \u00b6 Michael has the same user environment as RC Support's other clusters, so the User Guide is relevant and is a good starting point for further information about how the environment works. Any variations that Michael has should be listed on this page. Submitting a job \u00b6 Create a job script for non-interactive use and submit it using qsub . Jobscripts must begin #!/bin/bash -l in order to run as a login shell and get your login environment and modules. A job on Michael must also specify what type of job it is (Gold, Free, Test) and the project it is being submitted for. (See Budgets and allocations below). Memory requests \u00b6 Note: the memory you request is always per core, not the total amount. If you ask for 128G RAM and 24 cores, that will run on 24 nodes using only one core per node. This allows you to have sparse process placement when you do actually need that much RAM per process. Monitoring a job \u00b6 In addition to qstat , nodesforjob $JOB_ID can be useful to see what proportion of cpu/memory/swap is being used on the nodes a certain job is running on. qexplain $JOB_ID will show you the full error for a job that is in Eqw status. Useful utilities \u00b6 As well as nodesforjob , there are the following utilities which can help you find information about your jobs after they have run. jobhist - shows your job history for the last 24hrs by default, including start and end times and the head node it ran on. You can view a longer history by specifying --hours=100 for example. scriptfor $JOB_ID - show the script that was submitted for the given job. These utilities live in GitHub at https://github.com/UCL-RITS/go-clustertools and https://github.com/UCL-RITS/rcps-cluster-scripts Software \u00b6 Michael mounts the RC Systems software stack . Have a look at Applications for specific information on running some applications, including example scripts. The list there is not exhaustive. Access to software is managed through the use of modules. module avail shows all modules available. module list shows modules currently loaded. Access to licensed software may vary based on your host institution and project. Requesting software installs \u00b6 To request software installs, email us at the support address below or open an issue on our GitHub . You can see what software has already been requested in the Github issues and can add a comment if you're also interested in something already requested. Installing your own software \u00b6 You may install software in your own space. Please look at Compiling for tips. Maintaining a piece of software for a group \u00b6 It is possible for people to be given central areas to install software that they wish to make available to everyone or to a select group - generally because they are the developers or if they wish to use multiple versions or developer versions. The people given install access would then be responsible for managing and maintaining these installs. Licensed software \u00b6 Reserved application groups exist for software that requires them. The group name will begin with leg or lg . After we add you to one of these groups, the central group change will happen overnight. You can check your groups with the groups command. Please let us know your username when you ask to be added to a group. CASTEP : You/your group leader need to have signed up for a CASTEP license . Send us an acceptance email, or we can ask them to verify you have a license. You will then be added to the reserved application group lgcastep . If you are a member of UKCP you are already covered by a license and just need to tell us when you request access. CRYSTAL : You/your group leader need to have signed up for an Academic license. Crystal Solutions will send an email saying an account has been upgraded to \"Academic UK\" - forward that to us along with confirmation from the group leader that you should be in their group. You will be added to the legcryst group. DL_POLY : has individual licenses for specific versions. Sign up at DL_POLY's website and send us the acceptance email they give you. We will add you to the appropriate version's reserved application group, eg lgdlp408 . Gaussian : not currently accessible for non-UCL institutions. UCL having a site license and another institute having a site license does not allow users from the other institute to run Gaussian on UCL-owned hardware. VASP : When you request access you need to send us the name and email of the main VASP license holder along with the license number. We will then ask VASP if we can add you, and on confirmation can do so. We will add you to the legvasp reserved application group. You may also install your own copy in your home, and we provide a simple build script on Github (tested with VASP 5.4.4, no patches). You need to download the VASP source code and then you can run the script following the instructions at the top. Suggested job sizes \u00b6 The target job sizes for Michael are 48-120 cores (2-5 nodes). Jobs larger than this may have a longer queue time and are better suited to ARCHER, and single node jobs may be more suited to your local facilities. Maximum job resources \u00b6 Cores Max wallclock 864 48hrs On Michael, interactive sessions using qrsh have the same wallclock limit as other jobs. Nodes in Michael are 24 cores, 128GB RAM. The default maximum jobsize is 864 cores, to remain within the 36-node 1:1 nonblocking interconnect zones. Jobs on Michael do not share nodes . This means that if you request less than 24 cores, your job is still taking up an entire node and no other jobs can run on it, but some of the cores are idle. Whenever possible, request a number of cores that is a multiple of 24 for full usage of your nodes. There is a superqueue for use in exceptional circumstances that will allow access to a larger number of cores outside the nonblocking interconnect zones, going across the 3:1 interconnect between blocks. A third of each CU is accessible this way, roughly approximating a 1:1 connection. Access to the superqueue for larger jobs must be applied for: contact the support address below for details. Some normal multi-node jobs will use the superqueue - this is to make it easier for larger jobs to be scheduled, as otherwise they can have very long waits if every CU is half full. Budgets and allocations \u00b6 We have enabled Gold for allocation management. Jobs that are run under a project budget have higher priority than free non-budgeted jobs. All jobs need to specify what project they belong to, whether they are paid or free. To see the name of your project(s) and how much allocation that budget has, run the command budgets . $ budgets Project Machines Balance -------- -------- -------- Faraday_Test ANY 22781.89 Submitting a job under a project \u00b6 To submit a paid job that will take Gold from a particular project budget, add this to your jobscript: #$ -P Gold #$ -A MyProject To submit a free job that will not use up any Gold, use this instead: #$ -P Free #$ -A MyProject You can also submit testing jobs that will not use up any Gold, and will have higher priority than normal free jobs, but are limited to 2 nodes (48 cores) and 1 hour of walltime: #$ -P Test #$ -A MyProject Troubleshooting: Unable to verify membership of username in the policyjsv project \u00b6 Unable to run job: Rejected by policyjsv Unable to verify membership of `<username>` in the policyjsv project You asked for a Free job but didn't specify #$ -A MyProject in your jobscript. Gold charging \u00b6 When you submit a job, it will reserve the total number of core hours that the job script is asking for. When the job ends, the Gold will move from 'reserved' into charged. If the job doesn't run for the full time it asked for, the unused reserved portion will be refunded after the job ends. You cannot submit a job that you do not have the budget to run. Troubleshooting: Unable to verify sufficient material worth to submit this job \u00b6 Unable to run job: Rejected by policyjsv Reason:Unable to verify sufficient material worth to submit this job: Insufficient balance to reserve job This means you don't have enough Gold to cover the cores*wallclock time cost of the job you are trying to submit. You need to wait for queued jobs to finish and return unused Gold to your project, or submit a smaller/shorter job. Note that array jobs have to cover the whole cost of all the tasks at submit time. Job deletion \u00b6 If you qdel a submitted Gold job, the reserved Gold will be made available again. This is done by a cron job that runs every 15 minutes, so you may not see it back instantly. Support \u00b6 Email rc-support@ucl.ac.uk with any support queries. It will be helpful to include Michael in the subject along with some descriptive text about the type of problem, and you should mention your username in the body.","title":"Michael"},{"location":"Wiki_Export/done/Michael/#applying-for-an-account","text":"Michael accounts belong to you as an individual and are applied for via David Scanlon who is the point of contact for Michael. You will need to supply an SSH public key, which is the only method used to log in.","title":"Applying for an account"},{"location":"Wiki_Export/done/Michael/#creating-an-ssh-key-pair","text":"An ssh key consists of a public and a private part, typically named id_rsa and id_rsa.pub by default. The public part is what we need. You must not share your private key with anyone else. You can copy it onto multiple machines belonging to you so you can log in from all of them (or you can have a separate pair for each machine).","title":"Creating an ssh key pair"},{"location":"Wiki_Export/done/Michael/#creating-an-ssh-key-in-linuxunixmac-os-x","text":"ssh-keygen -t rsa The defaults should give you a reasonable key. If you prefer to use ECDSA or ED25519 instead, and longer keys, you can. You can also tell it to create one with a different name, so it doesn't overwrite any existing key. We strongly suggest you not use DSA as OpenSSH 7.0 has deprecated it and does not use it by default on client or server. Michael currently accepts them but that may change. You will be asked to add a passphrase for your key. A blank passphrase is not recommended; if you use one please make sure that no one else ever has access to your local computer account. How often you are asked for a passphrase depends on how long your local ssh agent keeps it. You may need to run ssh-add to add the key to your agent so you can use it. If you aren't sure what keys your agent can see, running ssh-add -L will show all the public parts of the keys it is aware of.","title":"Creating an ssh key in Linux/Unix/Mac OS X"},{"location":"Wiki_Export/done/Michael/#creating-an-ssh-key-in-windows","text":"Have a look at Key-Based SSH Logins With PuTTY which has step-by-step instructions. You can choose whether to use Pageant or not to manage your key. You can again pick RSA, DSA, ECDSA etc but do not pick SSH-1 as that is a very old and insecure key type.","title":"Creating an ssh key in Windows"},{"location":"Wiki_Export/done/Michael/#information-for-points-of-contact","text":"Points of Contact have some tools they can use to manage users and allocations, documented at Points of Contact .","title":"Information for Points of Contact"},{"location":"Wiki_Export/done/Michael/#logging-in","text":"You will be assigned a personal username and your SSH key pair will be used to log in. External users will have a username in the form mmmxxxx and UCL users will use their central username. You connect with ssh directly to: michael.rc.ucl.ac.uk","title":"Logging in"},{"location":"Wiki_Export/done/Michael/#ssh-timeouts","text":"Idle ssh sessions will be disconnected after 7 days.","title":"SSH timeouts"},{"location":"Wiki_Export/done/Michael/#using-the-system","text":"Michael is a batch system. The login nodes allow you to manage your files, compile code and submit jobs. Very short (\\<15mins) and non-resource-intensive software tests can be run on the login nodes, but anything more should be submitted as a job.","title":"Using the system"},{"location":"Wiki_Export/done/Michael/#full-user-guide","text":"Michael has the same user environment as RC Support's other clusters, so the User Guide is relevant and is a good starting point for further information about how the environment works. Any variations that Michael has should be listed on this page.","title":"Full user guide"},{"location":"Wiki_Export/done/Michael/#submitting-a-job","text":"Create a job script for non-interactive use and submit it using qsub . Jobscripts must begin #!/bin/bash -l in order to run as a login shell and get your login environment and modules. A job on Michael must also specify what type of job it is (Gold, Free, Test) and the project it is being submitted for. (See Budgets and allocations below).","title":"Submitting a job"},{"location":"Wiki_Export/done/Michael/#memory-requests","text":"Note: the memory you request is always per core, not the total amount. If you ask for 128G RAM and 24 cores, that will run on 24 nodes using only one core per node. This allows you to have sparse process placement when you do actually need that much RAM per process.","title":"Memory requests"},{"location":"Wiki_Export/done/Michael/#monitoring-a-job","text":"In addition to qstat , nodesforjob $JOB_ID can be useful to see what proportion of cpu/memory/swap is being used on the nodes a certain job is running on. qexplain $JOB_ID will show you the full error for a job that is in Eqw status.","title":"Monitoring a job"},{"location":"Wiki_Export/done/Michael/#useful-utilities","text":"As well as nodesforjob , there are the following utilities which can help you find information about your jobs after they have run. jobhist - shows your job history for the last 24hrs by default, including start and end times and the head node it ran on. You can view a longer history by specifying --hours=100 for example. scriptfor $JOB_ID - show the script that was submitted for the given job. These utilities live in GitHub at https://github.com/UCL-RITS/go-clustertools and https://github.com/UCL-RITS/rcps-cluster-scripts","title":"Useful utilities"},{"location":"Wiki_Export/done/Michael/#software","text":"Michael mounts the RC Systems software stack . Have a look at Applications for specific information on running some applications, including example scripts. The list there is not exhaustive. Access to software is managed through the use of modules. module avail shows all modules available. module list shows modules currently loaded. Access to licensed software may vary based on your host institution and project.","title":"Software"},{"location":"Wiki_Export/done/Michael/#requesting-software-installs","text":"To request software installs, email us at the support address below or open an issue on our GitHub . You can see what software has already been requested in the Github issues and can add a comment if you're also interested in something already requested.","title":"Requesting software installs"},{"location":"Wiki_Export/done/Michael/#installing-your-own-software","text":"You may install software in your own space. Please look at Compiling for tips.","title":"Installing your own software"},{"location":"Wiki_Export/done/Michael/#maintaining-a-piece-of-software-for-a-group","text":"It is possible for people to be given central areas to install software that they wish to make available to everyone or to a select group - generally because they are the developers or if they wish to use multiple versions or developer versions. The people given install access would then be responsible for managing and maintaining these installs.","title":"Maintaining a piece of software for a group"},{"location":"Wiki_Export/done/Michael/#licensed-software","text":"Reserved application groups exist for software that requires them. The group name will begin with leg or lg . After we add you to one of these groups, the central group change will happen overnight. You can check your groups with the groups command. Please let us know your username when you ask to be added to a group. CASTEP : You/your group leader need to have signed up for a CASTEP license . Send us an acceptance email, or we can ask them to verify you have a license. You will then be added to the reserved application group lgcastep . If you are a member of UKCP you are already covered by a license and just need to tell us when you request access. CRYSTAL : You/your group leader need to have signed up for an Academic license. Crystal Solutions will send an email saying an account has been upgraded to \"Academic UK\" - forward that to us along with confirmation from the group leader that you should be in their group. You will be added to the legcryst group. DL_POLY : has individual licenses for specific versions. Sign up at DL_POLY's website and send us the acceptance email they give you. We will add you to the appropriate version's reserved application group, eg lgdlp408 . Gaussian : not currently accessible for non-UCL institutions. UCL having a site license and another institute having a site license does not allow users from the other institute to run Gaussian on UCL-owned hardware. VASP : When you request access you need to send us the name and email of the main VASP license holder along with the license number. We will then ask VASP if we can add you, and on confirmation can do so. We will add you to the legvasp reserved application group. You may also install your own copy in your home, and we provide a simple build script on Github (tested with VASP 5.4.4, no patches). You need to download the VASP source code and then you can run the script following the instructions at the top.","title":"Licensed software"},{"location":"Wiki_Export/done/Michael/#suggested-job-sizes","text":"The target job sizes for Michael are 48-120 cores (2-5 nodes). Jobs larger than this may have a longer queue time and are better suited to ARCHER, and single node jobs may be more suited to your local facilities.","title":"Suggested job sizes"},{"location":"Wiki_Export/done/Michael/#maximum-job-resources","text":"Cores Max wallclock 864 48hrs On Michael, interactive sessions using qrsh have the same wallclock limit as other jobs. Nodes in Michael are 24 cores, 128GB RAM. The default maximum jobsize is 864 cores, to remain within the 36-node 1:1 nonblocking interconnect zones. Jobs on Michael do not share nodes . This means that if you request less than 24 cores, your job is still taking up an entire node and no other jobs can run on it, but some of the cores are idle. Whenever possible, request a number of cores that is a multiple of 24 for full usage of your nodes. There is a superqueue for use in exceptional circumstances that will allow access to a larger number of cores outside the nonblocking interconnect zones, going across the 3:1 interconnect between blocks. A third of each CU is accessible this way, roughly approximating a 1:1 connection. Access to the superqueue for larger jobs must be applied for: contact the support address below for details. Some normal multi-node jobs will use the superqueue - this is to make it easier for larger jobs to be scheduled, as otherwise they can have very long waits if every CU is half full.","title":"Maximum job resources"},{"location":"Wiki_Export/done/Michael/#budgets-and-allocations","text":"We have enabled Gold for allocation management. Jobs that are run under a project budget have higher priority than free non-budgeted jobs. All jobs need to specify what project they belong to, whether they are paid or free. To see the name of your project(s) and how much allocation that budget has, run the command budgets . $ budgets Project Machines Balance -------- -------- -------- Faraday_Test ANY 22781.89","title":"Budgets and allocations"},{"location":"Wiki_Export/done/Michael/#submitting-a-job-under-a-project","text":"To submit a paid job that will take Gold from a particular project budget, add this to your jobscript: #$ -P Gold #$ -A MyProject To submit a free job that will not use up any Gold, use this instead: #$ -P Free #$ -A MyProject You can also submit testing jobs that will not use up any Gold, and will have higher priority than normal free jobs, but are limited to 2 nodes (48 cores) and 1 hour of walltime: #$ -P Test #$ -A MyProject","title":"Submitting a job under a project"},{"location":"Wiki_Export/done/Michael/#troubleshooting-unable-to-verify-membership-of-username-in-the-policyjsv-project","text":"Unable to run job: Rejected by policyjsv Unable to verify membership of `<username>` in the policyjsv project You asked for a Free job but didn't specify #$ -A MyProject in your jobscript.","title":"Troubleshooting: Unable to verify membership of username in the policyjsv project"},{"location":"Wiki_Export/done/Michael/#gold-charging","text":"When you submit a job, it will reserve the total number of core hours that the job script is asking for. When the job ends, the Gold will move from 'reserved' into charged. If the job doesn't run for the full time it asked for, the unused reserved portion will be refunded after the job ends. You cannot submit a job that you do not have the budget to run.","title":"Gold charging"},{"location":"Wiki_Export/done/Michael/#troubleshooting-unable-to-verify-sufficient-material-worth-to-submit-this-job","text":"Unable to run job: Rejected by policyjsv Reason:Unable to verify sufficient material worth to submit this job: Insufficient balance to reserve job This means you don't have enough Gold to cover the cores*wallclock time cost of the job you are trying to submit. You need to wait for queued jobs to finish and return unused Gold to your project, or submit a smaller/shorter job. Note that array jobs have to cover the whole cost of all the tasks at submit time.","title":"Troubleshooting: Unable to verify sufficient material worth to submit this job"},{"location":"Wiki_Export/done/Michael/#job-deletion","text":"If you qdel a submitted Gold job, the reserved Gold will be made available again. This is done by a cron job that runs every 15 minutes, so you may not see it back instantly.","title":"Job deletion"},{"location":"Wiki_Export/done/Michael/#support","text":"Email rc-support@ucl.ac.uk with any support queries. It will be helpful to include Michael in the subject along with some descriptive text about the type of problem, and you should mention your username in the body.","title":"Support"},{"location":"Wiki_Export/done/Myriad/","text":"Myriad is designed for high I/O, high throughput jobs that will run within a single node rather than multi-node parallel jobs. Accounts \u00b6 Everyone who signs up for a Research Computing account gets access to Myriad. Logging in \u00b6 You will use your UCL username and password to ssh in to Myriad. ssh uccaxxx@myriad.rc.ucl.ac.uk If using PuTTY, put myriad.rc.ucl.ac.uk as the hostname and your seven-character username (with no @ after) as the username when logging in, eg. uccaxxx . When entering your password in PuTTY no characters or bulletpoints will show on screen - this is normal. If you are outside the UCL firewall you will need to follow the instructions for accessing services from outside UCL . Logging in to a specific node \u00b6 You can access a specific Myriad login node with: ssh uccaxxx@login12.myriad.rc.ucl.ac.uk ssh uccaxxx@login13.myriad.rc.ucl.ac.uk The main address will redirect you on to either one of them. Copying data onto Myriad \u00b6 You will need to use an SCP or SFTP client to copy data onto Myriad. Have a look at Managing Data on RC Systems . Quotas \u00b6 The default quotas on Myriad are 150GB for home and 1TB for Scratch. These are hard quotas: once you reach them, you will no longer be able to write more data. Keep an eye on them, as this will cause jobs to fail if they cannot create their .o or .e files at the start, or their output files partway through. You can check both quotas on Myriad by running: lquota which will give you output similar to this: LUSTRE SCRATCH USAGE/QUOTA userid quota usage percent Filesystem uccaxxx 150GB 0GB 0.00% /home/uccaxxx uccaxxx 1024GB 0GB 0.00% /scratch/scratch/uccaxxx You can apply for quota increases using the form at Additional Resource Requests . Here are some tips for managing your quota and finding where space is being used. Job sizes \u00b6 Cores Max wallclock 1 72hrs 2 to 36 48hrs Interactive jobs run with qrsh have a maximum wallclock time of 2 hours. Node types \u00b6 Myriad contains three node types: standard compute nodes, high memory nodes and GPU nodes. Type Cores per node RAM per node Nodes H 36 192GB 48 I 36 1.5TB 2 J 36 + 2 GPUs 192GB 2 You can tell the type of a node by its name: type H nodes are named node-h00a-001 etc. GPUs \u00b6 Myriad has two GPU nodes, each with two nVidia Tesla P100s. You can request one or two GPUs by adding them as a resource request to your jobscript: # For 1 GPU #$ -l gpu=1 # For 2 GPUs #$ -l gpu=2 The GPU nodes page has some sample code for running GPU jobs if you need a test example. Tensorflow \u00b6 Tensorflow is installed: type module avail tensorflow to see the available versions. Modules to load for the non-MKL GPU version: module unload compilers mpi module load compilers/gnu/4.9.2 module load python3/recommended module load cuda/8.0.61-patch2/gnu-4.9.2 module load cudnn/6.0/cuda-8.0 module load tensorflow/1.4.1/gpu","title":"Myriad"},{"location":"Wiki_Export/done/Myriad/#accounts","text":"Everyone who signs up for a Research Computing account gets access to Myriad.","title":"Accounts"},{"location":"Wiki_Export/done/Myriad/#logging-in","text":"You will use your UCL username and password to ssh in to Myriad. ssh uccaxxx@myriad.rc.ucl.ac.uk If using PuTTY, put myriad.rc.ucl.ac.uk as the hostname and your seven-character username (with no @ after) as the username when logging in, eg. uccaxxx . When entering your password in PuTTY no characters or bulletpoints will show on screen - this is normal. If you are outside the UCL firewall you will need to follow the instructions for accessing services from outside UCL .","title":"Logging in"},{"location":"Wiki_Export/done/Myriad/#logging-in-to-a-specific-node","text":"You can access a specific Myriad login node with: ssh uccaxxx@login12.myriad.rc.ucl.ac.uk ssh uccaxxx@login13.myriad.rc.ucl.ac.uk The main address will redirect you on to either one of them.","title":"Logging in to a specific node"},{"location":"Wiki_Export/done/Myriad/#copying-data-onto-myriad","text":"You will need to use an SCP or SFTP client to copy data onto Myriad. Have a look at Managing Data on RC Systems .","title":"Copying data onto Myriad"},{"location":"Wiki_Export/done/Myriad/#quotas","text":"The default quotas on Myriad are 150GB for home and 1TB for Scratch. These are hard quotas: once you reach them, you will no longer be able to write more data. Keep an eye on them, as this will cause jobs to fail if they cannot create their .o or .e files at the start, or their output files partway through. You can check both quotas on Myriad by running: lquota which will give you output similar to this: LUSTRE SCRATCH USAGE/QUOTA userid quota usage percent Filesystem uccaxxx 150GB 0GB 0.00% /home/uccaxxx uccaxxx 1024GB 0GB 0.00% /scratch/scratch/uccaxxx You can apply for quota increases using the form at Additional Resource Requests . Here are some tips for managing your quota and finding where space is being used.","title":"Quotas"},{"location":"Wiki_Export/done/Myriad/#job-sizes","text":"Cores Max wallclock 1 72hrs 2 to 36 48hrs Interactive jobs run with qrsh have a maximum wallclock time of 2 hours.","title":"Job sizes"},{"location":"Wiki_Export/done/Myriad/#node-types","text":"Myriad contains three node types: standard compute nodes, high memory nodes and GPU nodes. Type Cores per node RAM per node Nodes H 36 192GB 48 I 36 1.5TB 2 J 36 + 2 GPUs 192GB 2 You can tell the type of a node by its name: type H nodes are named node-h00a-001 etc.","title":"Node types"},{"location":"Wiki_Export/done/Myriad/#gpus","text":"Myriad has two GPU nodes, each with two nVidia Tesla P100s. You can request one or two GPUs by adding them as a resource request to your jobscript: # For 1 GPU #$ -l gpu=1 # For 2 GPUs #$ -l gpu=2 The GPU nodes page has some sample code for running GPU jobs if you need a test example.","title":"GPUs"},{"location":"Wiki_Export/done/Myriad/#tensorflow","text":"Tensorflow is installed: type module avail tensorflow to see the available versions. Modules to load for the non-MKL GPU version: module unload compilers mpi module load compilers/gnu/4.9.2 module load python3/recommended module load cuda/8.0.61-patch2/gnu-4.9.2 module load cudnn/6.0/cuda-8.0 module load tensorflow/1.4.1/gpu","title":"Tensorflow"},{"location":"Wiki_Export/done/News_and_Events/","text":"Recent News and Upcoming Events \u00b6 Previous Events \u00b6","title":"News and Events"},{"location":"Wiki_Export/done/News_and_Events/#recent-news-and-upcoming-events","text":"","title":"Recent News and Upcoming Events"},{"location":"Wiki_Export/done/News_and_Events/#previous-events","text":"","title":"Previous Events"},{"location":"Wiki_Export/done/Paid-For_Resources/","text":"Users with access to paid resources have some extra flags and a tool for monitoring their nodes. Jobscript additions \u00b6 For a job to be eligible to run on your nodes, you will need to specify your project in your jobscript: # Specify project #$ -P <project> This will allow a job to run on your nodes, but it can also be scheduled on general-use nodes if some are available first. This should be the main way you run jobs. If you need to, you can force jobs to run on your nodes only. This is suitable when you have arranged policies on your nodes that are different from the normal policies, as it allows you to override them. # Specify paid flag to force running on your nodes only, with your policies #$ -l paid=1 Check what is running on your nodes \u00b6 We have a whatsonmynode script that does a qhost -j on each of the nodes belonging to your project, so you can see which nodes you have, what is running on them and from which user. module load userscripts whatsonmynode <project> Nodetypes \u00b6 Legion nodes are named beginning with node-[pqstuvxyz] so you can tell the nodetype from the name. The standard option for paid nodes is type U - the exact hardware varies over time as newer ones are bought, so U nodes are similar rather than identical. Backfill \u00b6 In our usual arrangement, paid-for nodes are available for backfill from other users when you have not been using them. The policy is set by the CRAG: this is the current policy as of November 2015. When you have not run a job on an individual node for 48hrs, then it becomes available for general use jobs of up to 12hrs. When you submit a new job, the queues will not allow any other general use jobs on to your nodes, but the ones currently running will complete. The maximum wait time for your job is hence 12hrs. Other options may be discussed at time of purchase if this is not suitable.","title":"Paid-For Resources"},{"location":"Wiki_Export/done/Paid-For_Resources/#jobscript-additions","text":"For a job to be eligible to run on your nodes, you will need to specify your project in your jobscript: # Specify project #$ -P <project> This will allow a job to run on your nodes, but it can also be scheduled on general-use nodes if some are available first. This should be the main way you run jobs. If you need to, you can force jobs to run on your nodes only. This is suitable when you have arranged policies on your nodes that are different from the normal policies, as it allows you to override them. # Specify paid flag to force running on your nodes only, with your policies #$ -l paid=1","title":"Jobscript additions"},{"location":"Wiki_Export/done/Paid-For_Resources/#check-what-is-running-on-your-nodes","text":"We have a whatsonmynode script that does a qhost -j on each of the nodes belonging to your project, so you can see which nodes you have, what is running on them and from which user. module load userscripts whatsonmynode <project>","title":"Check what is running on your nodes"},{"location":"Wiki_Export/done/Paid-For_Resources/#nodetypes","text":"Legion nodes are named beginning with node-[pqstuvxyz] so you can tell the nodetype from the name. The standard option for paid nodes is type U - the exact hardware varies over time as newer ones are bought, so U nodes are similar rather than identical.","title":"Nodetypes"},{"location":"Wiki_Export/done/Paid-For_Resources/#backfill","text":"In our usual arrangement, paid-for nodes are available for backfill from other users when you have not been using them. The policy is set by the CRAG: this is the current policy as of November 2015. When you have not run a job on an individual node for 48hrs, then it becomes available for general use jobs of up to 12hrs. When you submit a new job, the queues will not allow any other general use jobs on to your nodes, but the ones currently running will complete. The maximum wait time for your job is hence 12hrs. Other options may be discussed at time of purchase if this is not suitable.","title":"Backfill"},{"location":"Wiki_Export/done/Planned_Service_Outages/","text":"Below is the list of planned outages, partial or otherwise, which Research Computing Platforms will have to undergo for service improvements or due to external dependencies, such as data centre infrastructural works. Date: specifies the period of time during which the outage is expected to take place. Service Impact: details the Service and specific hardware affected by the outage. Comments: provides additional information such as details about how the service will be affected and advice. Date Service Impact Comments Thurs 24 May 2018 Legion partial outage Node types LMNOQSUY will be drained for 8am for work to take place on the power to the racks in TP3 datacentre. Node types XPTVZ will be running jobs. This work is not expected to take all day. Tues 10 - Thurs 12 Apr 2018 Thomas full outage Update of Lustre firmware. Jobs will be drained for 8am on 10th and the cluster will be out of service for that day, login nodes included. Possibility of overrun and 13th should be considered at risk. Outage extended by one day as a member of staff was required on site in the datacentre. Tues 27 - Weds 28 Feb 2018 Thomas full outage Update of Lustre firmware. Jobs will be drained for 8am on 27th and the cluster will be out of service for that day, login nodes included. Possibility of overrun and 28th should be considered at risk. ''(This was rescheduled to April due to strike action.)'' Fri 17 Nov - Mon 20 Nov 2017 Legion partial outage All the L, M, N, O, P, S, U and Y nodes are draining for 3pm on Friday 17th November so nodes and infrastructure currently in Wolfson House datacentre can be moved back out. Login08 is also being moved. We will attempt to have everything back online during Monday. Weds 27 Sept - Mon 2 Oct 2017 Grace outage Our vendors need to replace some hardware components and run further tests. Grace will be unavailable for submissions or data access from 08:00 on Wed 27th Sep 2017. The service will be restored at or before 10:00 on Mon 02 Oct 2017. Following this, Intel expect to issue a permanent firmware fix within two months, likely requiring a further downtime period. 31 July 2017 Grace queue lengths and outage Another outage is required for OCF to replace the broken cable. Mon 31st July will be an all-day outage. Full-length jobs will be running over the weekend. Thurs 20 July 2017 Grace outage Grace is being drained on the 19th so OCF can swap a cable that has problems. This work is expected to be finished at some point in the afternoon. There is likely to be another day's outage at a later date to replace it - we do not have details at present. Thurs 22 June 2017 Legion outage We will be updating the firmware of Legion's Lustre metadata controller. Jobs are being drained and Legion will be down entirely for the morning and at risk in the afternoon. Thurs 15 June 2017 Thomas outage Thomas will have a brief outage in the morning for us to reconfigure it to have no link to Grace's Infiniband. Home directories are being moved (data is being rsynced to Thomas' Lustre). The queues are being drained in preparation. Weds 14 - Thurs 15 June 2017 Grace outage Grace is down today in preparation to reconfigure the Infiniband network so there is no link to Thomas, which we believe is causing the problems. We will bring Grace back up later on Thursday and hopefully the issues will be resolved. Weds 17 May 2017 Grace and Thomas outage A faulty module is being replaced in a Grace switch. The queues have been drained so jobs are not running. This should allow the subset of Grace nodes that are still down to be brought back into use. Mon 8 May 2017 Grace and Thomas outage Cables needed to be switched in order for the work intended for the previous outage to be carried out, and the switch has been done. The queues are being drained for 10am and will be re-enabled as soon as we know no further work needs to be carried out. Jobs will run over the weekend but will not start if they do not have time to finish. Thurs 4 - Fri 5 May 2017 Grace and Thomas outage Our vendors are doing some work on the network equipment in Grace (we narrowed down the Infiniband problems to specific switches). Jobs on Grace and Thomas are drained. Thomas login nodes will not be available. Thurs 27 April 2017 Grace and Thomas outage We are investigating intermittent Infiniband problems on Grace and jobs have been drained for today. We cannot guarantee that the login nodes will remain available. (Thomas is still in pilot, but this may also make home directories inaccessible for parts of the day and affect running jobs). Sun 26th - Tues 28th Feb 2017 Legion outage We are replacing the NFS file servers on Legion with upgraded ones and as a result there is a planned outage from 5PM Sunday 26th Feb until morning Tuesday 28th Feb. You will be unable to log into the service, existing logins will be logged out and jobs will not be running during the outage. The service should be considered \"at risk\" for the rest of the 28th. Weds 7th - Fri 9th Dec 2016 Grace outage Due to some remedial work dating back to the last Grace upgrade and preparation for the coming deployment of the Tier 2 materials centre it is necessary to have a three day outage of the Grace service to adjust the configuration of the storage. There will be no access during this time. Fri 18 Nov - Tues 22 Nov 2016 Legion reduced service The TXYZ nodes will be up and running, but all other nodes will be down during this time as they need to be moved. They may be back as early as Monday lunchtime, but we cannot guarantee this and they could be unavailable until end of day on Tuesday 22nd November. Mon 26 Sept - Weds 28 Sept 2016 Legion outage This is to update Lustre firmware. The system should be considered at risk on the 29th and 30th after this. Legion login nodes will be unavailable from the morning of Monday 26th. If you are going to need any of your data during this time, please remember to copy it elsewhere before the outage, as there will be no access during this time. This will also mean a service interruption for the Research Software Development \"Jenkins\" service, which depends on Legion. Mon 11 July - Tues 30 August 2016 Grace expansion outage Grace will taken out of service for this period in order to be undertake an expansion and upgrade of the compute, storage and interconnect fabric of the machine. These works will provide an additional 324 nodes (5,184 cores), a doubling in storage (scratch and home) and an InfiniBand network capable of scaling to circa 1000 nodes. This will effectively double the capacity of Grace in the short term and provide a much easier pathway for future expansions of the system. We have discussed the length of the outage, and potential options for mitigating this, with the Computational Resource Allocation Group. However, both the CRAG and Research IT Services members agree that the need to take a single long outage is the right decision in this instance given the breadth and complexity of the work that needs to be undertaken. We will be providing additional information, progress updates and any actions required from users prior to and during the system outage via the grace-users mailing list. Thurs 12 May 2016 Grace outage There will be an all-day network outage at Slough so Grace will be down all day and not running jobs. Mon 9 May 2016 Legion outage We are draining jobs for Monday so we can install updates to fix a kernel bug. Mon 18 - Thurs 21 April 2016 Legion outage Legion will be unavailable while we do some updates, test Lustre and enable Scratch quotas. It should be considered at risk for the rest of the week. Update: Work still ongoing on Thurs 21. Fri 1 April 2016 Login05 outage The dedicated transfer node login05 will be re-imaged with the new Legion OS so will not be available for data transfer for part of the day. Thurs 11 Feb 2016, 8-9am Grace connectivity at risk Network routing tests to Slough are being done between 8-9am. There may be some issues connecting to Grace during that window. Mon 29 - Tues 30 June 2015 Legion outage Legion will be unavailable while we replace an NFS controller and re-enable Lustre quotas. Weds 1 July should be considered at risk. Tues 5 - Thurs 7 May 2015 Legion outage Legion will be unavailable while we carry out a necessary software update to the parallel file system. The service should also be considered at risk on Fri 8 May. Mon 9 - Tues 10 Mar 2015 login05 outage Legion's dedicated transfer node, login05, will be unavailable from 10am on March 10th so we can move it to a new datacentre. It won't allow new logins after 10am on March 9th. Mon 19th Jan to Weds 21st Jan 2015 Legion outage Legion will be down while we update the Lustre firmware. The 22nd and 23rd should also be considered at risk. Fri 29th Nov to Mon 1st Dec 2014 Legion outage Wolfson House Data Centre shutdown for remedial work to be carried out by Estates. Midday Fri 31st Oct to Mon 10th Nov 2014 Complete outage of Legion while electrical testing is done at Torrington Place data centre. During this time we also intend to move the remaining core infrastructure for Legion to the Torrington Place datacentre so that we avoid being affected by planned outages at the other datacentre later this year.","title":"Planned Service Outages"},{"location":"Wiki_Export/done/Points_of_Contact/","text":"This page contains tools and information for the nominated Points of Contact. Other system-specific information is at Thomas or Michael . These commands can all be run as thomas-command or michael-command : they run the same thing and the different names are for convenience. Displaying user information \u00b6 thomas-show or michael-show is a tool that enables you to find a lot of information about users. Access to the database is given to points of contact individually, contact rc-support@ucl.ac.uk if you try to use this and get an access denied. At the top level, --user shows all information for one user, in multiple tables. --contacts shows all points of contact - useful for getting the IDs, and --institutes is the same. --allusers will show everyone's basic info. --getmmm will show the most recently used mmm username. thomas-show -h usage: thomas-show [-h] [--user username] [--contacts] [--institutes] [--allusers] [--getmmm] {recentusers,getusers,whois} ... Show data from the Thomas database. Use [positional argument -h] for more help. positional arguments: {recentusers,getusers,whois} recentusers Show the n newest users (5 by default) getusers Show all users with this project, institute, contact whois Search for users matching the given requirements optional arguments: -h, --help show this help message and exit --user username Show all current info for this user --contacts Show all allowed values for contact --institutes Show all allowed values for institute --allusers Show all current users --getmmm Show the highest mmm username used Show recent users \u00b6 thomas-show recentusers or michael-show recentusers shows you the most recently-added N users, default 5. thomas-show recentusers -h usage: thomas-show recentusers [-h] [-n N] optional arguments: -h, --help show this help message and exit -n N Show users with a given project, institute, contact \u00b6 thomas-show getusers or michael-show getusers will search for exact matches to the given project, institute, contact combination. thomas-show getusers -h usage: thomas-show getusers [-h] [-p PROJECT] [-i INST_ID] [-c POC_ID] optional arguments: -h, --help show this help message and exit -p PROJECT, --project PROJECT Project name -i INST_ID, --institute INST_ID Institute ID -c POC_ID, --contact POC_ID Point of Contact ID Search for users based on partial information \u00b6 thomas-show whois or michael-show whois can be used to search for partial matches to username, name, email fragments, including all of those in combination. thomas-show whois -h usage: thomas-show whois [-h] [-u USERNAME] [-e EMAIL] [-n GIVEN_NAME] [-s SURNAME] optional arguments: -h, --help show this help message and exit -u USERNAME, --user USERNAME UCL username of user contains -e EMAIL, --email EMAIL Email address of user contains -n GIVEN_NAME, --name GIVEN_NAME Given name of user contains -s SURNAME, --surname SURNAME Surname of user contains Adding user information and new projects \u00b6 thomas-add or michael-add will add information to the database. Access to the database is given to points of contact individually, contact rc-support@ucl.ac.uk if you try to use this and get an access denied. Please note that all options have a --debug flag that will allow you to see the query generated without committing the changes to the database - double-check that the information you are adding is correct. thomas-add -h usage: thomas-add [-h] {user,project,projectuser,poc,institute} ... Add data to the Thomas database. Use [positional argument -h] for more help. positional arguments: {user,project,projectuser,poc,institute} user Adding a new user with their initial project project Adding a new project projectuser Adding a new user-project-contact relationship poc Adding a new Point of Contact institute Adding a new institute/consortium optional arguments: -h, --help show this help message and exit Add a new user \u00b6 thomas-add user or michael-add user allows you to add a new user, with their initial project and point of contact. This does not create their account, but does email us with everything we need in order to create it. If you run this, you do not need to email us separately. The project specified must exist. thomas-add user -h usage: thomas-add user [-h] -u USERNAME -n GIVEN_NAME [-s SURNAME] -e EMAIL_ADDRESS -k \"SSH_KEY\" -p PROJECT_ID -c POC_ID [--debug] optional arguments: -h, --help show this help message and exit -u USERNAME, --user USERNAME UCL username of user -n GIVEN_NAME, --name GIVEN_NAME Given name of user -s SURNAME, --surname SURNAME Surname of user (optional) -e EMAIL_ADDRESS, --email EMAIL_ADDRESS Institutional email address of user -k \"SSH_KEY\", --key \"SSH_KEY\" User's public ssh key (quotes necessary) -p PROJECT_ID, --project PROJECT_ID Initial project the user belongs to -c POC_ID, --contact POC_ID Short ID of the user's Point of Contact --verbose Show SQL queries that are being submitted --debug Show SQL query submitted without committing the change SSH key formats \u00b6 It will verify the provided ssh key by default. Note that it has to be in the form ssh-xxx keystartshere . If someone has sent in a key which has line breaks and header items, make it into this format by adding the key type to the start and removing the line breaks from the key body. This key: ---- BEGIN SSH2 PUBLIC KEY ---- Comment: \"comment goes here\" AAAAB3NzaC1yc2EAAAABJQAAAQEAlLhFLr/4LGC3cM1xgRZVxfQ7JgoSvnVXly0K 7MNufZbUSUkKtVnBXAOIjtOYe7EPndyT/SAq1s9RGZ63qsaVc/05diLrgL0E0gW+ 9VptTmiUh7OSsXkoKQn1RiACfH7sbKi6H373bmB5/TyXNZ5C5KVmdXxO+laT8IdW 7JdD/gwrBra9M9vAMfcxNYVCBcPQRhJ7vOeDZ+e30qapH4R/mfEyKorYxrvQerJW OeLKjOH4rSnAAOLcEqPmJhkLL8k6nQAAK3P/E1PeOaB2xD7NNPqfIsjhAJLZ+2wV 3eUZATx9vnmVF0YafOjvzcoK2GqUrhNAvi7k0f+ihh8twkfthj== ---- END SSH2 PUBLIC KEY ---- should be converted into ssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAQEAlLhFLr/4LGC3cM1xgRZVxfQ7JgoSvnVXly0K7MNufZbUSUkKtVnBXAOIjtOYe7EPndyT/SAq1s9RGZ63qsaVc/05diLrgL0E0gW+9VptTmiUh7OSsXkoKQn1RiACfH7sbKi6H373bmB5/TyXNZ5C5KVmdXxO+laT8IdW7JdD/gwrBra9M9vAMfcxNYVCBcPQRhJ7vOeDZ+e30qapH4R/mfEyKorYxrvQerJWOeLKjOH4rSnAAOLcEqPmJhkLL8k6nQAAK3P/E1PeOaB2xD7NNPqfIsjhAJLZ+2wV3eUZATx9vnmVF0YafOjvzcoK2GqUrhNAvi7k0f+ihh8twkfthj== Other types of keys (dss etc) will say what they are in the first line, and you should change the ssh-rsa appropriately. The guide linked at Creating an ssh key in Windows also shows where users can get the second format out of PuTTY. Add a new project \u00b6 thomas-add project or michael-add project will create a new project, associated with an institution. It will not show in Gold until it also has a user in it. A project ID should begin with your institute ID, followed by an underscore and a project name. thomas-add project -h usage: thomas-add project [-h] -p PROJECT_ID -i INST_ID [--debug] optional arguments: -h, --help show this help message and exit -p PROJECT_ID, --project PROJECT_ID A new unique project ID -i INST_ID, --institute INST_ID Institute ID this project belongs to --debug Show SQL query submitted without committing the change Add a new project/user pairing \u00b6 thomas-add projectuser or michael-add projectuser will add an existing user to an existing project. Creating a new user for an existing project also creates this relationship. After a new project-user relationship is added, a cron job will pick that up within 15 minutes and create that project for that user in Gold, with no allocation. thomas-add projectuser -h usage: thomas-add projectuser [-h] -u USERNAME -p PROJECT_ID -c POC_ID [--debug] optional arguments: -h, --help show this help message and exit -u USERNAME, --user USERNAME An existing UCL username -p PROJECT_ID, --project PROJECT_ID An existing project ID -c POC_ID, --contact POC_ID An existing Point of Contact ID --debug Show SQL query submitted without committing the change Gold resource allocation \u00b6 We are currently using Gold to manage allocations on Thomas and Michael. There is one Gold database, so all the projects exist on both, but they are only active on specific clusters. Reporting from Gold \u00b6 There are wrapper scripts for a number of Gold commands (these exist in the userscripts module, loaded by default). These are all set to report in cpu-hours with the -h flag, as that is our main unit. If you wish to change anything about the wrappers, they live in /shared/ucl/apps/cluster-scripts/ so you can take a copy and add your preferred options. They all have a --man option to see the man pages for that command. Here are some basic useful options and what they do. They can all be given more options for more specific searches. gusage -p project_name [-s start_time] # Show the Gold usage per user in this project, in the given timeframe if specified. gbalance # Show the balance for every project, split into total, reserved and available. glsuser # Shows all the users in Gold. glsproject # Shows all the projects and which users are in them. glsres # Show all the current reservatioms, inc user and project. The Name column is the SGE job ID. gstatement # Produce a reporting statement showing beginning and end balances, credits and debits. # Less useful commands glstxn # Show all Gold transactions. Filter or it will take forever to run. glsalloc # Show all the allocations. These can be run by any user. The date format is YYYY-MM-DD. Eg. gstatement -p PROJECT -s 2017-08-01 will show all credits and debits for the given project since the given date, saying which user and job ID each charge was associated with. Transferring Gold \u00b6 As the point of contact, you can transfer Gold from your allocation account into other project accounts. As before, we've put -h in the wrapper so it is always working in cpu-hours. gtransfer --fromProject xxx_allocation --toProject xxx_subproject cpu_hours You can also transfer in the opposite direction, from the subproject back into your allocation account. Note that you are able to transfer your allocation into another institute's projects, but you cannot transfer it back again - only the other institute's point of contact (or rc-support) can give it back, so be careful which project you specify. When two allocations are active \u00b6 There is now an overlap period of a week when two allocations can be active. By default, gtransfer will transfer from active allocations in the order of earliest expiring first. To transfer from the new allocation only, you need to specify the allocation id. gtransfer -i allocation_ID --fromProject xxx_allocation --toProject xxx_subproject cpu_hours glsalloc shows you all allocations that ever existed, and the first column is the id. Id Account Projects StartTime EndTime Amount Deposited Description --- ------- --------------------- ---------- ---------- ---------- ---------- -------------- 87 38 UKCP_allocation 2017-08-07 2017-11-05 212800.00 3712800.00 97 38 UKCP_allocation 2017-10-30 2018-02-04 3712800.00 3712800.00","title":"Points of Contact"},{"location":"Wiki_Export/done/Points_of_Contact/#displaying-user-information","text":"thomas-show or michael-show is a tool that enables you to find a lot of information about users. Access to the database is given to points of contact individually, contact rc-support@ucl.ac.uk if you try to use this and get an access denied. At the top level, --user shows all information for one user, in multiple tables. --contacts shows all points of contact - useful for getting the IDs, and --institutes is the same. --allusers will show everyone's basic info. --getmmm will show the most recently used mmm username. thomas-show -h usage: thomas-show [-h] [--user username] [--contacts] [--institutes] [--allusers] [--getmmm] {recentusers,getusers,whois} ... Show data from the Thomas database. Use [positional argument -h] for more help. positional arguments: {recentusers,getusers,whois} recentusers Show the n newest users (5 by default) getusers Show all users with this project, institute, contact whois Search for users matching the given requirements optional arguments: -h, --help show this help message and exit --user username Show all current info for this user --contacts Show all allowed values for contact --institutes Show all allowed values for institute --allusers Show all current users --getmmm Show the highest mmm username used","title":"Displaying user information"},{"location":"Wiki_Export/done/Points_of_Contact/#show-recent-users","text":"thomas-show recentusers or michael-show recentusers shows you the most recently-added N users, default 5. thomas-show recentusers -h usage: thomas-show recentusers [-h] [-n N] optional arguments: -h, --help show this help message and exit -n N","title":"Show recent users"},{"location":"Wiki_Export/done/Points_of_Contact/#show-users-with-a-given-project-institute-contact","text":"thomas-show getusers or michael-show getusers will search for exact matches to the given project, institute, contact combination. thomas-show getusers -h usage: thomas-show getusers [-h] [-p PROJECT] [-i INST_ID] [-c POC_ID] optional arguments: -h, --help show this help message and exit -p PROJECT, --project PROJECT Project name -i INST_ID, --institute INST_ID Institute ID -c POC_ID, --contact POC_ID Point of Contact ID","title":"Show users with a given project, institute, contact"},{"location":"Wiki_Export/done/Points_of_Contact/#search-for-users-based-on-partial-information","text":"thomas-show whois or michael-show whois can be used to search for partial matches to username, name, email fragments, including all of those in combination. thomas-show whois -h usage: thomas-show whois [-h] [-u USERNAME] [-e EMAIL] [-n GIVEN_NAME] [-s SURNAME] optional arguments: -h, --help show this help message and exit -u USERNAME, --user USERNAME UCL username of user contains -e EMAIL, --email EMAIL Email address of user contains -n GIVEN_NAME, --name GIVEN_NAME Given name of user contains -s SURNAME, --surname SURNAME Surname of user contains","title":"Search for users based on partial information"},{"location":"Wiki_Export/done/Points_of_Contact/#adding-user-information-and-new-projects","text":"thomas-add or michael-add will add information to the database. Access to the database is given to points of contact individually, contact rc-support@ucl.ac.uk if you try to use this and get an access denied. Please note that all options have a --debug flag that will allow you to see the query generated without committing the changes to the database - double-check that the information you are adding is correct. thomas-add -h usage: thomas-add [-h] {user,project,projectuser,poc,institute} ... Add data to the Thomas database. Use [positional argument -h] for more help. positional arguments: {user,project,projectuser,poc,institute} user Adding a new user with their initial project project Adding a new project projectuser Adding a new user-project-contact relationship poc Adding a new Point of Contact institute Adding a new institute/consortium optional arguments: -h, --help show this help message and exit","title":"Adding user information and new projects"},{"location":"Wiki_Export/done/Points_of_Contact/#add-a-new-user","text":"thomas-add user or michael-add user allows you to add a new user, with their initial project and point of contact. This does not create their account, but does email us with everything we need in order to create it. If you run this, you do not need to email us separately. The project specified must exist. thomas-add user -h usage: thomas-add user [-h] -u USERNAME -n GIVEN_NAME [-s SURNAME] -e EMAIL_ADDRESS -k \"SSH_KEY\" -p PROJECT_ID -c POC_ID [--debug] optional arguments: -h, --help show this help message and exit -u USERNAME, --user USERNAME UCL username of user -n GIVEN_NAME, --name GIVEN_NAME Given name of user -s SURNAME, --surname SURNAME Surname of user (optional) -e EMAIL_ADDRESS, --email EMAIL_ADDRESS Institutional email address of user -k \"SSH_KEY\", --key \"SSH_KEY\" User's public ssh key (quotes necessary) -p PROJECT_ID, --project PROJECT_ID Initial project the user belongs to -c POC_ID, --contact POC_ID Short ID of the user's Point of Contact --verbose Show SQL queries that are being submitted --debug Show SQL query submitted without committing the change","title":"Add a new user"},{"location":"Wiki_Export/done/Points_of_Contact/#ssh-key-formats","text":"It will verify the provided ssh key by default. Note that it has to be in the form ssh-xxx keystartshere . If someone has sent in a key which has line breaks and header items, make it into this format by adding the key type to the start and removing the line breaks from the key body. This key: ---- BEGIN SSH2 PUBLIC KEY ---- Comment: \"comment goes here\" AAAAB3NzaC1yc2EAAAABJQAAAQEAlLhFLr/4LGC3cM1xgRZVxfQ7JgoSvnVXly0K 7MNufZbUSUkKtVnBXAOIjtOYe7EPndyT/SAq1s9RGZ63qsaVc/05diLrgL0E0gW+ 9VptTmiUh7OSsXkoKQn1RiACfH7sbKi6H373bmB5/TyXNZ5C5KVmdXxO+laT8IdW 7JdD/gwrBra9M9vAMfcxNYVCBcPQRhJ7vOeDZ+e30qapH4R/mfEyKorYxrvQerJW OeLKjOH4rSnAAOLcEqPmJhkLL8k6nQAAK3P/E1PeOaB2xD7NNPqfIsjhAJLZ+2wV 3eUZATx9vnmVF0YafOjvzcoK2GqUrhNAvi7k0f+ihh8twkfthj== ---- END SSH2 PUBLIC KEY ---- should be converted into ssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAQEAlLhFLr/4LGC3cM1xgRZVxfQ7JgoSvnVXly0K7MNufZbUSUkKtVnBXAOIjtOYe7EPndyT/SAq1s9RGZ63qsaVc/05diLrgL0E0gW+9VptTmiUh7OSsXkoKQn1RiACfH7sbKi6H373bmB5/TyXNZ5C5KVmdXxO+laT8IdW7JdD/gwrBra9M9vAMfcxNYVCBcPQRhJ7vOeDZ+e30qapH4R/mfEyKorYxrvQerJWOeLKjOH4rSnAAOLcEqPmJhkLL8k6nQAAK3P/E1PeOaB2xD7NNPqfIsjhAJLZ+2wV3eUZATx9vnmVF0YafOjvzcoK2GqUrhNAvi7k0f+ihh8twkfthj== Other types of keys (dss etc) will say what they are in the first line, and you should change the ssh-rsa appropriately. The guide linked at Creating an ssh key in Windows also shows where users can get the second format out of PuTTY.","title":"SSH key formats"},{"location":"Wiki_Export/done/Points_of_Contact/#add-a-new-project","text":"thomas-add project or michael-add project will create a new project, associated with an institution. It will not show in Gold until it also has a user in it. A project ID should begin with your institute ID, followed by an underscore and a project name. thomas-add project -h usage: thomas-add project [-h] -p PROJECT_ID -i INST_ID [--debug] optional arguments: -h, --help show this help message and exit -p PROJECT_ID, --project PROJECT_ID A new unique project ID -i INST_ID, --institute INST_ID Institute ID this project belongs to --debug Show SQL query submitted without committing the change","title":"Add a new project"},{"location":"Wiki_Export/done/Points_of_Contact/#add-a-new-projectuser-pairing","text":"thomas-add projectuser or michael-add projectuser will add an existing user to an existing project. Creating a new user for an existing project also creates this relationship. After a new project-user relationship is added, a cron job will pick that up within 15 minutes and create that project for that user in Gold, with no allocation. thomas-add projectuser -h usage: thomas-add projectuser [-h] -u USERNAME -p PROJECT_ID -c POC_ID [--debug] optional arguments: -h, --help show this help message and exit -u USERNAME, --user USERNAME An existing UCL username -p PROJECT_ID, --project PROJECT_ID An existing project ID -c POC_ID, --contact POC_ID An existing Point of Contact ID --debug Show SQL query submitted without committing the change","title":"Add a new project/user pairing"},{"location":"Wiki_Export/done/Points_of_Contact/#gold-resource-allocation","text":"We are currently using Gold to manage allocations on Thomas and Michael. There is one Gold database, so all the projects exist on both, but they are only active on specific clusters.","title":"Gold resource allocation"},{"location":"Wiki_Export/done/Points_of_Contact/#reporting-from-gold","text":"There are wrapper scripts for a number of Gold commands (these exist in the userscripts module, loaded by default). These are all set to report in cpu-hours with the -h flag, as that is our main unit. If you wish to change anything about the wrappers, they live in /shared/ucl/apps/cluster-scripts/ so you can take a copy and add your preferred options. They all have a --man option to see the man pages for that command. Here are some basic useful options and what they do. They can all be given more options for more specific searches. gusage -p project_name [-s start_time] # Show the Gold usage per user in this project, in the given timeframe if specified. gbalance # Show the balance for every project, split into total, reserved and available. glsuser # Shows all the users in Gold. glsproject # Shows all the projects and which users are in them. glsres # Show all the current reservatioms, inc user and project. The Name column is the SGE job ID. gstatement # Produce a reporting statement showing beginning and end balances, credits and debits. # Less useful commands glstxn # Show all Gold transactions. Filter or it will take forever to run. glsalloc # Show all the allocations. These can be run by any user. The date format is YYYY-MM-DD. Eg. gstatement -p PROJECT -s 2017-08-01 will show all credits and debits for the given project since the given date, saying which user and job ID each charge was associated with.","title":"Reporting from Gold"},{"location":"Wiki_Export/done/Points_of_Contact/#transferring-gold","text":"As the point of contact, you can transfer Gold from your allocation account into other project accounts. As before, we've put -h in the wrapper so it is always working in cpu-hours. gtransfer --fromProject xxx_allocation --toProject xxx_subproject cpu_hours You can also transfer in the opposite direction, from the subproject back into your allocation account. Note that you are able to transfer your allocation into another institute's projects, but you cannot transfer it back again - only the other institute's point of contact (or rc-support) can give it back, so be careful which project you specify.","title":"Transferring Gold"},{"location":"Wiki_Export/done/Points_of_Contact/#when-two-allocations-are-active","text":"There is now an overlap period of a week when two allocations can be active. By default, gtransfer will transfer from active allocations in the order of earliest expiring first. To transfer from the new allocation only, you need to specify the allocation id. gtransfer -i allocation_ID --fromProject xxx_allocation --toProject xxx_subproject cpu_hours glsalloc shows you all allocations that ever existed, and the first column is the id. Id Account Projects StartTime EndTime Amount Deposited Description --- ------- --------------------- ---------- ---------- ---------- ---------- -------------- 87 38 UKCP_allocation 2017-08-07 2017-11-05 212800.00 3712800.00 97 38 UKCP_allocation 2017-10-30 2018-02-04 3712800.00 3712800.00","title":"When two allocations are active"},{"location":"Wiki_Export/done/Publications/","text":"Some key publications arising from use of the Legion HPC service , from several of the Research Computing Consortia are listed below. Papers preceded by *** resulted from research conducted on the Legion cluster via 'non\u2011standard' use of resources (see Requesting Additional or Unusual Resources ). Astrophysics and Remote Sensing \u00b6 \u2018Cosmological simulations using GCMHD+\u2019 by Barnes, David J., Kawata, Daisuke and Wu, Kinwah. Monthly Notices of the Royal Astronomical Society 420 (2012) 3195. 1 \u2018Axial symmetry breaking of Saturn's thermosphere\u2019 by Smith, C. G. A. and Achilleos, N. Monthly Notices of the Royal Astronomical Society 422 (2012) 1460. 2 \u2018Methane in the atmosphere of the transiting hot Neptune GJ436b?\u2019 by Beaulieu JP, Tinetti G, Kipping DM, Ribas I, Barber RJ, Cho JYK, Polichtchouk I, Tennyson J, Yurchenko SN, Griffith CA, Batista V, Waldmann I, Miller S, Carey S, Mousis O and Fossey SJ. Astrophysical Journal 731 (2011) 2041. 3 \u2018A variationally computed line list for hot NH3\u2019 by Yurchenko SN, Barber RJ and Tennyson J. Monthly Notices of the Royal Astronomical Society 413 (2011) 1828. 4 \u2018Maser Sources in Astrophysics\u2019 by Gray, M. D. Cambridge University Press (2012). 5 Bioinformatics and Computational Biology \u00b6 \u2018AIP Mutation in Pituitary Adenomas in the 18th Century and Today\u2019 by Chahal HS, Stals K, Unterlander M, Balding DJ, Thomas MG, Kumar AV, Besser GM, Atkinson AB, Morrison PJ, Howlett TA, Levy MJ, Orme SM, Akker SA, Abel RL, Grossman AB, Burger J, Ellard S, and Korbonits M. New England Journal of Medicine 364 (2011) 43. 6 \u2018Genetic Discontinuity Between Local Hunter-Gatherers and Central Europe's First Farmers\u2019 by Bramanti B, Thomas MG, Haak W, Unterlaender M, Jores P, Tambets K, Antanaitis-Jacobs I, Haidle MN, Jankauskas R, Kind C-J, Lueth F, Terberger T, Hiller J, Matsumura S, Forster P and Burger J. Science 326 (2009) 137. 7 \u2018Accurate de novo structure prediction of large transmembrane protein domains using fragment assembly and correlated mutation analysis\u2019 by Nugent T and Jones DT. Proceedings of the National Academy of Sciences (2012). . 8 \u2018GeMMA: functional subfamily classification within superfamilies of predicted protein structural domains\u2019 by Lee DA, Rentzsch R and Orengo C. Nucleic Acids Research 38 (2010) 720. 9 *** \u2018The effect of insertions, deletions and alignment errors on the branch-site test of positive selection\u2019 by Fletcher W and Yang Z. Molecular Biology and Evolution 27 (2010) 2257. 10 Earth Materials \u00b6 'Lattice electrical resistivity of magnetic bcc iron from first-principles calculations' by D. Alf\u00e8, M. Pozzo, and M. P. Desjarlais. Physical Review B 85, (2012) 024102 1-5. 11 Epidemiology \u00b6 \u2018Effect on transmission of HIV-1 resistance of timing of implementation of viral load monitoring to determine switches from first to second line antiretroviral regimens in resource-limited settings\u2019 by Phillips AN, Pillay D, Garnett G, Bennett D, Vitoria M, Cambiano V and Lundgren JD. AIDS 25 (2011) 843. 12 \u2018Projected life expectancy of people with HIV according to timing of diagnosis\u2019 by Nakagawa F, Lodwick RK, Smith CJ, Smith R, Cambiano V, Lundgren JD, Delpech V and Phillips AN. AIDS 26 (2012) 335. 13 \u2018HIV Treatment as Prevention: Systematic Comparison of Mathematical Models of the Potential Impact of Antiretroviral Therapy on HIV Incidence in South Africa\u2019 by Jeffrey W. Eaton, Leigh F. Johnson, Joshua A. Salomon, Till B\u00e4rnighausen, Eran Bendavid, Anna Bershteyn, David E. Bloom, Valentina Cambiano, Christophe Fraser, Jan A. C. Hontelez, Salal Humair, Daniel J. Klein, Elisa F. Long, Andrew N. Phillips, Carel Pretorius, John Stover, Edward A. Wenger, Brian G. Williams and Timothy B. Hallett. Public Library of Science Medicine Medicine 9 (2012) e1001245. 14 \u2018Threshold Haemoglobin Levels and the Prognosis of Stable Coronary Disease: Two New Cohorts and a Systematic Review and Meta-Analysis\u2019 by Anoop D. Shah, Owen Nicholas, Adam D. Timmis, Gene Feder, Keith R. Abrams, Ruoling Chen, Aroon D. Hingorani and Harry Hemingway. Public Library of Science Medicine 8 (2011) e1000439. 15 Molecular Quantum Dynamics and Electronic Structure \u00b6 \u2018Experimental and computational studies of small molecule activation by uranium tris(aryloxides): binding of N2, coupling of CO and deoxygenation insertion of CO2 under ambient conditions\u2019 by Stephen M. Mansell, Nikolas Kaltsoyannis and Polly L. Arnold. Journal of the American Chemical Society 133 (2011) 9036. 16 \u2018A combined NMR/MD/QM approach for structure and dynamics elucidations in the solution state: pilot studies using tetrapeptides\u2019 by Aliev, A. E., Courtier-Murias, D., Bhandal, S. and Zhou, S. Chemical Communications 46 (2010) 695. 17 \u2018A stable two-coordinate acyclic silylene\u2019 by Andrey V. Protchenko, Krishna Hassomal Birjkumar, Deepak Dange, Andrew D. Schwarz, Dragoslav Vidovic, Cameron Jones, Nikolas Kaltsoyannis, Philip Mountford and Simon Aldridge. Journal of the American Chemical Society 134 (2012) 6500. 18 Work subsequently highlighted in Nature 485 (2012) 49. 19 \u2018A global, high accuracy ab initio dipole moment surface for the electronic ground state of the water molecule\u2019 by Lorenzo Lodi, Jonathan Tennyson and Oleg L. Polyanski. Journal of Chemical Physics 135 (2011) 034113. 20 \u2018Line lists for H218O and H217O based on empirical line positions and ab initio intensities\u2019 by Lorenzo Lodi and Jonathan Tennyson. Journal of Quantitative Spectroscopy & Radiative Transfer 113 (2012) 850. 21 Nanoscience and Defects \u00b6 'Point defects at the ice (0001) surface\u2019 by Matthew Watkin, Joost VandeVondele and Ben Slater. Proceedings of the National Academy of Sciences 107 (2010) 12429. 22 \u2018Aluminosilicate glasses as yttrium vectors for in-situ radiotherapy: understanding composition-durability effects through molecular dynamics simulations\u2019 by J. K. Christie and A. Tilocca. Chem. Mater. 22 (2010) 3725. 23 \u2018Aerobic Oxidation of Hydrocarbons Catalyzed by Mn-Doped Nanoporous Aluminophosphates(I): Preactivation of the Mn Sites\u2019 by Gomez-Hortiguela, L and Cora, F and Catlow, CRA. ACS Catalysis 1 (2011) 18. (Cover article in the first ever edition of this journal.) 24 \u2018Protonated Carboxyl Anchor for Stable Adsorption of Ru N749 Dye (Black Dye) on a TiO2 Anatase (101) Surface\u2019 by K. Sodeyama, M. Sumita, C. O'Rourke, U. Terranova, A. Islam, L. Han, D. R. Bowler and Y. Tateyama. J. Phys. Chem. Lett. 3 (2012) 472. 25 \u2018Mechanistic insight into the blocking of CO diffusion in [NiFe]-hydrogenase mutants through multiscale simulation\u2019 by P. Wang and J. Blumberger. Proceedings of the National Academy of Sciences 109 (2012) 6399. 26 27 Neuroscience \u00b6 \u2018Rapid Desynchronization of an Electrically Coupled Interneuron Network with Sparse Excitatory Synaptic Input\u2019 by Koen Vervaeke, Andrea L\u0151rincz, Padraig Gleeson, Matteo Farinella, Zoltan Nusser, R. Angus Silver. Neuron 67 (2010) 435. 28 Surface Science and Catalysis \u00b6 \u2018Ab initio molecular dynamics simulations of the cooperative adsorption of hydrazine and water on copper surfaces: Implications for shape control of nanoparticles\u2019 by T.D. Daff and N.H. de Leeuw. Chemistry of Materials 23 (2011) 2718. 29 \u2018Density functional theory and interatomic potential study of structural, mechanical and surface properties of calcium oxalate materials\u2019 by D. Di Tommaso, S.E. Ruiz-Hernandez, Z. Du and N.H. de Leeuw. RSC Advances 2 (2012) 4664. 30 \u2018Catalytic Reaction Mechanism of Mn-Doped Nanoporous Aluminophosphates for the Aerobic Oxidation of Hydrocarbons\u2019 by Luis G\u00f3mez-Hortig\u00fcela, Furio Cor\u00e0, Gopinathan Sankar, Claudio M. Zicovich-Wilson, and C. Richard A. Catlow. Chemistry, A European Journal 16 (2010) 13553. (Cover article.) 31 \u2018A molecular dynamics study of the interprotein interactions in collagen fibrils\u2019 by I. Streeter and N.H. de Leeuw. Soft Matter 7 (2011) 3373. 32 \u2018Molecular Dynamics simulation of the early stages of nucleation of hydroxyapatite at a collagen template\u2019 by N. Almora-Barrios and N.H. de Leeuw. Crystal Growth & Design 12 (2012) 756. 33 Systems Biomedicine \u00b6 \u2018Resolution of Discordant HIV-1 Protease Resistance Rankings Using Molecular Dynamics Simulations\u2019 by D. Wright and P. V. Coveney. Journal of Chemical Information and Modeling 51 (2011) 2636. 34 \u2018Rapid and accurate ranking of binding affinities of epidermal growth factor receptor sequences with selected lung cancer drugs\u2019 by S. Wan and P. V. Coveney. J. R. Soc. Interface 8 (2011) 1114. 35 \u2018Clay Minerals Mediate Folding and Regioselective Interactions of RNA: A Large-Scale Atomistic Simulation Study\u2019 by J. B. Swadling, P. V. Coveney and H. C. Greenwell. Journal of the American Chemical Society 132 (2010) 13750. 36 Other \u00b6 \u2018Universality of Performance Parameters in Vehicular ad hoc Networks\u2019 by T. Hewer, M. Nekovee and P. V. Coveney. IEEE Communications Letters 15 (2011) 947. 37 38","title":"Publications"},{"location":"Wiki_Export/done/Publications/#astrophysics-and-remote-sensing","text":"\u2018Cosmological simulations using GCMHD+\u2019 by Barnes, David J., Kawata, Daisuke and Wu, Kinwah. Monthly Notices of the Royal Astronomical Society 420 (2012) 3195. 1 \u2018Axial symmetry breaking of Saturn's thermosphere\u2019 by Smith, C. G. A. and Achilleos, N. Monthly Notices of the Royal Astronomical Society 422 (2012) 1460. 2 \u2018Methane in the atmosphere of the transiting hot Neptune GJ436b?\u2019 by Beaulieu JP, Tinetti G, Kipping DM, Ribas I, Barber RJ, Cho JYK, Polichtchouk I, Tennyson J, Yurchenko SN, Griffith CA, Batista V, Waldmann I, Miller S, Carey S, Mousis O and Fossey SJ. Astrophysical Journal 731 (2011) 2041. 3 \u2018A variationally computed line list for hot NH3\u2019 by Yurchenko SN, Barber RJ and Tennyson J. Monthly Notices of the Royal Astronomical Society 413 (2011) 1828. 4 \u2018Maser Sources in Astrophysics\u2019 by Gray, M. D. Cambridge University Press (2012). 5","title":"Astrophysics and Remote Sensing"},{"location":"Wiki_Export/done/Publications/#bioinformatics-and-computational-biology","text":"\u2018AIP Mutation in Pituitary Adenomas in the 18th Century and Today\u2019 by Chahal HS, Stals K, Unterlander M, Balding DJ, Thomas MG, Kumar AV, Besser GM, Atkinson AB, Morrison PJ, Howlett TA, Levy MJ, Orme SM, Akker SA, Abel RL, Grossman AB, Burger J, Ellard S, and Korbonits M. New England Journal of Medicine 364 (2011) 43. 6 \u2018Genetic Discontinuity Between Local Hunter-Gatherers and Central Europe's First Farmers\u2019 by Bramanti B, Thomas MG, Haak W, Unterlaender M, Jores P, Tambets K, Antanaitis-Jacobs I, Haidle MN, Jankauskas R, Kind C-J, Lueth F, Terberger T, Hiller J, Matsumura S, Forster P and Burger J. Science 326 (2009) 137. 7 \u2018Accurate de novo structure prediction of large transmembrane protein domains using fragment assembly and correlated mutation analysis\u2019 by Nugent T and Jones DT. Proceedings of the National Academy of Sciences (2012). . 8 \u2018GeMMA: functional subfamily classification within superfamilies of predicted protein structural domains\u2019 by Lee DA, Rentzsch R and Orengo C. Nucleic Acids Research 38 (2010) 720. 9 *** \u2018The effect of insertions, deletions and alignment errors on the branch-site test of positive selection\u2019 by Fletcher W and Yang Z. Molecular Biology and Evolution 27 (2010) 2257. 10","title":"Bioinformatics and Computational Biology"},{"location":"Wiki_Export/done/Publications/#earth-materials","text":"'Lattice electrical resistivity of magnetic bcc iron from first-principles calculations' by D. Alf\u00e8, M. Pozzo, and M. P. Desjarlais. Physical Review B 85, (2012) 024102 1-5. 11","title":"Earth Materials"},{"location":"Wiki_Export/done/Publications/#epidemiology","text":"\u2018Effect on transmission of HIV-1 resistance of timing of implementation of viral load monitoring to determine switches from first to second line antiretroviral regimens in resource-limited settings\u2019 by Phillips AN, Pillay D, Garnett G, Bennett D, Vitoria M, Cambiano V and Lundgren JD. AIDS 25 (2011) 843. 12 \u2018Projected life expectancy of people with HIV according to timing of diagnosis\u2019 by Nakagawa F, Lodwick RK, Smith CJ, Smith R, Cambiano V, Lundgren JD, Delpech V and Phillips AN. AIDS 26 (2012) 335. 13 \u2018HIV Treatment as Prevention: Systematic Comparison of Mathematical Models of the Potential Impact of Antiretroviral Therapy on HIV Incidence in South Africa\u2019 by Jeffrey W. Eaton, Leigh F. Johnson, Joshua A. Salomon, Till B\u00e4rnighausen, Eran Bendavid, Anna Bershteyn, David E. Bloom, Valentina Cambiano, Christophe Fraser, Jan A. C. Hontelez, Salal Humair, Daniel J. Klein, Elisa F. Long, Andrew N. Phillips, Carel Pretorius, John Stover, Edward A. Wenger, Brian G. Williams and Timothy B. Hallett. Public Library of Science Medicine Medicine 9 (2012) e1001245. 14 \u2018Threshold Haemoglobin Levels and the Prognosis of Stable Coronary Disease: Two New Cohorts and a Systematic Review and Meta-Analysis\u2019 by Anoop D. Shah, Owen Nicholas, Adam D. Timmis, Gene Feder, Keith R. Abrams, Ruoling Chen, Aroon D. Hingorani and Harry Hemingway. Public Library of Science Medicine 8 (2011) e1000439. 15","title":"Epidemiology"},{"location":"Wiki_Export/done/Publications/#molecular-quantum-dynamics-and-electronic-structure","text":"\u2018Experimental and computational studies of small molecule activation by uranium tris(aryloxides): binding of N2, coupling of CO and deoxygenation insertion of CO2 under ambient conditions\u2019 by Stephen M. Mansell, Nikolas Kaltsoyannis and Polly L. Arnold. Journal of the American Chemical Society 133 (2011) 9036. 16 \u2018A combined NMR/MD/QM approach for structure and dynamics elucidations in the solution state: pilot studies using tetrapeptides\u2019 by Aliev, A. E., Courtier-Murias, D., Bhandal, S. and Zhou, S. Chemical Communications 46 (2010) 695. 17 \u2018A stable two-coordinate acyclic silylene\u2019 by Andrey V. Protchenko, Krishna Hassomal Birjkumar, Deepak Dange, Andrew D. Schwarz, Dragoslav Vidovic, Cameron Jones, Nikolas Kaltsoyannis, Philip Mountford and Simon Aldridge. Journal of the American Chemical Society 134 (2012) 6500. 18 Work subsequently highlighted in Nature 485 (2012) 49. 19 \u2018A global, high accuracy ab initio dipole moment surface for the electronic ground state of the water molecule\u2019 by Lorenzo Lodi, Jonathan Tennyson and Oleg L. Polyanski. Journal of Chemical Physics 135 (2011) 034113. 20 \u2018Line lists for H218O and H217O based on empirical line positions and ab initio intensities\u2019 by Lorenzo Lodi and Jonathan Tennyson. Journal of Quantitative Spectroscopy & Radiative Transfer 113 (2012) 850. 21","title":"Molecular Quantum Dynamics and Electronic Structure"},{"location":"Wiki_Export/done/Publications/#nanoscience-and-defects","text":"'Point defects at the ice (0001) surface\u2019 by Matthew Watkin, Joost VandeVondele and Ben Slater. Proceedings of the National Academy of Sciences 107 (2010) 12429. 22 \u2018Aluminosilicate glasses as yttrium vectors for in-situ radiotherapy: understanding composition-durability effects through molecular dynamics simulations\u2019 by J. K. Christie and A. Tilocca. Chem. Mater. 22 (2010) 3725. 23 \u2018Aerobic Oxidation of Hydrocarbons Catalyzed by Mn-Doped Nanoporous Aluminophosphates(I): Preactivation of the Mn Sites\u2019 by Gomez-Hortiguela, L and Cora, F and Catlow, CRA. ACS Catalysis 1 (2011) 18. (Cover article in the first ever edition of this journal.) 24 \u2018Protonated Carboxyl Anchor for Stable Adsorption of Ru N749 Dye (Black Dye) on a TiO2 Anatase (101) Surface\u2019 by K. Sodeyama, M. Sumita, C. O'Rourke, U. Terranova, A. Islam, L. Han, D. R. Bowler and Y. Tateyama. J. Phys. Chem. Lett. 3 (2012) 472. 25 \u2018Mechanistic insight into the blocking of CO diffusion in [NiFe]-hydrogenase mutants through multiscale simulation\u2019 by P. Wang and J. Blumberger. Proceedings of the National Academy of Sciences 109 (2012) 6399. 26 27","title":"Nanoscience and Defects"},{"location":"Wiki_Export/done/Publications/#neuroscience","text":"\u2018Rapid Desynchronization of an Electrically Coupled Interneuron Network with Sparse Excitatory Synaptic Input\u2019 by Koen Vervaeke, Andrea L\u0151rincz, Padraig Gleeson, Matteo Farinella, Zoltan Nusser, R. Angus Silver. Neuron 67 (2010) 435. 28","title":"Neuroscience"},{"location":"Wiki_Export/done/Publications/#surface-science-and-catalysis","text":"\u2018Ab initio molecular dynamics simulations of the cooperative adsorption of hydrazine and water on copper surfaces: Implications for shape control of nanoparticles\u2019 by T.D. Daff and N.H. de Leeuw. Chemistry of Materials 23 (2011) 2718. 29 \u2018Density functional theory and interatomic potential study of structural, mechanical and surface properties of calcium oxalate materials\u2019 by D. Di Tommaso, S.E. Ruiz-Hernandez, Z. Du and N.H. de Leeuw. RSC Advances 2 (2012) 4664. 30 \u2018Catalytic Reaction Mechanism of Mn-Doped Nanoporous Aluminophosphates for the Aerobic Oxidation of Hydrocarbons\u2019 by Luis G\u00f3mez-Hortig\u00fcela, Furio Cor\u00e0, Gopinathan Sankar, Claudio M. Zicovich-Wilson, and C. Richard A. Catlow. Chemistry, A European Journal 16 (2010) 13553. (Cover article.) 31 \u2018A molecular dynamics study of the interprotein interactions in collagen fibrils\u2019 by I. Streeter and N.H. de Leeuw. Soft Matter 7 (2011) 3373. 32 \u2018Molecular Dynamics simulation of the early stages of nucleation of hydroxyapatite at a collagen template\u2019 by N. Almora-Barrios and N.H. de Leeuw. Crystal Growth & Design 12 (2012) 756. 33","title":"Surface Science and Catalysis"},{"location":"Wiki_Export/done/Publications/#systems-biomedicine","text":"\u2018Resolution of Discordant HIV-1 Protease Resistance Rankings Using Molecular Dynamics Simulations\u2019 by D. Wright and P. V. Coveney. Journal of Chemical Information and Modeling 51 (2011) 2636. 34 \u2018Rapid and accurate ranking of binding affinities of epidermal growth factor receptor sequences with selected lung cancer drugs\u2019 by S. Wan and P. V. Coveney. J. R. Soc. Interface 8 (2011) 1114. 35 \u2018Clay Minerals Mediate Folding and Regioselective Interactions of RNA: A Large-Scale Atomistic Simulation Study\u2019 by J. B. Swadling, P. V. Coveney and H. C. Greenwell. Journal of the American Chemical Society 132 (2010) 13750. 36","title":"Systems Biomedicine"},{"location":"Wiki_Export/done/Publications/#other","text":"\u2018Universality of Performance Parameters in Vehicular ad hoc Networks\u2019 by T. Hewer, M. Nekovee and P. V. Coveney. IEEE Communications Letters 15 (2011) 947. 37 38","title":"Other"},{"location":"Wiki_Export/done/Quick_Start/","text":"This is a quick start guide to our clusters for users already familiar with operating in an HPC environment. Accessing A Cluster \u00b6 Before accessing the Legion cluster, it is necessary to apply for an account . Once you have received notification that your account has been created, you may log in via SSH to: Legion: legion.rc.ucl.ac.uk Myriad: myriad.rc.ucl.ac.uk Grace: grace.rc.ucl.ac.uk Your username and password are the same as those for your central UCL user id. Legion, Myriad, and Grace are only accessible from within UCL\u2019s network. If you need to access them from outside, you need to log in via Socrates, a departmental machine, or install the IS VPN service. More details on connecting to these services are provided on the Accessing RC Systems page. Managing data on the our clusters \u00b6 Users on our clusters have access to three pools of storage. They have a home directory which is mounted read only on the compute nodes and therefore cannot be written to by running jobs. They have a \"scratch\" area which is writable from jobs and intended for live data and job output. There is a link to this area called \"Scratch\" within the user\u2019s home directory. Finally, within a job users have access to temporary local storage on the nodes (environmental variable $TMPDIR ) which is cleared at the end of the job. Legion has slow external network connections, so there is a dedicated transfer node with 10 gigabit network links to and from Legion available at: login05.external.legion.ucl.ac.uk Transfers to Grace and Myriad may use any of the normal login nodes. For more details on the fairly complicated data management structures within Legion, see the Managing Data on RC Systems page. User Environment \u00b6 Our clusters run an operating system based on Red Hat Enterprise Linux 7 with the Son of Grid Engine batch scheduler. UCL-supported and provided packages are made available to users through the use of the modules system. module avail lists available modules module load loads a module module remove removes a module The module system handles dependency and conflict information. You can find out more about the modules system on Legion on the RC Systems user environment page. Compiling your code \u00b6 We provide Intel and GNU compilers, and OpenMPI and Intel MPI through the modules system, with the usual wrappers. For a full list of the development tools available see here or in the development tools/compilers sections of the modules system. You can find out more about compiling code on a cluster on the Compiling page. Job scheduling policy and projects \u00b6 A fair-share resource allocation model has been implemented on all our clusters. See Resource Allocation for more information and context. Submission scripts \u00b6 Jobs submitted to the scheduler (with \"qsub\") are shell scripts with directives preceded by #$ . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/bash -l # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM per process. #$ -l mem=1G # Set the name of the job. #$ -N SomeScience_1_16 # Select the MPI parallel environment and 16 processes. #$ -pe mpi 16 # Select the project that this job will run under. (Only if you have # access to paid resources). #$ -P <your_project_id> # Set the working directory to somewhere in your scratch space. #$ -wd /home/<your_UCL_id>/Scratch/output You can then follow these directives with the commands your script would execute. Legion supports a wide variety of job types and we would strongly recommend you study the example scripts . Jobs can be controlled with qsub (submit job), qstat (list jobs) and qdel (delete job). See the Introduction to batch processing page for more details. Testing jobs using Interactive Jobs \u00b6 As well as batch access to the system, it is possible to run short, small jobs with interactive access through the scheduler. These can be requested though the qrsh command. You need to provide qrsh with the same options you would include in your job submission script, so: qrsh -pe mpi 8 -l mem=512M -l h_rt=2:0:0 Is functionally equivalent to: 1 2 3 4 5 #!/bin/bash #$ -S /bin/bash #$ -pe mpi 8 #$ -l mem=512M #$ -l h_rt=2:0:0 Except, of course, that the result of qrsh is an interactive shell. For more details, see the Interactive Jobs page. More information \u00b6 How the scheduler works Example submission scripts Acknowledging the use of our services in publications Contact and support FAQ Known issues Reporting Problems","title":"Legion Quick Start"},{"location":"Wiki_Export/done/Quick_Start/#accessing-a-cluster","text":"Before accessing the Legion cluster, it is necessary to apply for an account . Once you have received notification that your account has been created, you may log in via SSH to: Legion: legion.rc.ucl.ac.uk Myriad: myriad.rc.ucl.ac.uk Grace: grace.rc.ucl.ac.uk Your username and password are the same as those for your central UCL user id. Legion, Myriad, and Grace are only accessible from within UCL\u2019s network. If you need to access them from outside, you need to log in via Socrates, a departmental machine, or install the IS VPN service. More details on connecting to these services are provided on the Accessing RC Systems page.","title":"Accessing A Cluster"},{"location":"Wiki_Export/done/Quick_Start/#managing-data-on-the-our-clusters","text":"Users on our clusters have access to three pools of storage. They have a home directory which is mounted read only on the compute nodes and therefore cannot be written to by running jobs. They have a \"scratch\" area which is writable from jobs and intended for live data and job output. There is a link to this area called \"Scratch\" within the user\u2019s home directory. Finally, within a job users have access to temporary local storage on the nodes (environmental variable $TMPDIR ) which is cleared at the end of the job. Legion has slow external network connections, so there is a dedicated transfer node with 10 gigabit network links to and from Legion available at: login05.external.legion.ucl.ac.uk Transfers to Grace and Myriad may use any of the normal login nodes. For more details on the fairly complicated data management structures within Legion, see the Managing Data on RC Systems page.","title":"Managing data on the our clusters"},{"location":"Wiki_Export/done/Quick_Start/#user-environment","text":"Our clusters run an operating system based on Red Hat Enterprise Linux 7 with the Son of Grid Engine batch scheduler. UCL-supported and provided packages are made available to users through the use of the modules system. module avail lists available modules module load loads a module module remove removes a module The module system handles dependency and conflict information. You can find out more about the modules system on Legion on the RC Systems user environment page.","title":"User Environment"},{"location":"Wiki_Export/done/Quick_Start/#compiling-your-code","text":"We provide Intel and GNU compilers, and OpenMPI and Intel MPI through the modules system, with the usual wrappers. For a full list of the development tools available see here or in the development tools/compilers sections of the modules system. You can find out more about compiling code on a cluster on the Compiling page.","title":"Compiling your code"},{"location":"Wiki_Export/done/Quick_Start/#job-scheduling-policy-and-projects","text":"A fair-share resource allocation model has been implemented on all our clusters. See Resource Allocation for more information and context.","title":"Job scheduling policy and projects"},{"location":"Wiki_Export/done/Quick_Start/#submission-scripts","text":"Jobs submitted to the scheduler (with \"qsub\") are shell scripts with directives preceded by #$ . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/bash -l # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM per process. #$ -l mem=1G # Set the name of the job. #$ -N SomeScience_1_16 # Select the MPI parallel environment and 16 processes. #$ -pe mpi 16 # Select the project that this job will run under. (Only if you have # access to paid resources). #$ -P <your_project_id> # Set the working directory to somewhere in your scratch space. #$ -wd /home/<your_UCL_id>/Scratch/output You can then follow these directives with the commands your script would execute. Legion supports a wide variety of job types and we would strongly recommend you study the example scripts . Jobs can be controlled with qsub (submit job), qstat (list jobs) and qdel (delete job). See the Introduction to batch processing page for more details.","title":"Submission scripts"},{"location":"Wiki_Export/done/Quick_Start/#testing-jobs-using-interactive-jobs","text":"As well as batch access to the system, it is possible to run short, small jobs with interactive access through the scheduler. These can be requested though the qrsh command. You need to provide qrsh with the same options you would include in your job submission script, so: qrsh -pe mpi 8 -l mem=512M -l h_rt=2:0:0 Is functionally equivalent to: 1 2 3 4 5 #!/bin/bash #$ -S /bin/bash #$ -pe mpi 8 #$ -l mem=512M #$ -l h_rt=2:0:0 Except, of course, that the result of qrsh is an interactive shell. For more details, see the Interactive Jobs page.","title":"Testing jobs using Interactive Jobs"},{"location":"Wiki_Export/done/Quick_Start/#more-information","text":"How the scheduler works Example submission scripts Acknowledging the use of our services in publications Contact and support FAQ Known issues Reporting Problems","title":"More information"},{"location":"Wiki_Export/done/RC_Systems/","text":"We provide access to three computing clusters: Legion , Myriad , and Grace ( What is a computing cluster? ). All UCL researchers are eligible to use these platforms on a fair share basis and at no cost. This page provides a brief overview of our computing services and their technical specifications. We support Aristotle , which provides a limited interactive Linux environment to support training. We also host Thomas and Michael , clusters associated with the UK National Tier 2 High Performance Computing Hub in Materials and Molecular Modelling. Legion \u00b6 Legion is our general-use cluster. It contains nodes of different types, some specialist hardware, and nodes belonging to research groups. You can run serial or parallel jobs on it, and the combinations of resources you may request depend on the node type. Legion technical specs \u00b6 The Legion cluster nodes have several different types. Type T: 6 Dell 2U R820 large memory or fat nodes - four socket, eight cores per processor Each node has 32 cores at 48GB RAM per core Each node can work as a 32 core SMP system with 1.5TB of RAM 2TB local disk per node (1536G available for tmpfs) Type U: Exact hardware may vary, as these are bought in sections 160 Dell C6220 nodes (4 nodes per 2u) - dual processor, eight cores per processor 2560 cores, at 4GB RAM per core (64GB per node) Each node can work as a 16 core SMP device with 64GB of RAM 108 nodes are also connected with Infiniband configured as three 36 node 'islands' 1TB of local disk per node (792G available for tmpfs) Type X: 144 Dell C6100 nodes (4 nodes per 2u) - dual processor, six cores per processor 1728 cores, as 2GB RAM per core (24GB per node) Organized into 6 Computational Units of 288 cores Each server can function as a 12 core SMP device QDR InfiniPath chip-to-chip connectivity 250GB of local disk per server (173G available for tmpfs) Type Y: 108 Dell C6100 nodes (4 nodes per 2u) - dual processor, six cores per processor 1296 cores, each with 2GB RAM (24GB per node) Each server can function as a 12 core SMP device 500GB of local disk per server (406G available for tmpfs) Type Z: 4 Dell C6100 nodes (4 nodes in 2u) - dual processor, six cores per processor 48 cores, each with 4GB RAM (48GB per node) Each server can function as a 12 core SMP device 500GB of local disk per server (173G available for tmpfs) Type P GPU: 1 node - dual processor, six cores per processor Each server with 12 CPU cores and 1 NVIDIA K40c GPU card Each card having 2880 CUDA cores and 11GB RAM Each server can function as a 12 core SMP device 932GB of local disk per server (112G available for tmpfs) Type V GPU: 8 Dell C6100 nodes (4 nodes per 2u) - dual processor, six cores per processor Each server with 12 CPU cores and two M2070 GPU cards Each card having 448 CUDA cores and 6GB RAM Each server can function as a 12 core SMP device 500GB of local disk per server (358G available for tmpfs) Type S (experimental MIC nodes): 10 Dell 2U R720 nodes - two socket, 8 or 16 cores per processor Nodes have 16 CPU cores and two Xeon Phi 7120p MICs Nodes can work as a 16 core SMP device with 64GB of RAM 2TB of local disk per node (1536G available for tmpfs) Operating system is Red Hat Linux 6 The cluster is coupled to a large-scale high-performance file system: 342TB of RAID 6 storage Uses Lustre Cluster File System 4 servers to stripe data across the disks and 2 servers to store the metadata Aggregate speed of 6GB/s for Read/Writes Please note that this file system is for active data and not archive data. It should be used for temporary storage only . Myriad \u00b6 Myriad is our high-I/O, high-throughput cluster. It contains nodes of a few different types including GPUs. It runs jobs that will run within a single node rather than multi-node parallel jobs. Myriad technical specs \u00b6 Myriad consists of Lenovo SD530 nodes. There are two login nodes and two transfer nodes. There are three types of compute nodes: Type H: Lenovo SD530 Standard Nodes 2 x Intel Xeon Gold 6140 18C 140W 2.3GHz Processor (36 cores total) 12 x 16GB TruDDR4 RDIMM (192 GB total) 1 x 2TB 7.2K SATA HDD 1 x Mellanox ConnectX-5 EDR/100Gb IB single port VPI HCA Type I high memory: Lenovo SD530 High Memory Nodes 2 x Intel Xeon Gold 6140 18C 140W 2.3GHz Processor (36 cores total) 24 x 64GB TruDDR4 RDIMM (1.5TB total) 1 x 2TB 7.2K SAS HDD 1 x Mellanox ConnectX-4 2x100Gb/EDR IB VPI Adapter Type J GPU: Lenovo SD530 GPU Nodes 2 x Intel Xeon Gold 6140 18C 140W 2.3GHz Processor (36 cores total) 2 x nVidia Tesla P100 Adapter 12 x 16GB TruDDR4 RDIMM (192 GB total) 1 x 2TB 7.2K SATA HDD 1 x Mellanox ConnectX-5 EDR/100Gb IB single port VPI HCA Filesystem: Lenovo Lustre storage 200TB home 1PB Scratch 2 MDS servers 2 OSS servers Mellanox ConnectX-4 2x100Gb/EDR InfiniBand storage network Grace \u00b6 Grace is intended for large multinode parallel jobs. As per CRAG policy, jobs that require less than 32 cores are subject to a dramatic priority penalty. Grace technical specs \u00b6 Grace consists of 684 identical Lenovo NeXtScale nodes connected by non-blocking Intel TrueScale QDR Infiniband to each other and a 1.1 PetaByte DDN Lustre storage appliance. Four of the nodes are used as login and admin nodes. The remainder are available for running jobs. Each node has the following specs: 2x 8 core Intel Xeon E5-2630v3 processors (16 cores total) 64 Gigabytes of RAM 120 Gigabyte SSD for OS and TMPDIR Intel TrueScale QDR Infiniband adaptor Thomas \u00b6 Thomas is the UK National Tier 2 High Performance Computing Hub in Materials and Molecular Modelling, a domain-specific multi-institute machine hosted by UCL. Further details about Thomas Thomas technical specs \u00b6 Thomas consists of 720 Lenovo Intel x86-64 nodes, giving 17.2k cores in total, with Intel OmniPath interconnect (1:1 nonblocking in 36 node blocks, 3:1 between blocks and across the system). Each node has the following specs: 2 x 12 core Intel Broadwell processors (24 cores total) 128GB RAM 120GB SSD Aristotle \u00b6 Aristotle is a teaching machine, usable by everyone. It does not have a batch system - you run programs directly on the nodes and share resources with all other users. Use with consideration! Aristotle technical specs \u00b6 4x 16 core Dell servers with Intel(R) Xeon(R) CPU E5-2650 v2 64 gigabytes of RAM per node RedHat 7.2 No Infiniband so MPI may only be used within a node How do I apply for an account? \u00b6 Please apply at Account Services for everything other than Thomas - you will be approved for a Legion and Myriad account. You will be approved for a Grace account if the resources you request meet the requirements. For Thomas, see Applying for a Thomas account . Access to Aristotle \u00b6 Everyone with a UCL account has access to Aristotle. Login via SSH to: aristotle.rc.ucl.ac.uk","title":"Research Computing Platforms"},{"location":"Wiki_Export/done/RC_Systems/#legion","text":"Legion is our general-use cluster. It contains nodes of different types, some specialist hardware, and nodes belonging to research groups. You can run serial or parallel jobs on it, and the combinations of resources you may request depend on the node type.","title":"Legion"},{"location":"Wiki_Export/done/RC_Systems/#legion-technical-specs","text":"The Legion cluster nodes have several different types. Type T: 6 Dell 2U R820 large memory or fat nodes - four socket, eight cores per processor Each node has 32 cores at 48GB RAM per core Each node can work as a 32 core SMP system with 1.5TB of RAM 2TB local disk per node (1536G available for tmpfs) Type U: Exact hardware may vary, as these are bought in sections 160 Dell C6220 nodes (4 nodes per 2u) - dual processor, eight cores per processor 2560 cores, at 4GB RAM per core (64GB per node) Each node can work as a 16 core SMP device with 64GB of RAM 108 nodes are also connected with Infiniband configured as three 36 node 'islands' 1TB of local disk per node (792G available for tmpfs) Type X: 144 Dell C6100 nodes (4 nodes per 2u) - dual processor, six cores per processor 1728 cores, as 2GB RAM per core (24GB per node) Organized into 6 Computational Units of 288 cores Each server can function as a 12 core SMP device QDR InfiniPath chip-to-chip connectivity 250GB of local disk per server (173G available for tmpfs) Type Y: 108 Dell C6100 nodes (4 nodes per 2u) - dual processor, six cores per processor 1296 cores, each with 2GB RAM (24GB per node) Each server can function as a 12 core SMP device 500GB of local disk per server (406G available for tmpfs) Type Z: 4 Dell C6100 nodes (4 nodes in 2u) - dual processor, six cores per processor 48 cores, each with 4GB RAM (48GB per node) Each server can function as a 12 core SMP device 500GB of local disk per server (173G available for tmpfs) Type P GPU: 1 node - dual processor, six cores per processor Each server with 12 CPU cores and 1 NVIDIA K40c GPU card Each card having 2880 CUDA cores and 11GB RAM Each server can function as a 12 core SMP device 932GB of local disk per server (112G available for tmpfs) Type V GPU: 8 Dell C6100 nodes (4 nodes per 2u) - dual processor, six cores per processor Each server with 12 CPU cores and two M2070 GPU cards Each card having 448 CUDA cores and 6GB RAM Each server can function as a 12 core SMP device 500GB of local disk per server (358G available for tmpfs) Type S (experimental MIC nodes): 10 Dell 2U R720 nodes - two socket, 8 or 16 cores per processor Nodes have 16 CPU cores and two Xeon Phi 7120p MICs Nodes can work as a 16 core SMP device with 64GB of RAM 2TB of local disk per node (1536G available for tmpfs) Operating system is Red Hat Linux 6 The cluster is coupled to a large-scale high-performance file system: 342TB of RAID 6 storage Uses Lustre Cluster File System 4 servers to stripe data across the disks and 2 servers to store the metadata Aggregate speed of 6GB/s for Read/Writes Please note that this file system is for active data and not archive data. It should be used for temporary storage only .","title":"Legion technical specs"},{"location":"Wiki_Export/done/RC_Systems/#myriad","text":"Myriad is our high-I/O, high-throughput cluster. It contains nodes of a few different types including GPUs. It runs jobs that will run within a single node rather than multi-node parallel jobs.","title":"Myriad"},{"location":"Wiki_Export/done/RC_Systems/#myriad-technical-specs","text":"Myriad consists of Lenovo SD530 nodes. There are two login nodes and two transfer nodes. There are three types of compute nodes: Type H: Lenovo SD530 Standard Nodes 2 x Intel Xeon Gold 6140 18C 140W 2.3GHz Processor (36 cores total) 12 x 16GB TruDDR4 RDIMM (192 GB total) 1 x 2TB 7.2K SATA HDD 1 x Mellanox ConnectX-5 EDR/100Gb IB single port VPI HCA Type I high memory: Lenovo SD530 High Memory Nodes 2 x Intel Xeon Gold 6140 18C 140W 2.3GHz Processor (36 cores total) 24 x 64GB TruDDR4 RDIMM (1.5TB total) 1 x 2TB 7.2K SAS HDD 1 x Mellanox ConnectX-4 2x100Gb/EDR IB VPI Adapter Type J GPU: Lenovo SD530 GPU Nodes 2 x Intel Xeon Gold 6140 18C 140W 2.3GHz Processor (36 cores total) 2 x nVidia Tesla P100 Adapter 12 x 16GB TruDDR4 RDIMM (192 GB total) 1 x 2TB 7.2K SATA HDD 1 x Mellanox ConnectX-5 EDR/100Gb IB single port VPI HCA Filesystem: Lenovo Lustre storage 200TB home 1PB Scratch 2 MDS servers 2 OSS servers Mellanox ConnectX-4 2x100Gb/EDR InfiniBand storage network","title":"Myriad technical specs"},{"location":"Wiki_Export/done/RC_Systems/#grace","text":"Grace is intended for large multinode parallel jobs. As per CRAG policy, jobs that require less than 32 cores are subject to a dramatic priority penalty.","title":"Grace"},{"location":"Wiki_Export/done/RC_Systems/#grace-technical-specs","text":"Grace consists of 684 identical Lenovo NeXtScale nodes connected by non-blocking Intel TrueScale QDR Infiniband to each other and a 1.1 PetaByte DDN Lustre storage appliance. Four of the nodes are used as login and admin nodes. The remainder are available for running jobs. Each node has the following specs: 2x 8 core Intel Xeon E5-2630v3 processors (16 cores total) 64 Gigabytes of RAM 120 Gigabyte SSD for OS and TMPDIR Intel TrueScale QDR Infiniband adaptor","title":"Grace technical specs"},{"location":"Wiki_Export/done/RC_Systems/#thomas","text":"Thomas is the UK National Tier 2 High Performance Computing Hub in Materials and Molecular Modelling, a domain-specific multi-institute machine hosted by UCL. Further details about Thomas","title":"Thomas"},{"location":"Wiki_Export/done/RC_Systems/#thomas-technical-specs","text":"Thomas consists of 720 Lenovo Intel x86-64 nodes, giving 17.2k cores in total, with Intel OmniPath interconnect (1:1 nonblocking in 36 node blocks, 3:1 between blocks and across the system). Each node has the following specs: 2 x 12 core Intel Broadwell processors (24 cores total) 128GB RAM 120GB SSD","title":"Thomas technical specs"},{"location":"Wiki_Export/done/RC_Systems/#aristotle","text":"Aristotle is a teaching machine, usable by everyone. It does not have a batch system - you run programs directly on the nodes and share resources with all other users. Use with consideration!","title":"Aristotle"},{"location":"Wiki_Export/done/RC_Systems/#aristotle-technical-specs","text":"4x 16 core Dell servers with Intel(R) Xeon(R) CPU E5-2650 v2 64 gigabytes of RAM per node RedHat 7.2 No Infiniband so MPI may only be used within a node","title":"Aristotle technical specs"},{"location":"Wiki_Export/done/RC_Systems/#how-do-i-apply-for-an-account","text":"Please apply at Account Services for everything other than Thomas - you will be approved for a Legion and Myriad account. You will be approved for a Grace account if the resources you request meet the requirements. For Thomas, see Applying for a Thomas account .","title":"How do I apply for an account?"},{"location":"Wiki_Export/done/RC_Systems/#access-to-aristotle","text":"Everyone with a UCL account has access to Aristotle. Login via SSH to: aristotle.rc.ucl.ac.uk","title":"Access to Aristotle"},{"location":"Wiki_Export/done/RC_Systems_user_environment/","text":"RC Systems User Environment Operating System \u00b6 Legion, Myriad, and Grace \u00b6 Legion, Myriad, and Grace run a software stack based upon Red Hat Enterprise Linux 7 and Son of Grid Engine. The environment provided should be familiar to users of UNIX-like operating systems. Here is a A Quick Introduction to Unix for those not familiar with this essential operating system. Aristotle \u00b6 Aristotle runs Red Hat Enterprise Linux 6.5. Software \u00b6 As well as the system software, there are a number of applications, libraries and development tools available on our machines, the details of which may be found on the software pages . Modules \u00b6 Our systems use the environment modules system to manage packages. A module configures your current login session or job to use a particular piece of software. For example, this may involve altering your PATH and LD_LIBRARY_PATH environment variables to make the associated commands and/or libraries available at compile-time and/or run-time, without explicitly having to know the relevant paths. A module can for instance be associated with a particular version of the Intel compiler, or particular MPI libraries, or applications software, etc. The default environment has the most commonly required modules already loaded for your convenience. You can see what modules are currently loaded by using the command module list . The default module set is shown in the example below: $ module list Currently Loaded Modulefiles: 1) gcc-libs/4.9.2 8) screen/4.2.1 15) tmux/2.2 2) cmake/3.2.1 9) gerun 16) mrxvt/0.5.4 3) flex/2.5.39 10) nano/2.4.2 17) userscripts/1.3.0 4) git/2.10.2 11) nedit/5.6-aug15 18) rcps-core/1.0.0 5) apr/1.5.2 12) dos2unix/7.3 19) compilers/intel/2017/update1 6) apr-util/1.5.4 13) giflib/5.1.1 20) mpi/intel/2017/update1/intel 7) subversion/1.8.13 14) emacs/24.5 21) default-modules/2017 This output indicates that the Intel compilers are loaded, the Intel MPI environment, editor nedit and some other utilities. In addition to those made available in your default environment, we provide a rich set of additional modules for your use. These can be listed by typing: module whatis Or in a shorter form by typing: module avail You can load additional modules into your current session by using the command: module load For example, to add the module for FFTW 2.1.5 for the Intel compilers, type: module load fftw/2.1.5/intel-2015-update2 Typing module list will now show the above with the addition of the fftw module. You can unload modules from your current session by using the command: module unload For example, to remove the FFTW module, type: module unload fftw/2.1.5/intel-2015-update2 One commonly required change is to switch from using the Intel compiler and associated libraries (which are provided in the default environment), to using the GCC compiler. This would be achieved by typing the following commands: module unload compilers module unload mpi module load compilers/gnu/4.9.2 module load mpi/intel/2015/update3/gnu-4.9.2 Note that the order in which you execute these commands is vital! You must always unload modules before loading their replacements. Typing module list again will show the changes. You can permanently change what modules are loaded by default in your environment by editing your ~/.bashrc file to add the appropriate module load and unload commands at the end. When you first start using a new application, typing module help <module> (where <module> is the name of the application module) will provide you with additional Legion-specific instructions on how to use the application if any are necessary. Module Commands \u00b6 module load loads a module module unload unloads a module module purge unloads all modules module list shows currently loaded modules module avail shows available modules module whatis shows available modules with brief explanations module show List the contents of the module fire. Shows environment variables set-up by the module module help Shows helpful information about a module, including instructions on how to use the application Aristotle-Specific Modules \u00b6 Aristotle mounts the Research Computing software stack, so you will see all the same modules. They won't necessarily all work - everything built specifically for Aristotle will have Aristotle in the module name or else be in the extra module section that will show up at the bottom when using module avail : -------------------- /shared/ucl/apps/eb_ivybridge_noib/modules/all -------------------- Bison/2.7-goolf-1.4.10 OpenMPI/1.6.4-GCC-4.7.2 CMake/2.8.11-goolf-1.4.10 PCRE/8.12-goolf-1.4.10 Docutils/0.9.1-goolf-1.4.10-Python-2.7.3 Python/2.7.3-goolf-1.4.10 Doxygen/1.8.3.1-goolf-1.4.10 ScaLAPACK/2.0.2-gompi-1.4.10-OpenBLAS-0.2.6-LAPACK-3.4.2 EasyBuild/1.15.1 Sphinx/1.1.3-goolf-1.4.10-Python-2.7.3 FFTW/3.3.3-gompi-1.4.10 Szip/2.1-goolf-1.4.10 GCC/4.7.2 bzip2/1.0.6-goolf-1.4.10 GDAL/1.9.2-goolf-1.4.10 flex/2.5.37-goolf-1.4.10 GEOS/3.3.5-goolf-1.4.10 gompi/1.4.10 GMT/5.1.1-goolf-1.4.10 goolf/1.4.10 Ghostscript/9.10-goolf-1.4.10 hwloc/1.6.2-GCC-4.7.2 HDF5/1.8.10-patch1-goolf-1.4.10 libreadline/6.2-goolf-1.4.10 Jinja2/2.6-goolf-1.4.10-Python-2.7.3 ncurses/5.9-goolf-1.4.10 LibTIFF/4.0.3-goolf-1.4.10 netCDF/4.2.1.1-goolf-1.4.10 M4/1.4.16-goolf-1.4.10 setuptools/0.6c11-goolf-1.4.10-Python-2.7.3 OpenBLAS/0.2.6-gompi-1.4.10-LAPACK-3.4.2 zlib/1.2.7-goolf-1.4.10 The others are mixed in with the general modules: here are a few: matlab/full/r2015a/8.5-aristotle recommended/r-aristotle python/2.7.9/gnu.4.7.2-Aristotle gnuplot/5.0.1-Aristotle Aristotle has different default modules: $ module show default-modules-aristotle ------------------------------------------------------------------- /shared/ucl/apps/modulefiles2/bundles/default-modules-aristotle: module-whatis Adds default Aristotle modules to your environment. module load compilers/gnu/4.6.3 module load nedit/5.6 module load mrxvt/0.5.4 -------------------------------------------------------------------","title":"RC Systems user environment"},{"location":"Wiki_Export/done/RC_Systems_user_environment/#operating-system","text":"","title":"Operating System"},{"location":"Wiki_Export/done/RC_Systems_user_environment/#legion-myriad-and-grace","text":"Legion, Myriad, and Grace run a software stack based upon Red Hat Enterprise Linux 7 and Son of Grid Engine. The environment provided should be familiar to users of UNIX-like operating systems. Here is a A Quick Introduction to Unix for those not familiar with this essential operating system.","title":"Legion, Myriad, and Grace"},{"location":"Wiki_Export/done/RC_Systems_user_environment/#aristotle","text":"Aristotle runs Red Hat Enterprise Linux 6.5.","title":"Aristotle"},{"location":"Wiki_Export/done/RC_Systems_user_environment/#software","text":"As well as the system software, there are a number of applications, libraries and development tools available on our machines, the details of which may be found on the software pages .","title":"Software"},{"location":"Wiki_Export/done/RC_Systems_user_environment/#modules","text":"Our systems use the environment modules system to manage packages. A module configures your current login session or job to use a particular piece of software. For example, this may involve altering your PATH and LD_LIBRARY_PATH environment variables to make the associated commands and/or libraries available at compile-time and/or run-time, without explicitly having to know the relevant paths. A module can for instance be associated with a particular version of the Intel compiler, or particular MPI libraries, or applications software, etc. The default environment has the most commonly required modules already loaded for your convenience. You can see what modules are currently loaded by using the command module list . The default module set is shown in the example below: $ module list Currently Loaded Modulefiles: 1) gcc-libs/4.9.2 8) screen/4.2.1 15) tmux/2.2 2) cmake/3.2.1 9) gerun 16) mrxvt/0.5.4 3) flex/2.5.39 10) nano/2.4.2 17) userscripts/1.3.0 4) git/2.10.2 11) nedit/5.6-aug15 18) rcps-core/1.0.0 5) apr/1.5.2 12) dos2unix/7.3 19) compilers/intel/2017/update1 6) apr-util/1.5.4 13) giflib/5.1.1 20) mpi/intel/2017/update1/intel 7) subversion/1.8.13 14) emacs/24.5 21) default-modules/2017 This output indicates that the Intel compilers are loaded, the Intel MPI environment, editor nedit and some other utilities. In addition to those made available in your default environment, we provide a rich set of additional modules for your use. These can be listed by typing: module whatis Or in a shorter form by typing: module avail You can load additional modules into your current session by using the command: module load For example, to add the module for FFTW 2.1.5 for the Intel compilers, type: module load fftw/2.1.5/intel-2015-update2 Typing module list will now show the above with the addition of the fftw module. You can unload modules from your current session by using the command: module unload For example, to remove the FFTW module, type: module unload fftw/2.1.5/intel-2015-update2 One commonly required change is to switch from using the Intel compiler and associated libraries (which are provided in the default environment), to using the GCC compiler. This would be achieved by typing the following commands: module unload compilers module unload mpi module load compilers/gnu/4.9.2 module load mpi/intel/2015/update3/gnu-4.9.2 Note that the order in which you execute these commands is vital! You must always unload modules before loading their replacements. Typing module list again will show the changes. You can permanently change what modules are loaded by default in your environment by editing your ~/.bashrc file to add the appropriate module load and unload commands at the end. When you first start using a new application, typing module help <module> (where <module> is the name of the application module) will provide you with additional Legion-specific instructions on how to use the application if any are necessary.","title":"Modules"},{"location":"Wiki_Export/done/RC_Systems_user_environment/#module-commands","text":"module load loads a module module unload unloads a module module purge unloads all modules module list shows currently loaded modules module avail shows available modules module whatis shows available modules with brief explanations module show List the contents of the module fire. Shows environment variables set-up by the module module help Shows helpful information about a module, including instructions on how to use the application","title":"Module Commands"},{"location":"Wiki_Export/done/RC_Systems_user_environment/#aristotle-specific-modules","text":"Aristotle mounts the Research Computing software stack, so you will see all the same modules. They won't necessarily all work - everything built specifically for Aristotle will have Aristotle in the module name or else be in the extra module section that will show up at the bottom when using module avail : -------------------- /shared/ucl/apps/eb_ivybridge_noib/modules/all -------------------- Bison/2.7-goolf-1.4.10 OpenMPI/1.6.4-GCC-4.7.2 CMake/2.8.11-goolf-1.4.10 PCRE/8.12-goolf-1.4.10 Docutils/0.9.1-goolf-1.4.10-Python-2.7.3 Python/2.7.3-goolf-1.4.10 Doxygen/1.8.3.1-goolf-1.4.10 ScaLAPACK/2.0.2-gompi-1.4.10-OpenBLAS-0.2.6-LAPACK-3.4.2 EasyBuild/1.15.1 Sphinx/1.1.3-goolf-1.4.10-Python-2.7.3 FFTW/3.3.3-gompi-1.4.10 Szip/2.1-goolf-1.4.10 GCC/4.7.2 bzip2/1.0.6-goolf-1.4.10 GDAL/1.9.2-goolf-1.4.10 flex/2.5.37-goolf-1.4.10 GEOS/3.3.5-goolf-1.4.10 gompi/1.4.10 GMT/5.1.1-goolf-1.4.10 goolf/1.4.10 Ghostscript/9.10-goolf-1.4.10 hwloc/1.6.2-GCC-4.7.2 HDF5/1.8.10-patch1-goolf-1.4.10 libreadline/6.2-goolf-1.4.10 Jinja2/2.6-goolf-1.4.10-Python-2.7.3 ncurses/5.9-goolf-1.4.10 LibTIFF/4.0.3-goolf-1.4.10 netCDF/4.2.1.1-goolf-1.4.10 M4/1.4.16-goolf-1.4.10 setuptools/0.6c11-goolf-1.4.10-Python-2.7.3 OpenBLAS/0.2.6-gompi-1.4.10-LAPACK-3.4.2 zlib/1.2.7-goolf-1.4.10 The others are mixed in with the general modules: here are a few: matlab/full/r2015a/8.5-aristotle recommended/r-aristotle python/2.7.9/gnu.4.7.2-Aristotle gnuplot/5.0.1-Aristotle Aristotle has different default modules: $ module show default-modules-aristotle ------------------------------------------------------------------- /shared/ucl/apps/modulefiles2/bundles/default-modules-aristotle: module-whatis Adds default Aristotle modules to your environment. module load compilers/gnu/4.6.3 module load nedit/5.6 module load mrxvt/0.5.4 -------------------------------------------------------------------","title":"Aristotle-Specific Modules"},{"location":"Wiki_Export/done/Reporting_problems/","text":"RC Systems' support process is based around a ticketing system. To submit a ticket please send an e-mail to rc-support@ucl.ac.uk . In order to help our support team deal with your ticket efficiently, please ensure the following is the case: You have a clear description of your problem. This should include: Which system you are using (Legion, Grace, Aristotle etc). Your userid. What you were doing when you got the error. What the error was (including a copy of the exact error message on the email body or a relevant extract). Job IDs, job scripts and job output/error files if relevant. Please avoid creating duplicate tickets. If you are following up on an existing problem, please reply to a response from the ticketing system (or at least a message with the ticket ID in the subject) for the original ticket. This way our support staff will be able to see a complete history of your problem, and it is considerably more likely that your issue will be dealt with by a member of staff who is familiar with the history of your problem.","title":"Reporting problems"},{"location":"Wiki_Export/done/Research_computing_glossary/","text":"Bash \u00b6 A shell and scripting language, which is the default command processor on most Linux operating systems. Cluster \u00b6 A cluster consists of a set of computer nodes connected together over a fast local area network. A message passing protocol such as MPI allows individual nodes to work together as a single system. Core \u00b6 A core refers to a processing unit within a node . A node may have multiple cores which can work in parallel on a single task, operating on the same data in memory. This kind of parallelism is coordinated using the OpenMP library. Alternatively, cores may work independently on different tasks. Cores may or may not also share cache. Interconnect \u00b6 The interconnect is the network which is used to transfer data between nodes in a cluster . Different types of interconnect operate at different bandwidths and with different amounts of latency, which affects the suitability of a collection of nodes for jobs which use message passing ( MPI ). Job \u00b6 In the context of Batch Processing , a job refers to a computational task to be performed such as a single simulation or analysis. Job Script \u00b6 A job script is essentially a special kind of script used to specify the parameters of a job. Users can specify the data to input, program to use, and the computing resources required. The job script is specified when a job is submitted to SGE, which reads lines starting with #$ . MPI \u00b6 The Message Passing Interface (MPI) system is a set of portable libraries which can be incorporated into programs in order to control parallel computation. Specifically it coordinates effort between nodes which do not share the same memory address space cf. OpenMP . Node \u00b6 In cluster computing, a node refers to a computational unit which is capable of operating independently of other parts of the cluster. As a minimum it consists of one (or more) processing cores , has its own memory, and runs its own operating system. OpenMP \u00b6 Open Multi-Processing. OpenMP supports multithreading, a process whereby a master thread generates a number of slave threads to run a task which is divided among them. OpenMP applies to processes running on shared memory platforms, i.e. jobs running on a single node . Hybrid applications may make use of both OpenMP and MPI . Process \u00b6 A process is a single instance of a program that is running on a computer. A single process may consist of many threads acting concurrently, and there may multiple instances of a program running as separate processes. Script \u00b6 A shell script enables users to list commands to be run consecutively by typing them into a text file instead of typing them out live. The first line of the script uses the shebang notation #! to designate the scripting language interpreter program to be used to interpret the commands, e.g. bash . Shebang \u00b6 \"Shebang\" is a common abbreviation for \"hash-bang\" -- the character sequence #! -- which is placed at the start of a script to specify the interpreter that should be used. When the shebang is found in the first line of a script, the program loader reads the rest of the line as the path to the required interpreter (e.g. /bin/bash is the usual path to the bash shell). The specified interpreter is then run with the path to the script passed as an argument to it. Shell \u00b6 A command line interpreter which provides an interface for users to type instructions to be interpreted by the operating system and display output via the monitor. Users type specific shell commands in order to run processes , e.g. ls to list directory contents. Son of Grid Engine (SGE) \u00b6 The queuing system used by many cluster computing systems (including, currently, all the ones we run) to organise and schedule jobs . Once jobs are submitted to SGE, it takes care of executing them when the required resources become available. Job priority is subject to the local fair use policy. Thread \u00b6 A thread refers to a serial computational process which can run on a single core . The number of threads generated by a parallel job may exceed the number of cores available though, in which case cores may alternate between running different threads. Threads are a software concept whereas cores are physical hardware.","title":"Research Computing Glossary"},{"location":"Wiki_Export/done/Research_computing_glossary/#bash","text":"A shell and scripting language, which is the default command processor on most Linux operating systems.","title":"Bash"},{"location":"Wiki_Export/done/Research_computing_glossary/#cluster","text":"A cluster consists of a set of computer nodes connected together over a fast local area network. A message passing protocol such as MPI allows individual nodes to work together as a single system.","title":"Cluster"},{"location":"Wiki_Export/done/Research_computing_glossary/#core","text":"A core refers to a processing unit within a node . A node may have multiple cores which can work in parallel on a single task, operating on the same data in memory. This kind of parallelism is coordinated using the OpenMP library. Alternatively, cores may work independently on different tasks. Cores may or may not also share cache.","title":"Core"},{"location":"Wiki_Export/done/Research_computing_glossary/#interconnect","text":"The interconnect is the network which is used to transfer data between nodes in a cluster . Different types of interconnect operate at different bandwidths and with different amounts of latency, which affects the suitability of a collection of nodes for jobs which use message passing ( MPI ).","title":"Interconnect"},{"location":"Wiki_Export/done/Research_computing_glossary/#job","text":"In the context of Batch Processing , a job refers to a computational task to be performed such as a single simulation or analysis.","title":"Job"},{"location":"Wiki_Export/done/Research_computing_glossary/#job-script","text":"A job script is essentially a special kind of script used to specify the parameters of a job. Users can specify the data to input, program to use, and the computing resources required. The job script is specified when a job is submitted to SGE, which reads lines starting with #$ .","title":"Job Script"},{"location":"Wiki_Export/done/Research_computing_glossary/#mpi","text":"The Message Passing Interface (MPI) system is a set of portable libraries which can be incorporated into programs in order to control parallel computation. Specifically it coordinates effort between nodes which do not share the same memory address space cf. OpenMP .","title":"MPI"},{"location":"Wiki_Export/done/Research_computing_glossary/#node","text":"In cluster computing, a node refers to a computational unit which is capable of operating independently of other parts of the cluster. As a minimum it consists of one (or more) processing cores , has its own memory, and runs its own operating system.","title":"Node"},{"location":"Wiki_Export/done/Research_computing_glossary/#openmp","text":"Open Multi-Processing. OpenMP supports multithreading, a process whereby a master thread generates a number of slave threads to run a task which is divided among them. OpenMP applies to processes running on shared memory platforms, i.e. jobs running on a single node . Hybrid applications may make use of both OpenMP and MPI .","title":"OpenMP"},{"location":"Wiki_Export/done/Research_computing_glossary/#process","text":"A process is a single instance of a program that is running on a computer. A single process may consist of many threads acting concurrently, and there may multiple instances of a program running as separate processes.","title":"Process"},{"location":"Wiki_Export/done/Research_computing_glossary/#script","text":"A shell script enables users to list commands to be run consecutively by typing them into a text file instead of typing them out live. The first line of the script uses the shebang notation #! to designate the scripting language interpreter program to be used to interpret the commands, e.g. bash .","title":"Script"},{"location":"Wiki_Export/done/Research_computing_glossary/#shebang","text":"\"Shebang\" is a common abbreviation for \"hash-bang\" -- the character sequence #! -- which is placed at the start of a script to specify the interpreter that should be used. When the shebang is found in the first line of a script, the program loader reads the rest of the line as the path to the required interpreter (e.g. /bin/bash is the usual path to the bash shell). The specified interpreter is then run with the path to the script passed as an argument to it.","title":"Shebang"},{"location":"Wiki_Export/done/Research_computing_glossary/#shell","text":"A command line interpreter which provides an interface for users to type instructions to be interpreted by the operating system and display output via the monitor. Users type specific shell commands in order to run processes , e.g. ls to list directory contents.","title":"Shell"},{"location":"Wiki_Export/done/Research_computing_glossary/#son-of-grid-engine-sge","text":"The queuing system used by many cluster computing systems (including, currently, all the ones we run) to organise and schedule jobs . Once jobs are submitted to SGE, it takes care of executing them when the required resources become available. Job priority is subject to the local fair use policy.","title":"Son of Grid Engine (SGE)"},{"location":"Wiki_Export/done/Research_computing_glossary/#thread","text":"A thread refers to a serial computational process which can run on a single core . The number of threads generated by a parallel job may exceed the number of cores available though, in which case cores may alternate between running different threads. Threads are a software concept whereas cores are physical hardware.","title":"Thread"},{"location":"Wiki_Export/done/Terms_And_Conditions/","text":"All use of Research Computing Platforms is subject to the UCL Computing Regulations . All users will be required to renew their account once per year. Users will receive a reminder one month prior to suspension of their Legion account sent to their Live@UCL e-mail address. Funding information will need to be provided upon application, and publication information upon renewal. Users are forbidden from performing production runs on login nodes. The Research Computing Platform Services Team reserve the right to suspend or ban without prior warning any use of the system which impairs its operation. With the exception of in cases where there is imminent harm or risk to the service, the Research Computing Platform Services Team will not access your files without permission. Official service notifications are sent to the legion-users (or the equivalent for other services) mailing list. Users are automatically subscribed to this list using their Live@UCL e-mail address and should read notices sent there. The Research Computing Platform Services Team reserve the right to suspend users' accounts, without notice, in the event of a user being the subject of any UCL disciplinary procedure, or where a user is found to be in breach of UCL\u2019s Computing Regulations or best practice guidelines regarding password management, as provided by Information Services Division. Users are required to acknowledge their use of Research Computing services in any publications describing research that has been conducted, in any part, using our services. This should be done according to the descriptions here . All support requests should be sent by e-mail to rc-support@ucl.ac.uk .","title":"Terms and Conditions"},{"location":"Wiki_Export/done/The_Scheduler/","text":"One of the biggest concerns users experience when running jobs in a scheduled environment is uncertainty over when jobs they have submitted will run. Scheduler policies are always complex, there are many other users on the machine and it can be extremely frustrating to see other users' jobs running while yours remain in the queue. Some users end up driven to spend most of their time scrutinising the output of qstat, desperately trying to come up with a formula for job submission that will skip them further up the queue, before sending a somewhat grumpy ticket to the service desk to ask what is going on. Here we will attempt to explain some of this scheduler behaviour to alleviate some common concerns about how the system works. The scheduler is not a queue \u00b6 The first (and most basic), thing to understand is that the system does not operate a first in, first out queue like users might expect. In many ways, the scheduler does not behave like a queue at all. For a start, the scheduler is not dealing with jobs that are all the same size. Some jobs are large parallel jobs, while other jobs are smaller or even serial. This means that if you operate on a first come, first serve basis, then large parallel jobs will block the execution of smaller jobs while they wait for nodes to become free, wasting a great deal of resource. If instead the system were to operate in such a way as to run the next job that will fit into the available resource, then large parallel jobs would never run at all, because the resources needed to run on them would always be allocated to smaller jobs first. As a result, the scheduler needs to be implemented in such a way as to provide a balance between these behaviours. Scheduler behaviour on Legion is further complicated by our policy of fair-share (where the priority of heavy users is automatically lower than the priority of light users) which is necessitated by Legion being a \"free\" at the point of use resource. What this means is that the scheduler schedules jobs based on: The matching of available resources to the job The priority of the job Job priority is almost entirely based on three factors: fair-share weighting, wall clock time requested and how long the job has been in the queue (longer = higher priority). This all seems relatively simple so far, and you might be wondering \"why can't I have a tool which will tell me when my job will run?\". The answer is simple: The time your job will run is not only affected by the state of the queue when you submit the job, but also by any higher priority jobs (as a result of fair-share) which are submitted after your job is submitted. We have a big random number generator attached to the scheduler called \"users\" who submit jobs in an unpredictable fashion with inaccurate wall clock time estimates. With fair share, you have a priority parameter that modifies constantly the queue arrangement, depending on jobs being submitted at any given time. Any snapshot you take of the queue cannot be representative of its overall behaviour. You have to gather statistics over time, and that is what the CRAG does every month. User X is using most of the machine \u00b6 Another common complaint (from some user we shall call \"Y\") comes in the form \"I'm trying to get some very important results, my jobs are in the queue, but user X is running hundreds of cores worth of jobs on the machine and more of their jobs are starting all of the time!\". This can usually be explained by one of, or a combination of, these two possibilities: User Y's jobs are hard to schedule (this usually means large parallel jobs), whereas user X's jobs fit into the gaps between other jobs. User X's jobs have been in the queue for a very long time and therefore have an unusually high priority due to wait time. This behaviour is camouflaged somewhat by the qstat command because it uses one field for job submission/job start time and so when the job starts, it displays the start time rather than the submission time. This can give other users the impression that user X is getting unfair access to the resource (often made worse if user X is submitting large arrays of single processor jobs) but should be clear that if the cause is a) the scheduler is merely being efficient, and if it is b) it is being fair. Cores != Slots \u00b6 Another confusion that can arise is in utilisation of the machine. It may seem obvious to the user that the number of cores in use is the sum of the number of slots requested by jobs in the \"running\" state, but this is NOT the case. This confusion can lead to tickets of the form \"half the cluster is not in use but my jobs still aren\u2019t running!\". The reason this is the case is as follows: If a user requests more RAM per process than is available per core on the node type their job runs on, then they will be consuming additional cores which are not reflected in the number of slots they have requested. This problem is made considerably worse by users over-estimating the amount of RAM that their job needs. Doing a na\u00efve count of the number of slots in use will give a user the impression that the machine is under-used.","title":"How the scheduler works"},{"location":"Wiki_Export/done/The_Scheduler/#the-scheduler-is-not-a-queue","text":"The first (and most basic), thing to understand is that the system does not operate a first in, first out queue like users might expect. In many ways, the scheduler does not behave like a queue at all. For a start, the scheduler is not dealing with jobs that are all the same size. Some jobs are large parallel jobs, while other jobs are smaller or even serial. This means that if you operate on a first come, first serve basis, then large parallel jobs will block the execution of smaller jobs while they wait for nodes to become free, wasting a great deal of resource. If instead the system were to operate in such a way as to run the next job that will fit into the available resource, then large parallel jobs would never run at all, because the resources needed to run on them would always be allocated to smaller jobs first. As a result, the scheduler needs to be implemented in such a way as to provide a balance between these behaviours. Scheduler behaviour on Legion is further complicated by our policy of fair-share (where the priority of heavy users is automatically lower than the priority of light users) which is necessitated by Legion being a \"free\" at the point of use resource. What this means is that the scheduler schedules jobs based on: The matching of available resources to the job The priority of the job Job priority is almost entirely based on three factors: fair-share weighting, wall clock time requested and how long the job has been in the queue (longer = higher priority). This all seems relatively simple so far, and you might be wondering \"why can't I have a tool which will tell me when my job will run?\". The answer is simple: The time your job will run is not only affected by the state of the queue when you submit the job, but also by any higher priority jobs (as a result of fair-share) which are submitted after your job is submitted. We have a big random number generator attached to the scheduler called \"users\" who submit jobs in an unpredictable fashion with inaccurate wall clock time estimates. With fair share, you have a priority parameter that modifies constantly the queue arrangement, depending on jobs being submitted at any given time. Any snapshot you take of the queue cannot be representative of its overall behaviour. You have to gather statistics over time, and that is what the CRAG does every month.","title":"The scheduler is not a queue"},{"location":"Wiki_Export/done/The_Scheduler/#user-x-is-using-most-of-the-machine","text":"Another common complaint (from some user we shall call \"Y\") comes in the form \"I'm trying to get some very important results, my jobs are in the queue, but user X is running hundreds of cores worth of jobs on the machine and more of their jobs are starting all of the time!\". This can usually be explained by one of, or a combination of, these two possibilities: User Y's jobs are hard to schedule (this usually means large parallel jobs), whereas user X's jobs fit into the gaps between other jobs. User X's jobs have been in the queue for a very long time and therefore have an unusually high priority due to wait time. This behaviour is camouflaged somewhat by the qstat command because it uses one field for job submission/job start time and so when the job starts, it displays the start time rather than the submission time. This can give other users the impression that user X is getting unfair access to the resource (often made worse if user X is submitting large arrays of single processor jobs) but should be clear that if the cause is a) the scheduler is merely being efficient, and if it is b) it is being fair.","title":"User X is using most of the machine"},{"location":"Wiki_Export/done/The_Scheduler/#cores-33-slots","text":"Another confusion that can arise is in utilisation of the machine. It may seem obvious to the user that the number of cores in use is the sum of the number of slots requested by jobs in the \"running\" state, but this is NOT the case. This confusion can lead to tickets of the form \"half the cluster is not in use but my jobs still aren\u2019t running!\". The reason this is the case is as follows: If a user requests more RAM per process than is available per core on the node type their job runs on, then they will be consuming additional cores which are not reflected in the number of slots they have requested. This problem is made considerably worse by users over-estimating the amount of RAM that their job needs. Doing a na\u00efve count of the number of slots in use will give a user the impression that the machine is under-used.","title":"Cores != Slots"},{"location":"Wiki_Export/done/Thomas/","text":"Thomas is the UK National Tier 2 High Performance Computing Hub in Materials and Molecular Modelling. Applying for an account \u00b6 Thomas accounts belong to you as an individual and are applied for through your own institution's Point of Contact . You will need to supply an SSH public key, which is the only method used to log in. Creating an ssh key pair \u00b6 An ssh key consists of a public and a private part, typically named id_rsa and id_rsa.pub by default. The public part is what we need. You must not share your private key with anyone else. You can copy it onto multiple machines belonging to you so you can log in from all of them (or you can have a separate pair for each machine). Creating an ssh key in Linux/Unix/Mac OS X \u00b6 ssh-keygen -t rsa The defaults should give you a reasonable key. If you prefer to use ECDSA or ED25519 instead, and longer keys, you can. You can also tell it to create one with a different name, so it doesn't overwrite any existing key. We strongly suggest you not use DSA as OpenSSH 7.0 has deprecated it and does not use it by default on client or server. Thomas currently accepts them but that may change. You will be asked to add a passphrase for your key. A blank passphrase is not recommended; if you use one please make sure that no one else ever has access to your local computer account. How often you are asked for a passphrase depends on how long your local ssh agent keeps it. You may need to run ssh-add to add the key to your agent so you can use it. If you aren't sure what keys your agent can see, running ssh-add -L will show all the public parts of the keys it is aware of. Creating an ssh key in Windows \u00b6 Have a look at Key-Based SSH Logins With PuTTY which has step-by-step instructions. You can choose whether to use Pageant or not to manage your key. You can again pick RSA, DSA, ECDSA etc but do not pick SSH-1 as that is a very old and insecure key type. Information for Points of Contact \u00b6 Points of Contact have some tools they can use to manage users and allocations, documented at Points of Contact . Logging in \u00b6 You will be assigned a personal username and your SSH key pair will be used to log in. External users will have a username in the form mmmxxxx and UCL users will use their central username. You ssh directly to: thomas.rc.ucl.ac.uk SSH timeouts \u00b6 Idle ssh sessions will be disconnected after 7 days. Using the system \u00b6 Thomas is a batch system. The login nodes allow you to manage your files, compile code and submit jobs. Very short (\\<15mins) and non-resource-intensive software tests can be run on the login nodes, but anything more should be submitted as a job. Full user guide \u00b6 Thomas has the same user environment as RC Support's other clusters, so the User guide is relevant and is a good starting point for further information about how the environment works. Any variations that Thomas has should be listed on this page. Submitting a job \u00b6 Create a jobscript for non-interactive use and submit it using qsub . Jobscripts must begin #!/bin/bash -l in order to run as a login shell and get your login environment and modules. A job on Thomas must also specify what type of job it is (Gold, Free, Test) and the project it is being submitted for. (See Budgets and allocations below.) Memory requests \u00b6 Note: the memory you request is always per core, not the total amount. If you ask for 128GB RAM and 24 cores, that will run on 24 nodes using only one core per node. This allows you to have sparse process placement when you do actually need that much RAM per process. Monitoring a job \u00b6 In addition to qstat , nodesforjob $JOB_ID can be useful to see what proportion of cpu/memory/swap is being used on the nodes a certain job is running on. qexplain $JOB_ID will show you the full error for a job that is in Eqw status. Useful utilities \u00b6 As well as nodesforjob , there are the following utilities which can help you find information about your jobs after they have run. jobhist - shows your job history for the last 24hrs by default, including start and end times and the head node it ran on. You can view a longer history by specifying --hours=100 for example. scriptfor $JOB_ID - show the script that was submitted for the given job. These utilities live in GitHub at https://github.com/UCL-RITS/go-clustertools and https://github.com/UCL-RITS/rcps-cluster-scripts Queue names \u00b6 On Thomas, users do not submit directly to queues - the scheduler assigns your job to one based on the resources it requested. The queues have somewhat unorthodox names as they are only used internally, but this is what they mean: Jerry: single-node job Tom: multi-node job Spike: cross-CU job, using superqueue (any multi-node job may end up using this) Software \u00b6 Thomas mounts the RC Systems software stack . Have a look at Applications for specific information on running some applications, including example scripts. The list there is not exhaustive. Access to software is managed through the use of modules. module avail shows all modules available. module list shows modules currently loaded. Access to licensed software may vary based on your host institution and project. Requesting software installs \u00b6 To request software installs, email us at the support address below or open an issue on our GitHub . You can see what software has already been requested in the Github issues and can add a comment if you're also interested in something already requested. Installing your own software \u00b6 You may install software in your own space. Please look at Compiling for tips. Maintaining a piece of software for a group \u00b6 It is possible for people to be given central areas to install software that they wish to make available to everyone or to a select group - generally because they are the developers or if they wish to use multiple versions or developer versions. The people given install access would then be responsible for managing and maintaining these installs. Licensed software \u00b6 Reserved application groups exist for software that requires them. The group name will begin with leg or lg . After we add you to one of these groups, the central group change will happen overnight. You can check your groups with the groups command. Please let us know your username when you ask to be added to a group. CASTEP : You/your group leader need to have signed up for a CASTEP license . Send us an acceptance email, or we can ask them to verify you have a license. You will then be added to the reserved application group lgcastep . If you are a member of UKCP you are already covered by a license and just need to tell us when you request access. CRYSTAL : You/your group leader need to have signed up for an Academic license. Crystal Solutions will send an email saying an account has been upgraded to \"Academic UK\" - forward that to us along with confirmation from the group leader that you should be in their group. You will be added to the legcryst group. DL_POLY : has individual licenses for specific versions. Sign up at DL_POLY's website and send us the acceptance email they give you. We will add you to the appropriate version's reserved application group, eg lgdlp408 . Gaussian : not currently accessible for non-UCL institutions. UCL having a site license and another institute having a site license does not allow users from the other institute to run Gaussian on UCL-owned hardware. VASP : When you request access you need to send us the name and email of the main VASP license holder along with the license number. We will then ask VASP if we can add you, and on confirmation can do so. We will add you to the legvasp reserved application group. You may also install your own copy in your home, and we provide a simple build script on Github (tested with VASP 5.4.4, no patches). You need to download the VASP source code and then you can run the script following the instructions at the top. Suggested job sizes \u00b6 The target job sizes for Thomas are 48-120 cores (2-5 nodes). Jobs larger than this may have a longer queue time and are better suited to ARCHER, and single node jobs may be more suited to your local facilities. Maximum job resources \u00b6 Cores Max wallclock 864 48hrs On Thomas, interactive sessions using qrsh have the same wallclock limit as other jobs. Nodes in Thomas are 24 cores, 128G RAM. The default maximum jobsize is 864 cores, to remain within the 36-node 1:1 nonblocking interconnect zones. Jobs on Thomas do not share nodes . This means that if you request less than 24 cores, your job is still taking up an entire node and no other jobs can run on it, but some of the cores are idle. Whenever possible, request a number of cores that is a multiple of 24 for full usage of your nodes. There is a superqueue for use in exceptional circumstances that will allow access to a larger number of cores outside the nonblocking interconnect zones, going across the 3:1 interconnect between blocks. A third of each CU is accessible this way, roughly approximating a 1:1 connection. Access to the superqueue for larger jobs must be applied for: contact the support address below for details. Some normal multi-node jobs will use the superqueue - this is to make it easier for larger jobs to be scheduled, as otherwise they can have very long waits if every CU is half full. back to top Budgets and allocations \u00b6 We have enabled Gold for allocation management. Jobs that are run under a project budget have higher priority than free non-budgeted jobs. All jobs need to specify what project they belong to, whether they are paid or free. To see the name of your project(s) and how much allocation that budget has, run the command budgets . budgets` Project Machines Balance -------- -------- -------- UCL_Test ANY 22781.89 Pilot users temporarily had access to a project for their institution, eg. Imperial_pilot. These projects are no longer active and will not show up. Subprojects \u00b6 You might be in a subproject that does not itself have an allocation, but instead takes allocation from a different project: Project Machines Balance -------- -------- -------- UCL_physM ANY 474999.70 UCL_physM_Bowler ANY 0.00 In this case, you submit jobs using the subproject ( UCL_physM_Bowler here) even though it says it has 0 budget and it takes Gold from the superproject. Submitting a job under a project \u00b6 To submit a paid job that will take Gold from a particular project budget, add this to your jobscript: #$ -P Gold #$ -A MyProject To submit a free job that will not use up any Gold, use this instead: #$ -P Free #$ -A MyProject You can also submit testing jobs that will not use up any Gold, and will have higher priority than normal free jobs, but are limited to 2 nodes (48 cores) and 1 hour of walltime: #$ -P Test #$ -A MyProject Troubleshooting: Unable to verify membership of username in the policyjsv project \u00b6 Unable to run job: Rejected by policyjsv Unable to verify membership of `<username>` in the policyjsv project You asked for a Free job but didn't specify #$ -A MyProject in your jobscript. Gold charging \u00b6 When you submit a job, it will reserve the total number of core hours that the job script is asking for. When the job ends, the Gold will move from 'reserved' into charged. If the job doesn't run for the full time it asked for, the unused reserved portion will be refunded after the job ends. You cannot submit a job that you do not have the budget to run. Troubleshooting: Unable to verify sufficient material worth to submit this job \u00b6 Unable to run job: Rejected by policyjsv Reason:Unable to verify sufficient material worth to submit this job: Insufficient balance to reserve job This means you don't have enough Gold to cover the cores \u2a09 wallclock time cost of the job you are trying to submit. You need to wait for queued jobs to finish and return unused Gold to your project, or submit a smaller/shorter job. Note that array jobs have to cover the whole cost of all the tasks at submit time. Job deletion \u00b6 If you qdel a submitted Gold job, the reserved Gold will be made available again. This is done by a cron job that runs every 15 minutes, so you may not see it back instantly. Support \u00b6 Email rc-support@ucl.ac.uk with any support queries. It will be helpful to include Thomas in the subject along with some descriptive text about the type of problem, and you should mention your username in the body. Acknowledging the use of Thomas in publications \u00b6 All work arising from this facility should be properly acknowledged in presentations and papers with the following text: \"We are grateful to the UK Materials and Molecular Modelling Hub for computational resources, which is partially funded by EPSRC (EP/P020194/1)\" MCC \u00b6 When publishing work that benefited from resources allocated by the MCC: please include the following acknowledgment: \"Via our membership of the UK's HEC Materials Chemistry Consortium, which is funded by EPSRC (EP/L000202), this work used the UK Materials and Molecular Modelling Hub for computational resources, MMM Hub, which is partially funded by EPSRC (EP/P020194)\" UKCP \u00b6 When publishing work that benefited from resources allocated by UKCP , please include: \"We are grateful for computational support from the UK Materials and Molecular Modelling Hub, which is partially funded by EPSRC (EP/P020194), for which access was obtained via the UKCP consortium and funded by EPSRC grant ref EP/P022561/1\"","title":"Thomas"},{"location":"Wiki_Export/done/Thomas/#applying-for-an-account","text":"Thomas accounts belong to you as an individual and are applied for through your own institution's Point of Contact . You will need to supply an SSH public key, which is the only method used to log in.","title":"Applying for an account"},{"location":"Wiki_Export/done/Thomas/#creating-an-ssh-key-pair","text":"An ssh key consists of a public and a private part, typically named id_rsa and id_rsa.pub by default. The public part is what we need. You must not share your private key with anyone else. You can copy it onto multiple machines belonging to you so you can log in from all of them (or you can have a separate pair for each machine).","title":"Creating an ssh key pair"},{"location":"Wiki_Export/done/Thomas/#creating-an-ssh-key-in-linuxunixmac-os-x","text":"ssh-keygen -t rsa The defaults should give you a reasonable key. If you prefer to use ECDSA or ED25519 instead, and longer keys, you can. You can also tell it to create one with a different name, so it doesn't overwrite any existing key. We strongly suggest you not use DSA as OpenSSH 7.0 has deprecated it and does not use it by default on client or server. Thomas currently accepts them but that may change. You will be asked to add a passphrase for your key. A blank passphrase is not recommended; if you use one please make sure that no one else ever has access to your local computer account. How often you are asked for a passphrase depends on how long your local ssh agent keeps it. You may need to run ssh-add to add the key to your agent so you can use it. If you aren't sure what keys your agent can see, running ssh-add -L will show all the public parts of the keys it is aware of.","title":"Creating an ssh key in Linux/Unix/Mac OS X"},{"location":"Wiki_Export/done/Thomas/#creating-an-ssh-key-in-windows","text":"Have a look at Key-Based SSH Logins With PuTTY which has step-by-step instructions. You can choose whether to use Pageant or not to manage your key. You can again pick RSA, DSA, ECDSA etc but do not pick SSH-1 as that is a very old and insecure key type.","title":"Creating an ssh key in Windows"},{"location":"Wiki_Export/done/Thomas/#information-for-points-of-contact","text":"Points of Contact have some tools they can use to manage users and allocations, documented at Points of Contact .","title":"Information for Points of Contact"},{"location":"Wiki_Export/done/Thomas/#logging-in","text":"You will be assigned a personal username and your SSH key pair will be used to log in. External users will have a username in the form mmmxxxx and UCL users will use their central username. You ssh directly to: thomas.rc.ucl.ac.uk","title":"Logging in"},{"location":"Wiki_Export/done/Thomas/#ssh-timeouts","text":"Idle ssh sessions will be disconnected after 7 days.","title":"SSH timeouts"},{"location":"Wiki_Export/done/Thomas/#using-the-system","text":"Thomas is a batch system. The login nodes allow you to manage your files, compile code and submit jobs. Very short (\\<15mins) and non-resource-intensive software tests can be run on the login nodes, but anything more should be submitted as a job.","title":"Using the system"},{"location":"Wiki_Export/done/Thomas/#full-user-guide","text":"Thomas has the same user environment as RC Support's other clusters, so the User guide is relevant and is a good starting point for further information about how the environment works. Any variations that Thomas has should be listed on this page.","title":"Full user guide"},{"location":"Wiki_Export/done/Thomas/#submitting-a-job","text":"Create a jobscript for non-interactive use and submit it using qsub . Jobscripts must begin #!/bin/bash -l in order to run as a login shell and get your login environment and modules. A job on Thomas must also specify what type of job it is (Gold, Free, Test) and the project it is being submitted for. (See Budgets and allocations below.)","title":"Submitting a job"},{"location":"Wiki_Export/done/Thomas/#memory-requests","text":"Note: the memory you request is always per core, not the total amount. If you ask for 128GB RAM and 24 cores, that will run on 24 nodes using only one core per node. This allows you to have sparse process placement when you do actually need that much RAM per process.","title":"Memory requests"},{"location":"Wiki_Export/done/Thomas/#monitoring-a-job","text":"In addition to qstat , nodesforjob $JOB_ID can be useful to see what proportion of cpu/memory/swap is being used on the nodes a certain job is running on. qexplain $JOB_ID will show you the full error for a job that is in Eqw status.","title":"Monitoring a job"},{"location":"Wiki_Export/done/Thomas/#useful-utilities","text":"As well as nodesforjob , there are the following utilities which can help you find information about your jobs after they have run. jobhist - shows your job history for the last 24hrs by default, including start and end times and the head node it ran on. You can view a longer history by specifying --hours=100 for example. scriptfor $JOB_ID - show the script that was submitted for the given job. These utilities live in GitHub at https://github.com/UCL-RITS/go-clustertools and https://github.com/UCL-RITS/rcps-cluster-scripts","title":"Useful utilities"},{"location":"Wiki_Export/done/Thomas/#queue-names","text":"On Thomas, users do not submit directly to queues - the scheduler assigns your job to one based on the resources it requested. The queues have somewhat unorthodox names as they are only used internally, but this is what they mean: Jerry: single-node job Tom: multi-node job Spike: cross-CU job, using superqueue (any multi-node job may end up using this)","title":"Queue names"},{"location":"Wiki_Export/done/Thomas/#software","text":"Thomas mounts the RC Systems software stack . Have a look at Applications for specific information on running some applications, including example scripts. The list there is not exhaustive. Access to software is managed through the use of modules. module avail shows all modules available. module list shows modules currently loaded. Access to licensed software may vary based on your host institution and project.","title":"Software"},{"location":"Wiki_Export/done/Thomas/#requesting-software-installs","text":"To request software installs, email us at the support address below or open an issue on our GitHub . You can see what software has already been requested in the Github issues and can add a comment if you're also interested in something already requested.","title":"Requesting software installs"},{"location":"Wiki_Export/done/Thomas/#installing-your-own-software","text":"You may install software in your own space. Please look at Compiling for tips.","title":"Installing your own software"},{"location":"Wiki_Export/done/Thomas/#maintaining-a-piece-of-software-for-a-group","text":"It is possible for people to be given central areas to install software that they wish to make available to everyone or to a select group - generally because they are the developers or if they wish to use multiple versions or developer versions. The people given install access would then be responsible for managing and maintaining these installs.","title":"Maintaining a piece of software for a group"},{"location":"Wiki_Export/done/Thomas/#licensed-software","text":"Reserved application groups exist for software that requires them. The group name will begin with leg or lg . After we add you to one of these groups, the central group change will happen overnight. You can check your groups with the groups command. Please let us know your username when you ask to be added to a group. CASTEP : You/your group leader need to have signed up for a CASTEP license . Send us an acceptance email, or we can ask them to verify you have a license. You will then be added to the reserved application group lgcastep . If you are a member of UKCP you are already covered by a license and just need to tell us when you request access. CRYSTAL : You/your group leader need to have signed up for an Academic license. Crystal Solutions will send an email saying an account has been upgraded to \"Academic UK\" - forward that to us along with confirmation from the group leader that you should be in their group. You will be added to the legcryst group. DL_POLY : has individual licenses for specific versions. Sign up at DL_POLY's website and send us the acceptance email they give you. We will add you to the appropriate version's reserved application group, eg lgdlp408 . Gaussian : not currently accessible for non-UCL institutions. UCL having a site license and another institute having a site license does not allow users from the other institute to run Gaussian on UCL-owned hardware. VASP : When you request access you need to send us the name and email of the main VASP license holder along with the license number. We will then ask VASP if we can add you, and on confirmation can do so. We will add you to the legvasp reserved application group. You may also install your own copy in your home, and we provide a simple build script on Github (tested with VASP 5.4.4, no patches). You need to download the VASP source code and then you can run the script following the instructions at the top.","title":"Licensed software"},{"location":"Wiki_Export/done/Thomas/#suggested-job-sizes","text":"The target job sizes for Thomas are 48-120 cores (2-5 nodes). Jobs larger than this may have a longer queue time and are better suited to ARCHER, and single node jobs may be more suited to your local facilities.","title":"Suggested job sizes"},{"location":"Wiki_Export/done/Thomas/#maximum-job-resources","text":"Cores Max wallclock 864 48hrs On Thomas, interactive sessions using qrsh have the same wallclock limit as other jobs. Nodes in Thomas are 24 cores, 128G RAM. The default maximum jobsize is 864 cores, to remain within the 36-node 1:1 nonblocking interconnect zones. Jobs on Thomas do not share nodes . This means that if you request less than 24 cores, your job is still taking up an entire node and no other jobs can run on it, but some of the cores are idle. Whenever possible, request a number of cores that is a multiple of 24 for full usage of your nodes. There is a superqueue for use in exceptional circumstances that will allow access to a larger number of cores outside the nonblocking interconnect zones, going across the 3:1 interconnect between blocks. A third of each CU is accessible this way, roughly approximating a 1:1 connection. Access to the superqueue for larger jobs must be applied for: contact the support address below for details. Some normal multi-node jobs will use the superqueue - this is to make it easier for larger jobs to be scheduled, as otherwise they can have very long waits if every CU is half full. back to top","title":"Maximum job resources"},{"location":"Wiki_Export/done/Thomas/#budgets-and-allocations","text":"We have enabled Gold for allocation management. Jobs that are run under a project budget have higher priority than free non-budgeted jobs. All jobs need to specify what project they belong to, whether they are paid or free. To see the name of your project(s) and how much allocation that budget has, run the command budgets . budgets` Project Machines Balance -------- -------- -------- UCL_Test ANY 22781.89 Pilot users temporarily had access to a project for their institution, eg. Imperial_pilot. These projects are no longer active and will not show up.","title":"Budgets and allocations"},{"location":"Wiki_Export/done/Thomas/#subprojects","text":"You might be in a subproject that does not itself have an allocation, but instead takes allocation from a different project: Project Machines Balance -------- -------- -------- UCL_physM ANY 474999.70 UCL_physM_Bowler ANY 0.00 In this case, you submit jobs using the subproject ( UCL_physM_Bowler here) even though it says it has 0 budget and it takes Gold from the superproject.","title":"Subprojects"},{"location":"Wiki_Export/done/Thomas/#submitting-a-job-under-a-project","text":"To submit a paid job that will take Gold from a particular project budget, add this to your jobscript: #$ -P Gold #$ -A MyProject To submit a free job that will not use up any Gold, use this instead: #$ -P Free #$ -A MyProject You can also submit testing jobs that will not use up any Gold, and will have higher priority than normal free jobs, but are limited to 2 nodes (48 cores) and 1 hour of walltime: #$ -P Test #$ -A MyProject","title":"Submitting a job under a project"},{"location":"Wiki_Export/done/Thomas/#troubleshooting-unable-to-verify-membership-of-username-in-the-policyjsv-project","text":"Unable to run job: Rejected by policyjsv Unable to verify membership of `<username>` in the policyjsv project You asked for a Free job but didn't specify #$ -A MyProject in your jobscript.","title":"Troubleshooting: Unable to verify membership of username in the policyjsv project"},{"location":"Wiki_Export/done/Thomas/#gold-charging","text":"When you submit a job, it will reserve the total number of core hours that the job script is asking for. When the job ends, the Gold will move from 'reserved' into charged. If the job doesn't run for the full time it asked for, the unused reserved portion will be refunded after the job ends. You cannot submit a job that you do not have the budget to run.","title":"Gold charging"},{"location":"Wiki_Export/done/Thomas/#troubleshooting-unable-to-verify-sufficient-material-worth-to-submit-this-job","text":"Unable to run job: Rejected by policyjsv Reason:Unable to verify sufficient material worth to submit this job: Insufficient balance to reserve job This means you don't have enough Gold to cover the cores \u2a09 wallclock time cost of the job you are trying to submit. You need to wait for queued jobs to finish and return unused Gold to your project, or submit a smaller/shorter job. Note that array jobs have to cover the whole cost of all the tasks at submit time.","title":"Troubleshooting: Unable to verify sufficient material worth to submit this job"},{"location":"Wiki_Export/done/Thomas/#job-deletion","text":"If you qdel a submitted Gold job, the reserved Gold will be made available again. This is done by a cron job that runs every 15 minutes, so you may not see it back instantly.","title":"Job deletion"},{"location":"Wiki_Export/done/Thomas/#support","text":"Email rc-support@ucl.ac.uk with any support queries. It will be helpful to include Thomas in the subject along with some descriptive text about the type of problem, and you should mention your username in the body.","title":"Support"},{"location":"Wiki_Export/done/Thomas/#acknowledging-the-use-of-thomas-in-publications","text":"All work arising from this facility should be properly acknowledged in presentations and papers with the following text: \"We are grateful to the UK Materials and Molecular Modelling Hub for computational resources, which is partially funded by EPSRC (EP/P020194/1)\"","title":"Acknowledging the use of Thomas in publications"},{"location":"Wiki_Export/done/Thomas/#mcc","text":"When publishing work that benefited from resources allocated by the MCC: please include the following acknowledgment: \"Via our membership of the UK's HEC Materials Chemistry Consortium, which is funded by EPSRC (EP/L000202), this work used the UK Materials and Molecular Modelling Hub for computational resources, MMM Hub, which is partially funded by EPSRC (EP/P020194)\"","title":"MCC"},{"location":"Wiki_Export/done/Thomas/#ukcp","text":"When publishing work that benefited from resources allocated by UKCP , please include: \"We are grateful for computational support from the UK Materials and Molecular Modelling Hub, which is partially funded by EPSRC (EP/P020194), for which access was obtained via the UKCP consortium and funded by EPSRC grant ref EP/P022561/1\"","title":"UKCP"},{"location":"Wiki_Export/done/Training/","text":"Upcoming Courses \u00b6 Previous Courses \u00b6 Below is a list of some of the training courses we have run over the past year. Please email rits@ucl.ac.uk if you are interested in any of these courses and we will notify you the next time that course is being run. Recommended Online Resources \u00b6 In addition to providing our own courses and training materials we also regularly try out some of the many free online courses available for learning different aspects of research computing. Those we recommend are listed here by category.","title":"Training"},{"location":"Wiki_Export/done/Training/#upcoming-courses","text":"","title":"Upcoming Courses"},{"location":"Wiki_Export/done/Training/#previous-courses","text":"Below is a list of some of the training courses we have run over the past year. Please email rits@ucl.ac.uk if you are interested in any of these courses and we will notify you the next time that course is being run.","title":"Previous Courses"},{"location":"Wiki_Export/done/Training/#recommended-online-resources","text":"In addition to providing our own courses and training materials we also regularly try out some of the many free online courses available for learning different aspects of research computing. Those we recommend are listed here by category.","title":"Recommended Online Resources"},{"location":"Wiki_Export/done/UCL_UK_e-Science_Certificates/","text":"UCL Information Services serves as a local Registration Authority for the authentication of applications for e-Science Certificates. A valid e-Science certificate is required to gain access to the resources of the National e-Infrastructure Service (NES) (amongst others). Brief information to help you in applying for an e-Science Certificate is provided below. More detailed information can be found on the NGS Support website . Scope of the UCL Registration Authority \u00b6 In general, the UCL Registration Authority (RA) can only approve personal and server certificate requests for members of UCL and those associated with projects based at UCL. However we have approved personal certificate requests for members of other London institutions without local RAs on request. Before you Apply for a Certificate \u00b6 The recommended method for applying for a certificate is to use the Certificate Wizard. So: Download the CertWizard java application or use WebStart from the Certificate Wizard page on the NES website. Install the application on your computer. Run the Certificate Wizard application. Applying for a Certificate \u00b6 You will be asked for a number of items when completing your request including: Certificate Wizard keystore password. Your certificates are stored in keystore which is password protected. The password (or passphrase) you choose should be at least 8 characters long and should conform to common secure password guidelines (e.g. include upper and lower-case letters, numbers, and punctuation symbols). Note that this password is the only thing that protects the private key part of your certificate(s) from being compromised, and thus rendered invalid. Keep this password to yourself, and don't forget it. If you forget this password, or if it is compromised, your certificate(s) will have to be revoked, and you will need to re-apply for them (at considerable inconvenience to both you and the CA/RA). Your given name and family name. You must enter your real name here. Names of roles will be rejected by the CA, for example you cannot use Biochem GRID. Your first name must be a word not just your your initial. Registration Authority. Use UCL EISD. This is the only valid Registration Authority (RA) for UCL. Your e-mail address. Make sure you get this right as it will be used by the e-Science CA to contact you when your certificate is ready. Your PIN. ( Not your bank PIN.) This should be, at minimum, 10 characters long. You will be asked for your PIN by your Registration Authority so it needs to be something you can remember or show. It should not be any of your normal passwords. Using one of these as your PIN (and thus revealing it to both your RA and the e-Science CA) will compromise its use as a password. Extra items for Server Certificates \u00b6 There are two extra items for certificates for servers: Host Name. The fully qualified DNS name (not numeric IP address) of your server. Host Admin Email. To apply for a server certificate you must have a user certificate for yourself and be responsible for the server. After Your Request has been Submitted \u00b6 After you have submitted your request, it has to be authenticated by your Registration Authority (RA) before the certificate is issued by the UK e-Science Certification Authority (CA). For authentication the UK e-Science CA requires that you present yourself in person to your RA with an appropriate form of photo-ID and your PIN. You will be asked to explain why you need a UK e-Science Certificate. The RA for UCL is based in Informations Services Division (ISD). To arrange an appointment please email grid-ra AT ucl.ac.uk in the first instance. Valid forms of Photo-ID are any of the following: Valid UCL ID card (It has to be a complete ID card with photo; authorisation for an ID card is not sufficient.) Current passport UK style photocard driving licence We are required to make and log a photocopy of your photo-ID. If you have none of the above forms of photo-ID available, contact us for advice by e-mail at grid-ra AT ucl.ac.uk. Please don't just turn up with an alternative as we may not be able to accept it. Extra Requirements for Students \u00b6 In addition to the above, students should provide a letter (on department paper) from their project supervisor explaining why they need a certificate. Extra Requirements for Servers \u00b6 In addition to the above, you need to provide a letter from your department explaining that you are responsible for this server. The letter should be on departmental stationary and be signed by your head of department. Obtaining Your Certificate \u00b6 After your request has been authenticated by your Registration Authority, it is forwarded to the UK e-Science Certification Authority for final creation (this stage is called signing the certificate). Signing is normally done on the same or next working day. When your certificate is ready the CA will e-mail you using the e-mail address that you provided with details of how to download your certificate. If you used the recommend method to request it, then you can download it into the Certificate Wizard application using the Refresh button. You should now make a backup of your certificate using the Export button in the Certificate Wizard application.","title":"UCL UK e-Science Certificates"},{"location":"Wiki_Export/done/UCL_UK_e-Science_Certificates/#scope-of-the-ucl-registration-authority","text":"In general, the UCL Registration Authority (RA) can only approve personal and server certificate requests for members of UCL and those associated with projects based at UCL. However we have approved personal certificate requests for members of other London institutions without local RAs on request.","title":"Scope of the UCL Registration Authority"},{"location":"Wiki_Export/done/UCL_UK_e-Science_Certificates/#before-you-apply-for-a-certificate","text":"The recommended method for applying for a certificate is to use the Certificate Wizard. So: Download the CertWizard java application or use WebStart from the Certificate Wizard page on the NES website. Install the application on your computer. Run the Certificate Wizard application.","title":"Before you Apply for a Certificate"},{"location":"Wiki_Export/done/UCL_UK_e-Science_Certificates/#applying-for-a-certificate","text":"You will be asked for a number of items when completing your request including: Certificate Wizard keystore password. Your certificates are stored in keystore which is password protected. The password (or passphrase) you choose should be at least 8 characters long and should conform to common secure password guidelines (e.g. include upper and lower-case letters, numbers, and punctuation symbols). Note that this password is the only thing that protects the private key part of your certificate(s) from being compromised, and thus rendered invalid. Keep this password to yourself, and don't forget it. If you forget this password, or if it is compromised, your certificate(s) will have to be revoked, and you will need to re-apply for them (at considerable inconvenience to both you and the CA/RA). Your given name and family name. You must enter your real name here. Names of roles will be rejected by the CA, for example you cannot use Biochem GRID. Your first name must be a word not just your your initial. Registration Authority. Use UCL EISD. This is the only valid Registration Authority (RA) for UCL. Your e-mail address. Make sure you get this right as it will be used by the e-Science CA to contact you when your certificate is ready. Your PIN. ( Not your bank PIN.) This should be, at minimum, 10 characters long. You will be asked for your PIN by your Registration Authority so it needs to be something you can remember or show. It should not be any of your normal passwords. Using one of these as your PIN (and thus revealing it to both your RA and the e-Science CA) will compromise its use as a password.","title":"Applying for a Certificate"},{"location":"Wiki_Export/done/UCL_UK_e-Science_Certificates/#extra-items-for-server-certificates","text":"There are two extra items for certificates for servers: Host Name. The fully qualified DNS name (not numeric IP address) of your server. Host Admin Email. To apply for a server certificate you must have a user certificate for yourself and be responsible for the server.","title":"Extra items for Server Certificates"},{"location":"Wiki_Export/done/UCL_UK_e-Science_Certificates/#after-your-request-has-been-submitted","text":"After you have submitted your request, it has to be authenticated by your Registration Authority (RA) before the certificate is issued by the UK e-Science Certification Authority (CA). For authentication the UK e-Science CA requires that you present yourself in person to your RA with an appropriate form of photo-ID and your PIN. You will be asked to explain why you need a UK e-Science Certificate. The RA for UCL is based in Informations Services Division (ISD). To arrange an appointment please email grid-ra AT ucl.ac.uk in the first instance. Valid forms of Photo-ID are any of the following: Valid UCL ID card (It has to be a complete ID card with photo; authorisation for an ID card is not sufficient.) Current passport UK style photocard driving licence We are required to make and log a photocopy of your photo-ID. If you have none of the above forms of photo-ID available, contact us for advice by e-mail at grid-ra AT ucl.ac.uk. Please don't just turn up with an alternative as we may not be able to accept it.","title":"After Your Request has been Submitted"},{"location":"Wiki_Export/done/UCL_UK_e-Science_Certificates/#extra-requirements-for-students","text":"In addition to the above, students should provide a letter (on department paper) from their project supervisor explaining why they need a certificate.","title":"Extra Requirements for Students"},{"location":"Wiki_Export/done/UCL_UK_e-Science_Certificates/#extra-requirements-for-servers","text":"In addition to the above, you need to provide a letter from your department explaining that you are responsible for this server. The letter should be on departmental stationary and be signed by your head of department.","title":"Extra Requirements for Servers"},{"location":"Wiki_Export/done/UCL_UK_e-Science_Certificates/#obtaining-your-certificate","text":"After your request has been authenticated by your Registration Authority, it is forwarded to the UK e-Science Certification Authority for final creation (this stage is called signing the certificate). Signing is normally done on the same or next working day. When your certificate is ready the CA will e-mail you using the e-mail address that you provided with details of how to download your certificate. If you used the recommend method to request it, then you can download it into the Certificate Wizard application using the Refresh button. You should now make a backup of your certificate using the Export button in the Certificate Wizard application.","title":"Obtaining Your Certificate"},{"location":"Wiki_Export/done/User_Scripts/","text":"These are tools developed by either the Research Computing group or users of the services, which may be useful to others. If you have a tool which you think might be useful to others, please feel free to send it to rc-support@ucl.ac.uk . If we think it's appropriate, we'll give it a look over and possibly some polish, and add it to the list. These tools tend to be created for Legion in the first instance, so they may not all be appropriate on other systems. These are located in: /shared/ucl/apps/userscripts or can be used by loading the userscripts module: module load userscripts You should be able to obtain more information about these scripts by typing the name of the script followed by --help , for example: qexplain --help Script Description qexplain Prints the full error associated with a job in an error state. jobhist Shows recently finished jobs, along with when they finished and, optionally, other information about them. Displays the last 24 hours by default. nodesforjob Shows all the nodes that a currently-running job is running on, along with information on load, memory and swap being used. nodetypes Show a list of currently-available node types, including the number of cores and amount of RAM they have. (Nodes that are down will not be counted, so the numbers will fluctuate). to-grace, to-legion Copy files from Legion to Grace or vice versa. Uses login05 as the destination if copying to Legion. It will tar up the file/directory you give it, copy it to your home on the other machine and untar it again.","title":"User Scripts"},{"location":"Wiki_Export/done/X11_Forwarding_With_Windows/","text":"X forwarding allows users to interact via a GUI with a graphical program running on a remote computer. To get this to work on Windows machines with Legion you will need: An SSH client; e.g., PuTTY An X server program; e.g., Exceed Other SSH clients and X servers are available, but the following instructions will tell you how to set up X forwarding for Legion using PuTTY and Exceed: Install both programs if you have not done so already. For Exceed you want a personal installation. Open Exceed - the exceed icon should appear on the task bar. Open PuTTY In PuTTY, set up the connection with Legion as usual with the following information: Host name: legion.rc.ucl.ac.uk Port: 22 Connection type: SSH Then, from the Category menu, select Connection>SSH>X11 for 'Options controlling SSH X11 forwarding' Make sure the box marked 'Enable X11 forwarding' is checked. Return to the session menu and save these setting with a new name such as 'Legion X' for reuse in future. Click 'Open' and login to Legion as usual To test that X-forwarding is working try one of these test applications: xeyes: to bring up a set of eyes that track the mouse position on the screen glxgears: to bring up an animated set of gears xclock: a clock If these work, you have succesfully enabled X forwarding for graphical applications on Legion.","title":"X11 Forwarding With Windows"},{"location":"Wiki_Export/needs_work/Resource_Allocation/","text":"For information about requesting additional resources see Additional Resource Requests . Governance \u00b6 Resource allocation policy for Research Computing services is determined by the CRAG , informed by the user community. The CRAG reports to the Research Computing Governance Group . Resource Allocation on Legion \u00b6 Allocation of computational resources on the Legion cluster is based on a combination of job class, wait time and fairshare. Resource allocation is based on four features of job: Memory size Core count Licenses Wall clock time Legion has nodes of several different types, listed below. The tmpfs is the maximum size of $TMPDIR that can be requested. Type Cores per node RAM per node Connectivity Nodes Total Cores tmpfs T 32 1511GB Ethernet 6 192 1536G U 16 64GB Infiniband 160 2560 792G V 12 + 2 GPU 48GB Ethernet 8 96 + 16GPU 358G X 12 24GB Infiniband 144 1728 173G Y 12 24GB Ethernet 99 1188 406G Z 12 48GB Ethernet 4 48 173G S 16 + 2 MIC 64GB Infiniband 10 160 + 20 MIC 1536G O 16 64GB Infiniband 36 576 792G P 12 + 1 K40c GPU 8GB Ethernet 1 12 + 1 K40c GPU 112G Q 32 512GB Ethernet 1 32 1024G Nodes of type W are the original nodes (now retired), whilst X, Y and Z are the new nodes added during the Legion III upgrade. Nodes of type X are for running parallel jobs, nodes of type Y are used for running jobs which can be run within one node (less than 12 cores) and nodes of type Z are used for jobs which require more memory. Types T, U and V were added later. Type T are for jobs with a high memory requirement. Type V are only for jobs which request a GPU. Type S are only for jobs which request a mic. The largest job that the general population of users can run on nodes of types U, S, O and Q will vary as they are mostly paid for by specific research groups. When a job is submitted it is evaluated and automatically assigned to one of several classes, based on information in the job submission script: In addition, as before, scheduling is based on the job type of the job. There are three job types: Multi-node jobs: These jobs require more than one node of the type they have been assigned to. Short, single-node jobs: These have a wall-clock time less than or equal to X minutes and fit within a single node of the type they have been assigned to. Long, single-node jobs: These have a wall-clock time greater than X and fit within a single node of the type they have been assigned to. X is under constant evaluation: Assumptions should not be made as to the value of X at any given time. Assignment rules \u00b6 The policy defined by the CRAG for scheduling jobs is based on the eight rules below: Resource requests that cannot be satisfied will cause the job to be rejected at submit time. The number of nodes a job will use will be determined independently for each node class. When this is combined with run time requirements, may cause the jobs to not be eligible to run on a particular node class. Single node jobs will share the node they run on with other single node jobs to the limit of available resources. Long Single Node jobs are banned from node classes X and U. Multi node jobs are banned from node classes Y and Z. Only jobs that request a GPU can use nodes of type V. Only jobs that request a MIC can use nodes of type S. Nodes of type T have a scheduling policy like Y/Z for jobs that use > 64GB RAM. Other jobs are limited to 1hr. (Eg smp jobs of 32 cores need to request > 2G per core). Jobs requiring Licenses will run on those nodes where they consume the fewest licenses. Users can specify which node classes their jobs will run on, provided that they do not contradict the policy set above. Any other resource matching will be done automatically by the scheduler to soonest available resource. Wallclock times \u00b6 Specific information related to wall-clock times and where jobs will run is summarised in the table below. Wall clock time X Y Z T U V S \\<=15 mins \\<=1 node \\<=1 node \\<=1 node \\<=1 node \\<=1 node* \\<=1 node* \\<=10 nodes* \\<=12 hours 2-72 nodes \\<=1 node \\<=1 node \\<=1 node* \\<=1-36 nodes* \\<=1 node* \\<=10 nodes* \\<=1 day 2-42 nodes \\<=1 node \\<=1 node \\<=1 node* 2-25 nodes* \\<=1 node* \\<=1 node* \\<=2 days 2-21 nodes \\<=1 node \\<=1 node \\<=1 node* 2-16 nodes* \\<=1 node* \\<=1 node* \\<=3 days 0 1 core 1 core 1 core* 0* 1 core* 0 * marks combinations that have other restrictions as described in the rules above. The priority of jobs is set as follows: \\<=15 min and \\<=1 node and eligible for X are set the lowest priority because it is expected that these jobs will obtain resources via backfill. All other jobs have priority set inversely proportional to the wall-clock time. With the exception of the jobs in point 1, there is no relationship between priority and job size. Fair-share and wait times are weighted in the priority calculation. In addition to the priority assigned based on job classes, jobs will also derive priority from fair share; jobs that have been waiting a long time, or have been submitted by a user and/or project that has not otherwise consumed many resources recently, will also acquire a higher priority. Note that despite these priority assignments it may take longer to assign resources for large jobs than for small ones. However, the higher priority assigned to large jobs should prevent smaller jobs from delaying them. Jobs that request 64 nodes or a little less may be delayed by the requirement to run within a computational unit. Estimating resources needed by your job \u00b6 It can be difficult to know where to start when estimating the resources your job will need. One way you can find out what resources your jobs need is to submit one job which requests far more than you think necessary, and gather data on what it actually uses. If you aren't sure what 'far more' entails, request the maximum wallclock time and job size that will fit on one node, and reduce this after you have some idea. Run your program as: ``` /usr/bin/time --verbose myprogram myargs `` where myprogram myargs` is however you normally run your program, with whatever options you pass to it. When your job finishes, you will get output about the resources it used and how long it took - the relevant one for memory is maxrss (maximum resident set size) which roughly tells you the largest amount of memory it used. Remember that memory requests in your jobscript are always per core, so check the total you are requesting is sensible - if you increase it too much you may end up with a job that cannot be submitted. You can also look at nodesforjob $jobID when a job is running to see a snapshot of the memory, swap and load on the nodes your job is running on. (But if your job is sharing nodes it will show you the total resources in use, not just those used by your job). Bear in mind that memory use can increase over time as your job runs. Memory requests must be integers \u00b6 SoGE's memory specifiers are integers followed by a multiplier letter. Valid multiplier letters are k, K, m, M, g, G, t, and T, where k means multiply the value by 1000, K multiply by 1024, m multiply by 1000\u00d71000, M multiply by 1024\u00d71024, g multiply by 1000\u00d71000\u00d71000, G multiply by 1024\u00d71024\u00d71024, t multiply by 1000\u00d71000\u00d71000\u00d71000, and T multiply by 1024\u00d71024\u00d71024\u00d71024. If no multiplier is present, the value is just counted in bytes. These are valid: #$ -l mem=2500M #$ -l mem=1G #$ -l mem=1T but you cannot ask for 1.5G. Resource Allocation on Grace \u00b6 Grace is intended for parallel multi-node jobs requesting a minimum of 32 cores. All nodes on Grace have 16 cores and 64G RAM. The maximum tmpfs that can be requested is 100G. Jobs of less than 32 cores \u00b6 Jobs of less than 32 cores will only run on two of the compute nodes and the maximum wallclock for those is 12hrs, intended for testing purposes. If people submit many jobs of that size, the queue for those two nodes will be long. These workloads should be run on Legion. Wallclock times \u00b6 Cores Max wallclock 32-256 48hrs 257-512 24hrs 513-10912 12hrs You may have a very long queue time if you try to use the maximum job size... Priority access requests \u00b6 Requests to run jobs outside the above limits should be addressed to rc-support@ucl.ac.uk for review (see Priority Access ). A clear justification for the request must be included; where requests are made to run jobs for longer than 3 days, it is expected: the code to be run has been optimised for Legion or Grace the code to be run cannot do checkpoint/restart without major modifications.","title":"Resource Allocation"},{"location":"Wiki_Export/needs_work/Resource_Allocation/#governance","text":"Resource allocation policy for Research Computing services is determined by the CRAG , informed by the user community. The CRAG reports to the Research Computing Governance Group .","title":"Governance"},{"location":"Wiki_Export/needs_work/Resource_Allocation/#resource-allocation-on-legion","text":"Allocation of computational resources on the Legion cluster is based on a combination of job class, wait time and fairshare. Resource allocation is based on four features of job: Memory size Core count Licenses Wall clock time Legion has nodes of several different types, listed below. The tmpfs is the maximum size of $TMPDIR that can be requested. Type Cores per node RAM per node Connectivity Nodes Total Cores tmpfs T 32 1511GB Ethernet 6 192 1536G U 16 64GB Infiniband 160 2560 792G V 12 + 2 GPU 48GB Ethernet 8 96 + 16GPU 358G X 12 24GB Infiniband 144 1728 173G Y 12 24GB Ethernet 99 1188 406G Z 12 48GB Ethernet 4 48 173G S 16 + 2 MIC 64GB Infiniband 10 160 + 20 MIC 1536G O 16 64GB Infiniband 36 576 792G P 12 + 1 K40c GPU 8GB Ethernet 1 12 + 1 K40c GPU 112G Q 32 512GB Ethernet 1 32 1024G Nodes of type W are the original nodes (now retired), whilst X, Y and Z are the new nodes added during the Legion III upgrade. Nodes of type X are for running parallel jobs, nodes of type Y are used for running jobs which can be run within one node (less than 12 cores) and nodes of type Z are used for jobs which require more memory. Types T, U and V were added later. Type T are for jobs with a high memory requirement. Type V are only for jobs which request a GPU. Type S are only for jobs which request a mic. The largest job that the general population of users can run on nodes of types U, S, O and Q will vary as they are mostly paid for by specific research groups. When a job is submitted it is evaluated and automatically assigned to one of several classes, based on information in the job submission script: In addition, as before, scheduling is based on the job type of the job. There are three job types: Multi-node jobs: These jobs require more than one node of the type they have been assigned to. Short, single-node jobs: These have a wall-clock time less than or equal to X minutes and fit within a single node of the type they have been assigned to. Long, single-node jobs: These have a wall-clock time greater than X and fit within a single node of the type they have been assigned to. X is under constant evaluation: Assumptions should not be made as to the value of X at any given time.","title":"Resource Allocation on Legion"},{"location":"Wiki_Export/needs_work/Resource_Allocation/#assignment-rules","text":"The policy defined by the CRAG for scheduling jobs is based on the eight rules below: Resource requests that cannot be satisfied will cause the job to be rejected at submit time. The number of nodes a job will use will be determined independently for each node class. When this is combined with run time requirements, may cause the jobs to not be eligible to run on a particular node class. Single node jobs will share the node they run on with other single node jobs to the limit of available resources. Long Single Node jobs are banned from node classes X and U. Multi node jobs are banned from node classes Y and Z. Only jobs that request a GPU can use nodes of type V. Only jobs that request a MIC can use nodes of type S. Nodes of type T have a scheduling policy like Y/Z for jobs that use > 64GB RAM. Other jobs are limited to 1hr. (Eg smp jobs of 32 cores need to request > 2G per core). Jobs requiring Licenses will run on those nodes where they consume the fewest licenses. Users can specify which node classes their jobs will run on, provided that they do not contradict the policy set above. Any other resource matching will be done automatically by the scheduler to soonest available resource.","title":"Assignment rules"},{"location":"Wiki_Export/needs_work/Resource_Allocation/#wallclock-times","text":"Specific information related to wall-clock times and where jobs will run is summarised in the table below. Wall clock time X Y Z T U V S \\<=15 mins \\<=1 node \\<=1 node \\<=1 node \\<=1 node \\<=1 node* \\<=1 node* \\<=10 nodes* \\<=12 hours 2-72 nodes \\<=1 node \\<=1 node \\<=1 node* \\<=1-36 nodes* \\<=1 node* \\<=10 nodes* \\<=1 day 2-42 nodes \\<=1 node \\<=1 node \\<=1 node* 2-25 nodes* \\<=1 node* \\<=1 node* \\<=2 days 2-21 nodes \\<=1 node \\<=1 node \\<=1 node* 2-16 nodes* \\<=1 node* \\<=1 node* \\<=3 days 0 1 core 1 core 1 core* 0* 1 core* 0 * marks combinations that have other restrictions as described in the rules above. The priority of jobs is set as follows: \\<=15 min and \\<=1 node and eligible for X are set the lowest priority because it is expected that these jobs will obtain resources via backfill. All other jobs have priority set inversely proportional to the wall-clock time. With the exception of the jobs in point 1, there is no relationship between priority and job size. Fair-share and wait times are weighted in the priority calculation. In addition to the priority assigned based on job classes, jobs will also derive priority from fair share; jobs that have been waiting a long time, or have been submitted by a user and/or project that has not otherwise consumed many resources recently, will also acquire a higher priority. Note that despite these priority assignments it may take longer to assign resources for large jobs than for small ones. However, the higher priority assigned to large jobs should prevent smaller jobs from delaying them. Jobs that request 64 nodes or a little less may be delayed by the requirement to run within a computational unit.","title":"Wallclock times"},{"location":"Wiki_Export/needs_work/Resource_Allocation/#estimating-resources-needed-by-your-job","text":"It can be difficult to know where to start when estimating the resources your job will need. One way you can find out what resources your jobs need is to submit one job which requests far more than you think necessary, and gather data on what it actually uses. If you aren't sure what 'far more' entails, request the maximum wallclock time and job size that will fit on one node, and reduce this after you have some idea. Run your program as: ``` /usr/bin/time --verbose myprogram myargs `` where myprogram myargs` is however you normally run your program, with whatever options you pass to it. When your job finishes, you will get output about the resources it used and how long it took - the relevant one for memory is maxrss (maximum resident set size) which roughly tells you the largest amount of memory it used. Remember that memory requests in your jobscript are always per core, so check the total you are requesting is sensible - if you increase it too much you may end up with a job that cannot be submitted. You can also look at nodesforjob $jobID when a job is running to see a snapshot of the memory, swap and load on the nodes your job is running on. (But if your job is sharing nodes it will show you the total resources in use, not just those used by your job). Bear in mind that memory use can increase over time as your job runs.","title":"Estimating resources needed by your job"},{"location":"Wiki_Export/needs_work/Resource_Allocation/#memory-requests-must-be-integers","text":"SoGE's memory specifiers are integers followed by a multiplier letter. Valid multiplier letters are k, K, m, M, g, G, t, and T, where k means multiply the value by 1000, K multiply by 1024, m multiply by 1000\u00d71000, M multiply by 1024\u00d71024, g multiply by 1000\u00d71000\u00d71000, G multiply by 1024\u00d71024\u00d71024, t multiply by 1000\u00d71000\u00d71000\u00d71000, and T multiply by 1024\u00d71024\u00d71024\u00d71024. If no multiplier is present, the value is just counted in bytes. These are valid: #$ -l mem=2500M #$ -l mem=1G #$ -l mem=1T but you cannot ask for 1.5G.","title":"Memory requests must be integers"},{"location":"Wiki_Export/needs_work/Resource_Allocation/#resource-allocation-on-grace","text":"Grace is intended for parallel multi-node jobs requesting a minimum of 32 cores. All nodes on Grace have 16 cores and 64G RAM. The maximum tmpfs that can be requested is 100G.","title":"Resource Allocation on Grace"},{"location":"Wiki_Export/needs_work/Resource_Allocation/#jobs-of-less-than-32-cores","text":"Jobs of less than 32 cores will only run on two of the compute nodes and the maximum wallclock for those is 12hrs, intended for testing purposes. If people submit many jobs of that size, the queue for those two nodes will be long. These workloads should be run on Legion.","title":"Jobs of less than 32 cores"},{"location":"Wiki_Export/needs_work/Resource_Allocation/#wallclock-times_1","text":"Cores Max wallclock 32-256 48hrs 257-512 24hrs 513-10912 12hrs You may have a very long queue time if you try to use the maximum job size...","title":"Wallclock times"},{"location":"Wiki_Export/needs_work/Resource_Allocation/#priority-access-requests","text":"Requests to run jobs outside the above limits should be addressed to rc-support@ucl.ac.uk for review (see Priority Access ). A clear justification for the request must be included; where requests are made to run jobs for longer than 3 days, it is expected: the code to be run has been optimised for Legion or Grace the code to be run cannot do checkpoint/restart without major modifications.","title":"Priority access requests"},{"location":"Wiki_Export/needs_work/Running_Hybrid_OpenMP__MPI_Code/","text":"If you wish to submit a job that combines MPI and OpenMP parallelisation then you have a number of challenges you need to think about. First of all, you may need to use an MPI library that is thread-safe -- that does not keep MPI state in shared memory between processor threads. Support for this in OpenMPI is still in development, and Intel MPI (the default on our systems) is recommended for this instead. This guide will give you are short walk-through of the process of writing, building and running a simple hybrid code on Legion. Set up modules \u00b6 The default modules are correct - in case you have others loaded, these are what you need: module unload compilers mpi module load compilers/intel/2015/update2 module load mpi/intel/2015/update3/intel You can check the MPI you have loaded by running mpif90 -v You should see something similar to the output below: mpif90 for the Intel(R) MPI Library 5.0 Update 3 for Linux* Copyright(C) 2003-2015, Intel Corporation. All rights reserved. ifort version 15.0.2 Compile the code \u00b6 To compile the code, you need to use the mpif90 compiler wrapper (or the C equivalent for your own C code) and pass it the -openmp option to enable the processing of OpenMP directives. Run: mpif90 -o hybrid -openmp hybrid.f90 This should produce a binary called \"hybrid\" in your current working directory. Submit the Job \u00b6 You will need to request the total number of cores you wish to use, and either set $OMP_NUM_THREADS for the number of OpenMP threads yourself, or allow it to be worked out automatically by setting it to OMP_NUM_THREADS=$(ppn) . That will set $OMP_NUM_THREADS to $NSLOTS/$NHOSTS , so you can use threads within a node and MPI between nodes and don't need to know in advance what size of node you are running on. GERun will then run $NSLOTS/$OMP_NUM_THREADS processes, round-robin allocated (if supported by the MPI). Therefore, if you want to use 24 cores on the type X nodes, with one MPI process per node and 12 threads per process you would request the example below. Note that if you are using multiple nodes and ppn , you get exclusive access to those nodes, so if you ask for 2.5 nodes-worth of cores you will end up with more threads on the last node than you thought you had. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #!/bin/bash -l # Batch script to run a hybrid parallel job under SGE with Intel MPI. #$ -S /bin/bash # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space per node (default is 10 GB) #$ -l tmpfs=15G # Set the name of the job. #$ -N MadIntelHybrid # Select the MPI parallel environment and 24 cores. #$ -pe mpi 24 # Set the working directory to somewhere in your scratch space. #$ -wd /home/<your_UCL_id/scratch/output/ # Automatically set threads to processes per node: if on X nodes = 12 OMP threads export OMP_NUM_THREADS=$(ppn) # Run our MPI job with the default modules. Gerun is a wrapper script for mpirun. gerun $HOME/src/madscience/madhybrid If you want to specify a specific number of OMP threads, you would alter the relevant lines above to this: # Run 12 MPI processes, each spawning 2 threads #$ -pe mpi 24 export OMP_NUM_THREADS=2 gerun your_binary","title":"Running Hybrid OpenMP/MPI Code"},{"location":"Wiki_Export/needs_work/Running_Hybrid_OpenMP__MPI_Code/#set-up-modules","text":"The default modules are correct - in case you have others loaded, these are what you need: module unload compilers mpi module load compilers/intel/2015/update2 module load mpi/intel/2015/update3/intel You can check the MPI you have loaded by running mpif90 -v You should see something similar to the output below: mpif90 for the Intel(R) MPI Library 5.0 Update 3 for Linux* Copyright(C) 2003-2015, Intel Corporation. All rights reserved. ifort version 15.0.2","title":"Set up modules"},{"location":"Wiki_Export/needs_work/Running_Hybrid_OpenMP__MPI_Code/#compile-the-code","text":"To compile the code, you need to use the mpif90 compiler wrapper (or the C equivalent for your own C code) and pass it the -openmp option to enable the processing of OpenMP directives. Run: mpif90 -o hybrid -openmp hybrid.f90 This should produce a binary called \"hybrid\" in your current working directory.","title":"Compile the code"},{"location":"Wiki_Export/needs_work/Running_Hybrid_OpenMP__MPI_Code/#submit-the-job","text":"You will need to request the total number of cores you wish to use, and either set $OMP_NUM_THREADS for the number of OpenMP threads yourself, or allow it to be worked out automatically by setting it to OMP_NUM_THREADS=$(ppn) . That will set $OMP_NUM_THREADS to $NSLOTS/$NHOSTS , so you can use threads within a node and MPI between nodes and don't need to know in advance what size of node you are running on. GERun will then run $NSLOTS/$OMP_NUM_THREADS processes, round-robin allocated (if supported by the MPI). Therefore, if you want to use 24 cores on the type X nodes, with one MPI process per node and 12 threads per process you would request the example below. Note that if you are using multiple nodes and ppn , you get exclusive access to those nodes, so if you ask for 2.5 nodes-worth of cores you will end up with more threads on the last node than you thought you had. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #!/bin/bash -l # Batch script to run a hybrid parallel job under SGE with Intel MPI. #$ -S /bin/bash # Request ten minutes of wallclock time (format hours:minutes:seconds). #$ -l h_rt=0:10:0 # Request 1 gigabyte of RAM (must be an integer) #$ -l mem=1G # Request 15 gigabyte of TMPDIR space per node (default is 10 GB) #$ -l tmpfs=15G # Set the name of the job. #$ -N MadIntelHybrid # Select the MPI parallel environment and 24 cores. #$ -pe mpi 24 # Set the working directory to somewhere in your scratch space. #$ -wd /home/<your_UCL_id/scratch/output/ # Automatically set threads to processes per node: if on X nodes = 12 OMP threads export OMP_NUM_THREADS=$(ppn) # Run our MPI job with the default modules. Gerun is a wrapper script for mpirun. gerun $HOME/src/madscience/madhybrid If you want to specify a specific number of OMP threads, you would alter the relevant lines above to this: # Run 12 MPI processes, each spawning 2 threads #$ -pe mpi 24 export OMP_NUM_THREADS=2 gerun your_binary","title":"Submit the Job"},{"location":"Wiki_Export/needs_work/Summary_of_Legion_changes/","text":"Host key warning \u00b6 The host keys for these login nodes and for legion.rc.ucl.ac.uk have changed, so when you try to log in you may get a warning from ssh saying that this has happened. You will need to remove the old keys from the known hosts list. Remove old host keys \u00b6 On Linux you can remove the old keys with: `ssh-keygen -R login09.external.legion.ucl.ac.uk` `ssh-keygen -R 193.60.225.59` `ssh-keygen -R login08.external.legion.ucl.ac.uk` `ssh-keygen -R 193.60.225.58` `ssh-keygen -R login07.external.legion.ucl.ac.uk` `ssh-keygen -R 193.60.225.57` `ssh-keygen -R login06.external.legion.ucl.ac.uk` `ssh-keygen -R 193.60.225.56` `ssh-keygen -R legion.rc.ucl.ac.uk` On Socrates you will probably need to edit your ~/.ssh/known_hosts file manually and delete the line for legion. (pico and vi are available text editors on Socrates). Using WinSCP the warning will look like this, and you will have the option to update the key. ``` 'Server's host key does not match the one that WinSCP has in cache.' # Modules There are some fairly significant changes to the modules available and of course newer versions of packages than were available under the old system. To see all the modules: module avail If you have the Legion default modules loaded in your .bashrc, then you should have the new default modules loaded automatically. module list Currently Loaded Modulefiles: 1) gcc-libs/4.9.2 7) subversion/1.8.13 13) rcps-core/1.0.0 2) cmake/3.2.1 8) screen/4.2.1 14) compilers/intel/2015/update2 3) flex/2.5.39 9) gerun 15) mpi/intel/2015/update3/intel 4) git/2.3.5 10) nano/2.4.2 16) default-modules 5) apr/1.5.2 11) nedit/5.6-aug15 6) apr-util/1.5.4 12) dos2unix/7.3 If you have \u201cmodule load\u201d commands in your .bashrc, you'll have to update them to reflect the changes to the module names/versions, otherwise you will see error messages. You can check our progress in installing all applications on the github repository for the module files here: <https://github.com/UCL-RITS/rcps-modulefiles> And the scripts that build the packages here: <https://github.com/UCL-RITS/rcps-buildscripts> # Jobscript differences ## Parallel environments for shared memory threads or MPI The way you request threads has changed: instead of using `#$ -l thr=4`, you would put this in your jobscript: # Request 4 threads #$ -pe smp 4 If you are using MPI, then there is only one parallel environment: # Request 4 MPI processes #$ -pe mpi 4 (`-pe mpi` is an alias for `-pe qlc` so you can use either and they are equivalent). ## RAM requested by shared memory jobs As a result of the change above, threaded jobs now also request RAM per core like MPI jobs do, rather than requesting the total amount. For example, asking for 4 threads and 12G RAM will give you a total of 48G RAM and not 12G as it was before. Check your memory requirements as you will greatly reduce the places your jobs can run if you leave them too high. ## Mixed-mode OpenMP and MPI This has changed significantly. You will now request the total number of cores you wish to use, and either set OMP\\_NUM\\_THREADS yourself, or allow it to be worked out automatically. # Run 12 MPI processes, each spawning 2 threads #$ -pe qlc 24 export OMP_NUM_THREADS=2 gerun your_binary The below will automatically set OMP\\_NUM\\_THREADS to $NSLOTS/$NHOSTS, so you will use threads within a node and MPI between nodes and don't need to know in advance what size of node you are running on. Gerun will then run $NSLOTS/$OMP\\_NUM\\_THREADS processes, round-robin allocated (if supported by the MPI). #$ -pe qlc 24 export OMP_NUM_THREADS=$(ppn) gerun your_binary ``` For example, if that runs on 2 x 12-core nodes, you'll get 2 MPI processes, each using 12 threads. Python \u00b6 There are python2/recommended and python3/recommended bundles. These use a virtualenv and have pip set up for you. They both have numpy and scipy available. See also Compiling#Python for how to install your own packages. To see what is already installed, the Python-shared list shows what is installed for both Python2 and 3, while the Python2 list and Python3 list show what is only installed for one or the other. (There may also be prereqs that aren't listed explicitly - pip will tell you if something is already installed as long as you have the bundle loaded).","title":"Summary of Legion changes"},{"location":"Wiki_Export/needs_work/Summary_of_Legion_changes/#host-key-warning","text":"The host keys for these login nodes and for legion.rc.ucl.ac.uk have changed, so when you try to log in you may get a warning from ssh saying that this has happened. You will need to remove the old keys from the known hosts list.","title":"Host key warning"},{"location":"Wiki_Export/needs_work/Summary_of_Legion_changes/#remove-old-host-keys","text":"On Linux you can remove the old keys with: `ssh-keygen -R login09.external.legion.ucl.ac.uk` `ssh-keygen -R 193.60.225.59` `ssh-keygen -R login08.external.legion.ucl.ac.uk` `ssh-keygen -R 193.60.225.58` `ssh-keygen -R login07.external.legion.ucl.ac.uk` `ssh-keygen -R 193.60.225.57` `ssh-keygen -R login06.external.legion.ucl.ac.uk` `ssh-keygen -R 193.60.225.56` `ssh-keygen -R legion.rc.ucl.ac.uk` On Socrates you will probably need to edit your ~/.ssh/known_hosts file manually and delete the line for legion. (pico and vi are available text editors on Socrates). Using WinSCP the warning will look like this, and you will have the option to update the key. ``` 'Server's host key does not match the one that WinSCP has in cache.' # Modules There are some fairly significant changes to the modules available and of course newer versions of packages than were available under the old system. To see all the modules: module avail If you have the Legion default modules loaded in your .bashrc, then you should have the new default modules loaded automatically. module list Currently Loaded Modulefiles: 1) gcc-libs/4.9.2 7) subversion/1.8.13 13) rcps-core/1.0.0 2) cmake/3.2.1 8) screen/4.2.1 14) compilers/intel/2015/update2 3) flex/2.5.39 9) gerun 15) mpi/intel/2015/update3/intel 4) git/2.3.5 10) nano/2.4.2 16) default-modules 5) apr/1.5.2 11) nedit/5.6-aug15 6) apr-util/1.5.4 12) dos2unix/7.3 If you have \u201cmodule load\u201d commands in your .bashrc, you'll have to update them to reflect the changes to the module names/versions, otherwise you will see error messages. You can check our progress in installing all applications on the github repository for the module files here: <https://github.com/UCL-RITS/rcps-modulefiles> And the scripts that build the packages here: <https://github.com/UCL-RITS/rcps-buildscripts> # Jobscript differences ## Parallel environments for shared memory threads or MPI The way you request threads has changed: instead of using `#$ -l thr=4`, you would put this in your jobscript: # Request 4 threads #$ -pe smp 4 If you are using MPI, then there is only one parallel environment: # Request 4 MPI processes #$ -pe mpi 4 (`-pe mpi` is an alias for `-pe qlc` so you can use either and they are equivalent). ## RAM requested by shared memory jobs As a result of the change above, threaded jobs now also request RAM per core like MPI jobs do, rather than requesting the total amount. For example, asking for 4 threads and 12G RAM will give you a total of 48G RAM and not 12G as it was before. Check your memory requirements as you will greatly reduce the places your jobs can run if you leave them too high. ## Mixed-mode OpenMP and MPI This has changed significantly. You will now request the total number of cores you wish to use, and either set OMP\\_NUM\\_THREADS yourself, or allow it to be worked out automatically. # Run 12 MPI processes, each spawning 2 threads #$ -pe qlc 24 export OMP_NUM_THREADS=2 gerun your_binary The below will automatically set OMP\\_NUM\\_THREADS to $NSLOTS/$NHOSTS, so you will use threads within a node and MPI between nodes and don't need to know in advance what size of node you are running on. Gerun will then run $NSLOTS/$OMP\\_NUM\\_THREADS processes, round-robin allocated (if supported by the MPI). #$ -pe qlc 24 export OMP_NUM_THREADS=$(ppn) gerun your_binary ``` For example, if that runs on 2 x 12-core nodes, you'll get 2 MPI processes, each using 12 threads.","title":"Remove old host keys"},{"location":"Wiki_Export/needs_work/Summary_of_Legion_changes/#python","text":"There are python2/recommended and python3/recommended bundles. These use a virtualenv and have pip set up for you. They both have numpy and scipy available. See also Compiling#Python for how to install your own packages. To see what is already installed, the Python-shared list shows what is installed for both Python2 and 3, while the Python2 list and Python3 list show what is only installed for one or the other. (There may also be prereqs that aren't listed explicitly - pip will tell you if something is already installed as long as you have the bundle loaded).","title":"Python"}]}