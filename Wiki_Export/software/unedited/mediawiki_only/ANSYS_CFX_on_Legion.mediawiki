---
title: ANSYS/CFX, ANSYS/Fluent and AnsysEM
categories:
 - Applications
 - Pages with bash scripts
 - Software

layout: application
---
{{Applications
|name=ANSYS/CFX, ANSYS/Fluent and AnsysEM
|platform=Legion
|short=ANSYS/CFX and ANSYS/Fluent are commercial fluid dynamics packages.
|about=ANSYS/CFX and ANSYS/Fluent are commercial fluid dynamics packages.
|version=17.2, 18.0, 19.1
|moduleload1=ansys/19.1
|setup-notes=ANSYS/CFX and ANSYS/Fluent version 17.2, 18.0 and 19.1 are available on Legion,  Grace and Myriad. The ANSYS Electromagnetics Suite (AnsysEM) version 19.1 is also available.

ANSYS/CFX, ANSYS/Fluent and AnsysEM are intended to be run primarily within batch jobs however you may run short (less than 5 minutes execution time) interactive tests on the Login Nodes and longer (up to two hours) on the User Test Nodes. Interactive work can be done using the ANSYS interactive tools provided you have X-windows functionality enabled though your ssh connection. See our [https://wiki.rc.ucl.ac.uk/wiki/Category:Legion_User_Guide RC Systems User Guide] for more information about enabling X-windows functionality and the User Test nodes.

UCL's campus-wide license covers 125 instances with 512 HPC licenses (for parallel jobs) available for running CFX, Fluent and AnsysEM jobs and in order to make sure that jobs only run if there are licenses available, it is necessary for users to request ANSYS licenses with their jobs, by adding "-ac app=cfx" to their job submission.

In addition, because CFX handles its own parallelisation, a number of options need to be passed in job scripts to make it run correctly. 
|scripts=
{{Script
|script-title=Single node run
|script-code=
<nowiki>
#!/bin/bash -l

# ANSYS 19.1: Batch script to run cfx5solve on the StaticMixer.def example 
# file, single node multi-threaded (12 threads),

# 1. Force bash as the executing shell.

#$ -S /bin/bash

# 2. Request 15 munutes of wallclock time (format hours:minutes:seconds).
#$ -l h_rt=0:15:0

# 3. Request 1 gigabyte of RAM per core.
#$ -l mem=1G

# 4. Set the name of the job.
#$ -N StaticMixer_thread_12

# 5. Select 12 threads.
#$ -pe smp 12

# 6. Request ANSYS licences 
#$ -ac app=cfx

# 7. Set the working directory to somewhere in your scratch space. In this
# case the subdirectory cfxtests-19.1
#$ -wd /home/<your userid>/Scratch/cfxtests-19.1

# 8. Load the ANSYS module to set up your environment

module load ansys/19.1

# 9. Copy the .def file into the working (current) directory

cp /home/<your userid>/cfx_examples/StaticMixer.def .

# 10. Run cfx5solve - Note: -max-elapsed-time needs to be set to the same
# time as defined by 2 above.

cfx5solve -max-elapsed-time "15 [min]" -def StaticMixer.def -par-local -partition $OMP_NUM_THREADS
</nowiki>
|script-path=
|script-notes=
You will need to change the '-wd /home/<your_UCL_id>/Scratch/cfxtests-19.1'' SGE directive and may need to change the memory, wallclock time, number of threads and job name directives as well. Replace the ''.def'' file in 9 and 10 by your one and modify the ''-max-elapsed-time'' value if needed. The simplest form of qsub command can be used to submit the job eg:
<code>
 qsub run-StaticMixer-thr.sh
</code>
Output files will be saved in the job's working directory.

[[#top | Back to top]]
}}
{{Script
|script-title=Multi node run
|script-code=
<nowiki>
#!/bin/bash -l

# ANSYS 19.1: Batch script to run cfx5solve on the StaticMixer.def example 
# file, distributed parallel (32 cores).

# Using ANSYS 19 licence manager running on UCL central licence server.

# 1. Force bash as the executing shell.
#$ -S /bin/bash

# 2. Request one hour of wallclock time (format hours:minutes:seconds).
#$ -l h_rt=1:00:0

# 3. Request 2 gigabyte of RAM per core.
#$ -l mem=2G

# 4. Set the name of the job.
#$ -N StaticMixer_P_dist_32

# 5. Select the MPI parallel environment and 32 processors.
#$ -pe mpi 32

# 6. Request ANSYS licences 
#$ -ac app=cfx

# 7. Set the working directory to somewhere in your scratch space.  In this
# case the subdirectory cfxtests-19.1
#$ -wd /home/<your userid>/Scratch/cfxtests-19.1

# 8. Load the ANSYS module to set up your environment

module load ansys/19.1

# 9. Copy the .def file into the working (current) directory

cp /home/<your userid>/cfx_examples/StaticMixer.def .

# 10. SGE puts the machine file in $TMPDIR/machines. Use this to generate the 
# string CFX_NODES needed by cfx5solve

export CFX_NODES=`cfxnodes $TMPDIR/machines`

# 11. Run cfx5solve - Note: -max-elapsed-time needs to be set to the same
# time as defined by 2 above.

cfx5solve -max-elapsed-time "60 [min]" -def StaticMixer.def -par-dist $CFX_NODES
</nowiki>
|script-path=
|script-notes=Please copy if you wish and edit it to suit your jobs. You will need to change the ''-wd /home/<your_UCL_id>/Scratch/cfxtests-19.1'' SGE directive and may need to change the memory, wallclock time, number of MPI Processors (item 5) and job name directives as well. Replace the ''.def'' file in 9 and 11 by your one and modify the ''-max-elapsed-time'' value if needed. The simplest form of qsub command can be used to submit the job eg:
<code>
 qsub run-StaticMixer-par.sh
</code>
Output files will be saved in the job's working directory.

===Notes for running on Myriad===

The default supplied Intel MPI doesn't work on Myriad. Instead you need to use the supplied IBM MPI. This can be done by adding:
<code>
-start-method "IBM MPI Distributed Parallel"
</code>
to the ''cfx5solve'' command.

=Troubleshooting=

If you are getting licensing errors when trying to run a parallel job and you have a <code>~/.ansys/v161/licensing/license.preferences.xml</code> file, delete it. It does not work with the newer license server. (This applies to all versions, not just v161).

[[#top | Back to top]]
}}

}}